{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PbvtUGNGAee4",
        "kkeAFMUIVPkh"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MOSEI 2"
      ],
      "metadata": {
        "id": "Ztv8M854ldlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone data loader\n",
        "!git clone https://github.com/CMU-MultiComp-Lab/CMU-MultimodalSDK.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9OOIAvglgiv",
        "outputId": "d7185e51-4a81-45d6-f9ba-d059a733a486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CMU-MultimodalSDK'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 100 (delta 13), reused 94 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (100/100), 294.05 KiB | 1.21 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install requirements\n",
        "%cd /content/CMU-MultimodalSDK\n",
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Br5wre1ogQU",
        "outputId": "e5f28194-0da0-4dae-b146-205a0a16d441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CMU-MultimodalSDK\n",
            "Processing /content/CMU-MultimodalSDK\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from mmsdk==1.1.0) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from mmsdk==1.1.0) (3.12.1)\n",
            "Requirement already satisfied: validators>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from mmsdk==1.1.0) (0.34.0)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from mmsdk==1.1.0) (4.66.6)\n",
            "Requirement already satisfied: colorama>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from mmsdk==1.1.0) (0.4.6)\n",
            "Building wheels for collected packages: mmsdk\n",
            "  Building wheel for mmsdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmsdk: filename=mmsdk-1.1.0-py3-none-any.whl size=79210 sha256=0a4e736f9e82b16cb2972471ca6350eb44340fe00452d6e4b5985812328f34ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/12/b6/5abbb16746cd7a88030aee0301975f51dea74e77699c67ed0b\n",
            "Successfully built mmsdk\n",
            "Installing collected packages: mmsdk\n",
            "  Attempting uninstall: mmsdk\n",
            "    Found existing installation: mmsdk 1.1.0\n",
            "    Uninstalling mmsdk-1.1.0:\n",
            "      Successfully uninstalled mmsdk-1.1.0\n",
            "Successfully installed mmsdk-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mmsdk import mmdatasdk"
      ],
      "metadata": {
        "id": "z5CJrGUwqJUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch dataset high level features\n",
        "cmumosei_highlevel=mmdatasdk.mmdataset(mmdatasdk.cmu_mosei.highlevel,'cmumosei/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd0APyjD2pm4",
        "outputId": "f24b4932-8008-4ac9-f268-93ca0723a21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m\u001b[1m[2024-11-21 08:35:55.615] | Status  | \u001b[0mDownloading from http://immortal.multicomp.cs.cmu.edu/CMU-MOSEI/language/CMU_MOSEI_TimestampedWordVectors.csd to cmumosei/CMU_MOSEI_TimestampedWordVectors.csd...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\u001b[1m[2024-11-21 08:36:50.936] | Success | \u001b[0mDownload complete!\n",
            "\u001b[92m\u001b[1m[2024-11-21 08:36:51.032] | Success | \u001b[0mComputational sequence read from file cmumosei/CMU_MOSEI_TimestampedWordVectors.csd ...\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:36:51.363] | Status  | \u001b[0mChecking the integrity of the <glove_vectors> computational sequence ...\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:36:51.364] | Status  | \u001b[0mChecking the format of the data in <glove_vectors> computational sequence ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\u001b[1m[2024-11-21 08:36:53.612] | Success | \u001b[0m<glove_vectors> computational sequence data in correct format.\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:36:53.612] | Status  | \u001b[0mChecking the format of the metadata in <glove_vectors> computational sequence ...\n",
            "\u001b[93m\u001b[1m[2024-11-21 08:36:53.612] | Warning | \u001b[0m<glove_vectors> computational sequence does not have all the required metadata ... continuing \n",
            "\u001b[94m\u001b[1m[2024-11-21 08:36:53.981] | Status  | \u001b[0mDownloading from http://immortal.multicomp.cs.cmu.edu/CMU-MOSEI/acoustic/CMU_MOSEI_COVAREP.csd to cmumosei/CMU_MOSEI_COVAREP.csd...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\u001b[1m[2024-11-21 08:44:33.479] | Success | \u001b[0mDownload complete!\n",
            "\u001b[92m\u001b[1m[2024-11-21 08:44:33.488] | Success | \u001b[0mComputational sequence read from file cmumosei/CMU_MOSEI_COVAREP.csd ...\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:44:34.912] | Status  | \u001b[0mChecking the integrity of the <COVAREP> computational sequence ...\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:44:34.912] | Status  | \u001b[0mChecking the format of the data in <COVAREP> computational sequence ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\u001b[1m[2024-11-21 08:44:39.694] | Success | \u001b[0m<COVAREP> computational sequence data in correct format.\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:44:39.694] | Status  | \u001b[0mChecking the format of the metadata in <COVAREP> computational sequence ...\n",
            "\u001b[93m\u001b[1m[2024-11-21 08:44:39.694] | Warning | \u001b[0m<COVAREP> computational sequence does not have all the required metadata ... continuing \n",
            "\u001b[94m\u001b[1m[2024-11-21 08:44:39.996] | Status  | \u001b[0mDownloading from http://immortal.multicomp.cs.cmu.edu/CMU-MOSEI/visual/CMU_MOSEI_VisualOpenFace2.csd to cmumosei/CMU_MOSEI_VisualOpenFace2.csd...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\u001b[1m[2024-11-21 08:55:31.922] | Success | \u001b[0mDownload complete!\n",
            "\u001b[92m\u001b[1m[2024-11-21 08:55:31.927] | Success | \u001b[0mComputational sequence read from file cmumosei/CMU_MOSEI_VisualOpenFace2.csd ...\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:55:33.782] | Status  | \u001b[0mChecking the integrity of the <OpenFace_2> computational sequence ...\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:55:33.783] | Status  | \u001b[0mChecking the format of the data in <OpenFace_2> computational sequence ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\u001b[1m[2024-11-21 08:55:39.617] | Success | \u001b[0m<OpenFace_2> computational sequence data in correct format.\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:55:39.617] | Status  | \u001b[0mChecking the format of the metadata in <OpenFace_2> computational sequence ...\n",
            "\u001b[93m\u001b[1m[2024-11-21 08:55:39.618] | Warning | \u001b[0m<OpenFace_2> computational sequence does not have all the required metadata ... continuing \n",
            "\u001b[94m\u001b[1m[2024-11-21 08:55:39.869] | Status  | \u001b[0mDownloading from http://immortal.multicomp.cs.cmu.edu/CMU-MOSEI/visual/CMU_MOSEI_VisualFacet42.csd to cmumosei/CMU_MOSEI_VisualFacet42.csd...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\u001b[1m[2024-11-21 08:57:01.747] | Success | \u001b[0mDownload complete!\n",
            "\u001b[92m\u001b[1m[2024-11-21 08:57:01.751] | Success | \u001b[0mComputational sequence read from file cmumosei/CMU_MOSEI_VisualFacet42.csd ...\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:57:01.910] | Status  | \u001b[0mChecking the integrity of the <FACET 4.2> computational sequence ...\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:57:01.915] | Status  | \u001b[0mChecking the format of the data in <FACET 4.2> computational sequence ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\u001b[1m[2024-11-21 08:57:04.939] | Success | \u001b[0m<FACET 4.2> computational sequence data in correct format.\n",
            "\u001b[94m\u001b[1m[2024-11-21 08:57:04.939] | Status  | \u001b[0mChecking the format of the metadata in <FACET 4.2> computational sequence ...\n",
            "\u001b[93m\u001b[1m[2024-11-21 08:57:04.939] | Warning | \u001b[0m<FACET 4.2> computational sequence does not have all the required metadata ... continuing \n",
            "\u001b[92m\u001b[1m[2024-11-21 08:57:04.939] | Success | \u001b[0mDataset initialized successfully ... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch dataset labels\n",
        "cmumosei_highlevel.add_computational_sequences(mmdatasdk.cmu_mosei.labels,'cmumosei/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaujvmC936Bj",
        "outputId": "5ecf9beb-f846-49a2-a857-406cb547a967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m\u001b[1m[2024-11-21 09:12:32.501] | Status  | \u001b[0mDownloading from http://immortal.multicomp.cs.cmu.edu/CMU-MOSEI/labels/CMU_MOSEI_Labels.csd to cmumosei/CMU_MOSEI_Labels.csd...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\u001b[1m[2024-11-21 09:12:33.827] | Success | \u001b[0mDownload complete!\n",
            "\u001b[92m\u001b[1m[2024-11-21 09:12:33.832] | Success | \u001b[0mComputational sequence read from file cmumosei/CMU_MOSEI_Labels.csd ...\n",
            "\u001b[94m\u001b[1m[2024-11-21 09:12:33.930] | Status  | \u001b[0mChecking the integrity of the <All Labels> computational sequence ...\n",
            "\u001b[94m\u001b[1m[2024-11-21 09:12:33.931] | Status  | \u001b[0mChecking the format of the data in <All Labels> computational sequence ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\u001b[1m[2024-11-21 09:12:35.610] | Success | \u001b[0m<All Labels> computational sequence data in correct format.\n",
            "\u001b[94m\u001b[1m[2024-11-21 09:12:35.610] | Status  | \u001b[0mChecking the format of the metadata in <All Labels> computational sequence ...\n",
            "\u001b[93m\u001b[1m[2024-11-21 09:12:35.610] | Warning | \u001b[0m<All Labels> computational sequence does not have all the required metadata ... continuing \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOSEI 3"
      ],
      "metadata": {
        "id": "yhCGtEBhYgGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pliang279/MultiBench.git\n",
        "%cd MultiBench"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yljZDrJnFbJt",
        "outputId": "610a9662-8a94-4d4d-d154-fb7ca3cc382e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MultiBench' already exists and is not an empty directory.\n",
            "/content/MultiBench\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access my drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE2lE5DTH26m",
        "outputId": "0f485aa6-dfa7-4179-fcd7-a75548bfd413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y\n",
        "!pip install torch==2.3.0+cu118 torchvision==0.18.0+cu118 torchaudio==2.3.0+cu118 torchtext==0.18.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBnurZ8eTGx3",
        "outputId": "1b34440d-ebb3-4f10-f361-914946a14a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.3.0+cu118\n",
            "Uninstalling torch-2.3.0+cu118:\n",
            "  Successfully uninstalled torch-2.3.0+cu118\n",
            "Found existing installation: torchvision 0.18.0+cu118\n",
            "Uninstalling torchvision-0.18.0+cu118:\n",
            "  Successfully uninstalled torchvision-0.18.0+cu118\n",
            "Found existing installation: torchaudio 2.3.0+cu118\n",
            "Uninstalling torchaudio-2.3.0+cu118:\n",
            "  Successfully uninstalled torchaudio-2.3.0+cu118\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.3.0+cu118\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.3.0%2Bcu118-cp310-cp310-linux_x86_64.whl (839.6 MB)\n",
            "Collecting torchvision==0.18.0+cu118\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.18.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.3 MB)\n",
            "Collecting torchaudio==2.3.0+cu118\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.3.0%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "Requirement already satisfied: torchtext==0.18.0 in /usr/local/lib/python3.10/dist-packages (0.18.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (11.8.86)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu118) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.0+cu118) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.0+cu118) (11.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0+cu118) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0+cu118) (1.3.0)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "Successfully installed torch-2.3.0+cu118 torchaudio-2.3.0+cu118 torchvision-0.18.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "# Import the associated dataloader for affect datasets, which MOSEI is a part of\n",
        "from datasets.affect.get_data import get_dataloader\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "joDuk4ERJd_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training, validation, and test-set dataloaders.\n",
        "traindata, validdata, testdata = get_dataloader('/content/drive/MyDrive/data/mosei_raw.pkl', data_type='mosei', max_pad=True)"
      ],
      "metadata": {
        "id": "HYpor9In3VuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata.dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn_8ROodQYZT",
        "outputId": "22dbab86-0ad0-4964-fa17-06854b5fcd90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 0.0000, 86.5667,  0.9800,  ...,  0.0000,  0.0000,  0.3846],\n",
              "         [ 0.0000, 86.8667,  0.9800,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000, 87.2500,  0.9800,  ...,  0.0000,  0.0000,  0.1111],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]),\n",
              " tensor([[ 1.1593e+02,  7.0000e-01,  7.6338e-02,  ..., -3.4502e-01,\n",
              "          -3.3369e-01, -2.5789e-01],\n",
              "         [ 1.0325e+02,  9.0909e-01,  1.2092e-01,  ..., -3.6509e-01,\n",
              "          -4.0033e-01, -2.8453e-01],\n",
              "         [ 1.3098e+02,  6.2069e-01,  1.1778e-01,  ..., -3.8097e-01,\n",
              "          -3.5543e-01, -2.8628e-01],\n",
              "         ...,\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "           0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "           0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "           0.0000e+00,  0.0000e+00]]),\n",
              " tensor([[ 0.3358,  0.3090,  0.1210,  ...,  0.2656, -0.1599, -0.0340],\n",
              "         [-0.0850,  0.5020,  0.0024,  ..., -0.2151, -0.2630, -0.0060],\n",
              "         [ 0.0175,  0.0180,  0.0710,  ...,  0.0735, -0.3156,  0.1167],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]),\n",
              " tensor([[1.0000, 0.6667, 0.6667, 0.0000, 0.0000, 0.0000, 0.6667]])]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of elements in a line\n",
        "for i in range(3):\n",
        "    data = traindata.dataset[i]\n",
        "    print(data[0].size())\n",
        "    print(data[1].size())\n",
        "    print(data[2].size())\n",
        "    print(data[3].size())\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7WOl6lRQdyV",
        "outputId": "14779f11-6fe4-4749-ee65-9b4d67daa315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 713])\n",
            "torch.Size([50, 74])\n",
            "torch.Size([50, 300])\n",
            "torch.Size([1, 7])\n",
            "\n",
            "torch.Size([50, 713])\n",
            "torch.Size([50, 74])\n",
            "torch.Size([50, 300])\n",
            "torch.Size([1, 7])\n",
            "\n",
            "torch.Size([50, 713])\n",
            "torch.Size([50, 74])\n",
            "torch.Size([50, 300])\n",
            "torch.Size([1, 7])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we know that index 0 is video, index 1 is audio, index 2 is text, index 3 is label"
      ],
      "metadata": {
        "id": "WsTBDPYUQicK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of elements in a batch\n",
        "for video, audio, text, label in traindata:\n",
        "    print('Video Tensor Shape:', video.shape)\n",
        "    print('Audio Tensor Shape:', audio.shape)\n",
        "    print('Text Tensor Shape:', text.shape)\n",
        "    print('Label Shape:', label.shape)\n",
        "    break  # Stop after the first batch for inspection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmRU_whMRH0C",
        "outputId": "dbebbd53-5e7c-437b-9511-a0dd11d29b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Tensor Shape: torch.Size([32, 50, 713])\n",
            "Audio Tensor Shape: torch.Size([32, 50, 74])\n",
            "Text Tensor Shape: torch.Size([32, 50, 300])\n",
            "Label Shape: torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The label shape is wrong, it should be [32, 1, 7]. Need to correct it, also I would like to drop the singleton dimension and result with [32, 7]"
      ],
      "metadata": {
        "id": "YmRUvTseKxVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate(batch):\n",
        "    videos, audios, texts, labels = zip(*batch)  # Unpack the batch\n",
        "\n",
        "    # Stack inputs as usual\n",
        "    videos = torch.stack(videos)\n",
        "    audios = torch.stack(audios)\n",
        "    texts = torch.stack(texts)\n",
        "\n",
        "    # Stack labels and remove the singleton dimension\n",
        "    labels = torch.cat(labels, dim=0)  # Shape: [batch_size, 7]\n",
        "\n",
        "    return videos, audios, texts, labels\n",
        "\n",
        "# Create DataLoader with custom collate function\n",
        "traindata = DataLoader(traindata.dataset, batch_size=32, collate_fn=custom_collate)\n",
        "validdata = DataLoader(validdata.dataset, batch_size=32, collate_fn=custom_collate)\n",
        "testdata = DataLoader(testdata.dataset, batch_size=32, collate_fn=custom_collate)"
      ],
      "metadata": {
        "id": "m1EBWXwVKilN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for video, audio, text, label in traindata:\n",
        "    print('Label Shape:', label.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33HjqlQ6IWSu",
        "outputId": "bbfea91f-2657-4bb2-dd5d-190d5031e78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Shape: torch.Size([32, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_dataset_splits(train_loader, val_loader, test_loader):\n",
        "    # Helper function to count the total number of samples in a dataloader\n",
        "    def count_samples(dataloader):\n",
        "        return sum(batch[0].size(0) for batch in dataloader)  # Assumes batch[0] contains the data tensor\n",
        "\n",
        "    # Count samples in each dataloader\n",
        "    num_train_samples = count_samples(train_loader)\n",
        "    num_val_samples = count_samples(val_loader)\n",
        "    num_test_samples = count_samples(test_loader)\n",
        "\n",
        "    # Calculate total and percentages\n",
        "    total_samples = num_train_samples + num_val_samples + num_test_samples\n",
        "    train_split = num_train_samples / total_samples * 100\n",
        "    val_split = num_val_samples / total_samples * 100\n",
        "    test_split = num_test_samples / total_samples * 100\n",
        "\n",
        "    return {\n",
        "        \"train_split\": train_split,\n",
        "        \"val_split\": val_split,\n",
        "        \"test_split\": test_split\n",
        "    }\n",
        "\n",
        "dataset_splits = calculate_dataset_splits(traindata, validdata, testdata)\n",
        "dataset_splits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgq8KOiGxT1q",
        "outputId": "6ae34e6e-fa5a-4e56-c8af-b26727f80d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_split': 71.42169728783902,\n",
              " 'val_split': 8.184601924759406,\n",
              " 'test_split': 20.393700787401574}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Z-Score Standardization"
      ],
      "metadata": {
        "id": "ClIxhIe8DwpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize accumulators for mean and standard deviation\n",
        "video_sum, video_sq_sum, video_count = 0, 0, 0\n",
        "audio_sum, audio_sq_sum, audio_count = 0, 0, 0\n",
        "text_sum, text_sq_sum, text_count = 0, 0, 0\n",
        "\n",
        "# Helper function to calculate valid rows (eliminate padded all-zero rows)\n",
        "def get_valid_rows(batch):\n",
        "    '''\n",
        "    Loops backward through each sequence in the batch to find where the padding ends.\n",
        "    '''\n",
        "    valid_rows = []\n",
        "    for seq in batch:\n",
        "        # Loop backward to find the first non-zero row\n",
        "        for i in range(seq.size(0) - 1, -1, -1):\n",
        "            if seq[i].sum() != 0:  # If a row is non-zero, it's valid\n",
        "                valid_rows.append(seq[:i + 1])  # Include all rows up to this one\n",
        "                break\n",
        "    return valid_rows\n",
        "\n",
        "for video, audio, text, _ in traindata:  # Returns batches for each modality\n",
        "    # Process video modality\n",
        "    valid_video_rows = get_valid_rows(video)\n",
        "    for rows in valid_video_rows:\n",
        "        video_sum += rows.sum(dim=0)  # Sum valid rows\n",
        "        video_sq_sum += (rows ** 2).sum(dim=0)  # Sum squared valid rows\n",
        "        video_count += rows.size(0)  # Count valid rows\n",
        "\n",
        "    # Process audio modality\n",
        "    valid_audio_rows = get_valid_rows(audio)\n",
        "    for rows in valid_audio_rows:\n",
        "        audio_sum += rows.sum(dim=0)\n",
        "        audio_sq_sum += (rows ** 2).sum(dim=0)\n",
        "        audio_count += rows.size(0)\n",
        "\n",
        "    # Process text modality\n",
        "    valid_text_rows = get_valid_rows(text)\n",
        "    for rows in valid_text_rows:\n",
        "        text_sum += rows.sum(dim=0)\n",
        "        text_sq_sum += (rows ** 2).sum(dim=0)\n",
        "        text_count += rows.size(0)\n",
        "\n",
        "# Calculate mean and std for each modality\n",
        "video_mean = video_sum / video_count\n",
        "video_std = torch.sqrt(video_sq_sum / video_count - video_mean ** 2)\n",
        "\n",
        "audio_mean = audio_sum / audio_count\n",
        "audio_std = torch.sqrt(audio_sq_sum / audio_count - audio_mean ** 2)\n",
        "\n",
        "text_mean = text_sum / text_count\n",
        "text_std = torch.sqrt(text_sq_sum / text_count - text_mean ** 2)\n",
        "\n",
        "# If any feature in a modality has zero variance, set its standard deviation to 1.0 to avoid division by zero\n",
        "video_std[video_std == 0] = 1.0\n",
        "audio_std[audio_std == 0] = 1.0\n",
        "text_std[text_std == 0] = 1.0\n",
        "\n",
        "# Print computed values\n",
        "print('Video mean:', video_mean, '\\n')\n",
        "print('Video std:', video_std, '\\n')\n",
        "print('Audio mean:', audio_mean, '\\n')\n",
        "print('Audio std:', audio_std, '\\n')\n",
        "print('Text mean:', text_mean, '\\n')\n",
        "print('Text std:', text_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkRPYi3RZeKd",
        "outputId": "0e11fa2c-1484-469a-c091-f8aebbf73f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video mean: tensor([ 0.0000e+00,  5.7517e+01,  9.3876e-01,  9.6661e-01,  5.4636e-02,\n",
            "         1.8333e-01, -9.0856e-01, -8.3082e-02,  1.8719e-01, -9.0563e-01,\n",
            "        -1.5194e-02,  1.9564e-01,  4.0773e+02,  4.0960e+02,  4.1435e+02,\n",
            "         4.1919e+02,  4.2129e+02,  4.1978e+02,  4.1467e+02,  4.0983e+02,\n",
            "         4.0172e+02,  4.0454e+02,  4.0860e+02,  4.1370e+02,  4.1895e+02,\n",
            "         4.2304e+02,  4.2597e+02,  4.2277e+02,  4.1827e+02,  4.1336e+02,\n",
            "         4.0872e+02,  4.0469e+02,  4.1249e+02,  4.1465e+02,  4.1677e+02,\n",
            "         4.1760e+02,  4.1666e+02,  4.1450e+02,  4.1238e+02,  4.1155e+02,\n",
            "         4.7193e+02,  4.7381e+02,  4.7863e+02,  4.8357e+02,  4.8573e+02,\n",
            "         4.8385e+02,  4.7903e+02,  4.7371e+02,  4.6723e+02,  4.7033e+02,\n",
            "         4.7458e+02,  4.7991e+02,  4.8494e+02,  4.8883e+02,  4.9152e+02,\n",
            "         4.8888e+02,  4.8510e+02,  4.8057e+02,  4.7553e+02,  4.7074e+02,\n",
            "         4.7656e+02,  4.7877e+02,  4.8093e+02,  4.8177e+02,  4.8080e+02,\n",
            "         4.7859e+02,  4.7644e+02,  4.7560e+02,  1.7781e+02,  1.7284e+02,\n",
            "         1.7062e+02,  1.7246e+02,  1.7728e+02,  1.8264e+02,  1.8448e+02,\n",
            "         1.8263e+02,  1.8005e+02,  1.7731e+02,  1.7542e+02,  1.7435e+02,\n",
            "         1.7497e+02,  1.7683e+02,  1.7962e+02,  1.8135e+02,  1.8208e+02,\n",
            "         1.8256e+02,  1.8245e+02,  1.8172e+02,  1.7998e+02,  1.8080e+02,\n",
            "         1.7981e+02,  1.7759e+02,  1.7544e+02,  1.7461e+02,  1.7560e+02,\n",
            "         1.7783e+02,  1.7689e+02,  1.7190e+02,  1.6987e+02,  1.7200e+02,\n",
            "         1.7703e+02,  1.8202e+02,  1.8405e+02,  1.8233e+02,  1.7925e+02,\n",
            "         1.7641e+02,  1.7446e+02,  1.7374e+02,  1.7472e+02,  1.7653e+02,\n",
            "         1.7923e+02,  1.8091e+02,  1.8168e+02,  1.8187e+02,  1.8152e+02,\n",
            "         1.8092e+02,  1.7938e+02,  1.8033e+02,  1.7942e+02,  1.7719e+02,\n",
            "         1.7494e+02,  1.7399e+02,  1.7489e+02,  1.7713e+02, -2.4353e+01,\n",
            "        -2.2791e+01, -1.8801e+01, -1.4729e+01, -1.2963e+01, -1.4237e+01,\n",
            "        -1.8508e+01, -2.2574e+01, -2.9734e+01, -2.7170e+01, -2.3597e+01,\n",
            "        -1.9245e+01, -1.4867e+01, -1.1502e+01, -9.1036e+00, -1.1741e+01,\n",
            "        -1.5458e+01, -1.9551e+01, -2.3510e+01, -2.7050e+01, -2.0382e+01,\n",
            "        -1.8576e+01, -1.6808e+01, -1.6114e+01, -1.6899e+01, -1.8707e+01,\n",
            "        -2.0476e+01, -2.1171e+01,  1.9586e+01,  2.1164e+01,  2.5163e+01,\n",
            "         2.9239e+01,  3.0989e+01,  2.9388e+01,  2.5390e+01,  2.1031e+01,\n",
            "         1.5737e+01,  1.8236e+01,  2.1691e+01,  2.6077e+01,  3.0320e+01,\n",
            "         3.3704e+01,  3.6103e+01,  3.3713e+01,  3.0420e+01,  2.6591e+01,\n",
            "         2.2460e+01,  1.8577e+01,  2.3438e+01,  2.5243e+01,  2.7021e+01,\n",
            "         2.7729e+01,  2.6951e+01,  2.5141e+01,  2.3364e+01,  2.2659e+01,\n",
            "        -9.4909e+01, -9.9177e+01, -1.0103e+02, -9.9377e+01, -9.5196e+01,\n",
            "        -9.0645e+01, -8.9096e+01, -9.0735e+01, -9.3465e+01, -9.5469e+01,\n",
            "        -9.6745e+01, -9.7453e+01, -9.6924e+01, -9.5447e+01, -9.3235e+01,\n",
            "        -9.1607e+01, -9.0861e+01, -9.0480e+01, -9.0761e+01, -9.1685e+01,\n",
            "        -9.3098e+01, -9.2369e+01, -9.3190e+01, -9.5081e+01, -9.6935e+01,\n",
            "        -9.7667e+01, -9.6845e+01, -9.4952e+01, -8.9194e+01, -9.3463e+01,\n",
            "        -9.5288e+01, -9.3582e+01, -8.9347e+01, -8.5079e+01, -8.3278e+01,\n",
            "        -8.4666e+01, -8.7176e+01, -8.9423e+01, -9.0987e+01, -9.1649e+01,\n",
            "        -9.1087e+01, -8.9931e+01, -8.8024e+01, -8.6216e+01, -8.5222e+01,\n",
            "        -8.4828e+01, -8.5064e+01, -8.5655e+01, -8.7300e+01, -8.6542e+01,\n",
            "        -8.7345e+01, -8.9243e+01, -9.1123e+01, -9.1881e+01, -9.1073e+01,\n",
            "        -8.9175e+01,  6.6529e+02,  6.6581e+02,  6.6582e+02,  6.6531e+02,\n",
            "         6.6458e+02,  6.6426e+02,  6.6404e+02,  6.6456e+02,  6.6935e+02,\n",
            "         6.6682e+02,  6.6450e+02,  6.6324e+02,  6.6354e+02,  6.6466e+02,\n",
            "         6.6604e+02,  6.6447e+02,  6.6309e+02,  6.6296e+02,  6.6427e+02,\n",
            "         6.6663e+02,  6.6555e+02,  6.6532e+02,  6.6532e+02,  6.6556e+02,\n",
            "         6.6588e+02,  6.6611e+02,  6.6611e+02,  6.6587e+02,  5.8217e+02,\n",
            "         5.8319e+02,  5.8416e+02,  5.8451e+02,  5.8404e+02,  5.8302e+02,\n",
            "         5.8205e+02,  5.8186e+02,  5.8310e+02,  5.8205e+02,  5.8135e+02,\n",
            "         5.8155e+02,  5.8325e+02,  5.8587e+02,  5.8860e+02,  5.8559e+02,\n",
            "         5.8286e+02,  5.8110e+02,  5.8079e+02,  5.8178e+02,  5.8325e+02,\n",
            "         5.8341e+02,  5.8384e+02,  5.8430e+02,  5.8451e+02,  5.8435e+02,\n",
            "         5.8392e+02,  5.8346e+02, -3.1760e+05, -1.8104e+05,  4.3731e+05,\n",
            "         8.4041e-02,  4.7042e-02, -3.6029e-03,  3.7420e+02,  3.7415e+02,\n",
            "         3.7620e+02,  3.8021e+02,  3.8730e+02,  3.9854e+02,  4.1222e+02,\n",
            "         4.2858e+02,  4.4749e+02,  4.6628e+02,  4.8260e+02,  4.9696e+02,\n",
            "         5.0799e+02,  5.1489e+02,  5.1851e+02,  5.2053e+02,  5.2120e+02,\n",
            "         3.8714e+02,  3.9594e+02,  4.0791e+02,  4.2049e+02,  4.3202e+02,\n",
            "         4.6092e+02,  4.7344e+02,  4.8564e+02,  4.9735e+02,  5.0584e+02,\n",
            "         4.4689e+02,  4.4683e+02,  4.4681e+02,  4.4677e+02,  4.3177e+02,\n",
            "         4.3915e+02,  4.4680e+02,  4.5470e+02,  4.6179e+02,  4.0120e+02,\n",
            "         4.0907e+02,  4.1850e+02,  4.2662e+02,  4.1819e+02,  4.0888e+02,\n",
            "         4.6661e+02,  4.7504e+02,  4.8446e+02,  4.9204e+02,  4.8500e+02,\n",
            "         4.7579e+02,  4.1872e+02,  4.2903e+02,  4.3963e+02,  4.4678e+02,\n",
            "         4.5461e+02,  4.6552e+02,  4.7548e+02,  4.6586e+02,  4.5534e+02,\n",
            "         4.4688e+02,  4.3906e+02,  4.2859e+02,  4.2321e+02,  4.3956e+02,\n",
            "         4.4681e+02,  4.5474e+02,  4.7112e+02,  4.5476e+02,  4.4670e+02,\n",
            "         4.3931e+02,  1.8460e+02,  2.0480e+02,  2.2514e+02,  2.4498e+02,\n",
            "         2.6338e+02,  2.7944e+02,  2.9220e+02,  3.0179e+02,  3.0450e+02,\n",
            "         3.0177e+02,  2.9226e+02,  2.7943e+02,  2.6345e+02,  2.4468e+02,\n",
            "         2.2452e+02,  2.0408e+02,  1.8387e+02,  1.6351e+02,  1.5459e+02,\n",
            "         1.5131e+02,  1.5243e+02,  1.5643e+02,  1.5583e+02,  1.5154e+02,\n",
            "         1.5062e+02,  1.5345e+02,  1.6133e+02,  1.7431e+02,  1.8653e+02,\n",
            "         1.9862e+02,  2.1120e+02,  2.2296e+02,  2.2545e+02,  2.2752e+02,\n",
            "         2.2537e+02,  2.2295e+02,  1.7997e+02,  1.7506e+02,  1.7496e+02,\n",
            "         1.7989e+02,  1.8213e+02,  1.8245e+02,  1.7953e+02,  1.7432e+02,\n",
            "         1.7457e+02,  1.7901e+02,  1.8163e+02,  1.8158e+02,  2.5239e+02,\n",
            "         2.4527e+02,  2.4205e+02,  2.4387e+02,  2.4211e+02,  2.4547e+02,\n",
            "         2.5166e+02,  2.6144e+02,  2.6534e+02,  2.6615e+02,  2.6548e+02,\n",
            "         2.6170e+02,  2.5248e+02,  2.4931e+02,  2.4981e+02,  2.4912e+02,\n",
            "         2.5210e+02,  2.5542e+02,  2.5627e+02,  2.5560e+02, -7.1886e+01,\n",
            "        -7.1996e+01, -7.0117e+01, -6.6168e+01, -5.8732e+01, -4.7112e+01,\n",
            "        -3.3195e+01, -1.7367e+01, -3.4430e-02,  1.7214e+01,  3.2933e+01,\n",
            "         4.7270e+01,  5.8289e+01,  6.5015e+01,  6.8368e+01,  7.0261e+01,\n",
            "         7.1079e+01, -5.6069e+01, -4.7327e+01, -3.5734e+01, -2.3859e+01,\n",
            "        -1.3245e+01,  1.1911e+01,  2.3299e+01,  3.4669e+01,  4.5696e+01,\n",
            "         5.3758e+01, -3.0441e-01, -3.5815e-01, -3.6973e-01, -3.9772e-01,\n",
            "        -1.3723e+01, -7.1700e+00, -4.7297e-01,  6.4239e+00,  1.2665e+01,\n",
            "        -4.2368e+01, -3.4859e+01, -2.6113e+01, -1.8677e+01, -2.6374e+01,\n",
            "        -3.5022e+01,  1.7357e+01,  2.5025e+01,  3.3643e+01,  4.0714e+01,\n",
            "         3.4102e+01,  2.5670e+01, -2.6085e+01, -1.6301e+01, -6.7975e+00,\n",
            "        -5.6147e-01,  6.2844e+00,  1.5963e+01,  2.5238e+01,  1.6244e+01,\n",
            "         6.8994e+00, -5.0786e-01, -7.3484e+00, -1.6739e+01, -2.1922e+01,\n",
            "        -6.9033e+00, -5.5250e-01,  6.4068e+00,  2.1193e+01,  6.4346e+00,\n",
            "        -6.4211e-01, -7.1316e+00, -9.7852e+01, -7.7852e+01, -5.7718e+01,\n",
            "        -3.8006e+01, -1.9772e+01, -4.2339e+00,  7.5433e+00,  1.5753e+01,\n",
            "         1.7901e+01,  1.5694e+01,  7.4078e+00, -4.5145e+00, -1.9956e+01,\n",
            "        -3.8258e+01, -5.7757e+01, -7.7498e+01, -9.7254e+01, -1.1340e+02,\n",
            "        -1.2094e+02, -1.2293e+02, -1.2080e+02, -1.1626e+02, -1.1662e+02,\n",
            "        -1.2123e+02, -1.2287e+02, -1.2087e+02, -1.1401e+02, -1.0007e+02,\n",
            "        -8.8269e+01, -7.6845e+01, -6.5288e+01, -5.6060e+01, -5.3683e+01,\n",
            "        -5.1737e+01, -5.3690e+01, -5.5934e+01, -9.7557e+01, -1.0167e+02,\n",
            "        -1.0149e+02, -9.6574e+01, -9.4605e+01, -9.4552e+01, -9.6687e+01,\n",
            "        -1.0166e+02, -1.0154e+02, -9.7686e+01, -9.4767e+01, -9.4700e+01,\n",
            "        -3.0146e+01, -3.6318e+01, -3.9047e+01, -3.7383e+01, -3.8971e+01,\n",
            "        -3.6106e+01, -3.0730e+01, -2.1863e+01, -1.8419e+01, -1.7716e+01,\n",
            "        -1.8304e+01, -2.1638e+01, -3.0041e+01, -3.2659e+01, -3.2174e+01,\n",
            "        -3.2796e+01, -3.0320e+01, -2.7242e+01, -2.6480e+01, -2.7092e+01,\n",
            "         6.9745e+02,  6.9785e+02,  6.9904e+02,  6.9900e+02,  6.9448e+02,\n",
            "         6.8658e+02,  6.7477e+02,  6.6109e+02,  6.5659e+02,  6.6171e+02,\n",
            "         6.7369e+02,  6.8361e+02,  6.8818e+02,  6.8880e+02,  6.8758e+02,\n",
            "         6.8720e+02,  6.8876e+02,  6.6633e+02,  6.6074e+02,  6.5488e+02,\n",
            "         6.4892e+02,  6.4446e+02,  6.4355e+02,  6.4729e+02,  6.5165e+02,\n",
            "         6.5550e+02,  6.5932e+02,  6.4243e+02,  6.3559e+02,  6.2856e+02,\n",
            "         6.2182e+02,  6.3786e+02,  6.3472e+02,  6.3238e+02,  6.3386e+02,\n",
            "         6.3613e+02,  6.6040e+02,  6.5661e+02,  6.5496e+02,  6.5372e+02,\n",
            "         6.5403e+02,  6.5564e+02,  6.5250e+02,  6.5250e+02,  6.5321e+02,\n",
            "         6.5589e+02,  6.5233e+02,  6.5153e+02,  6.5328e+02,  6.4056e+02,\n",
            "         6.3486e+02,  6.3367e+02,  6.3429e+02,  6.4016e+02,  6.5083e+02,\n",
            "         6.4100e+02,  6.3525e+02,  6.3431e+02,  6.3550e+02,  6.4150e+02,\n",
            "         6.5062e+02,  6.3663e+02,  6.3530e+02,  6.3610e+02,  6.4855e+02,\n",
            "         6.3678e+02,  6.3587e+02,  6.3729e+02,  1.0895e+00,  4.1380e-02,\n",
            "         4.3418e-02, -3.1357e-03,  4.4705e+02,  2.1984e+02, -1.8809e+01,\n",
            "         3.2169e+00, -8.1603e+00,  5.7095e+00, -6.3184e+00, -2.4003e+00,\n",
            "         1.0594e+00,  2.1511e+00, -1.2313e+00,  3.8682e-01, -3.7099e+00,\n",
            "         3.9769e-01,  8.2868e-01, -3.5032e+00,  3.1636e-01, -5.5377e-01,\n",
            "        -1.3724e+00, -4.7479e-01, -2.1446e+00, -1.7949e+00,  4.8147e-01,\n",
            "        -4.4293e-02,  4.3972e-01, -7.6930e-01, -5.6448e-01,  3.9107e-01,\n",
            "         3.4397e-02, -2.0153e-01, -8.6949e-02, -7.4929e-02, -8.3943e-03,\n",
            "        -2.9125e-03, -2.2418e-02,  9.2081e-02,  3.0728e-01,  1.3947e-01,\n",
            "         4.7617e-01,  7.4233e-02,  2.9944e-01,  6.3980e-01,  8.1772e-02,\n",
            "         5.1323e-01,  3.5686e-01,  3.6708e-01,  1.8415e-01,  5.5840e-01,\n",
            "         1.2326e-01,  1.5722e-01,  5.9009e-01,  5.3752e-01,  2.4916e-01,\n",
            "         2.3500e-01,  2.5892e-01,  2.8643e-01,  4.9743e-01,  2.0937e-01,\n",
            "         3.3252e-01,  6.1730e-02,  3.6518e-01,  2.0322e-01,  3.6201e-01,\n",
            "         1.7698e-01,  2.9676e-01,  1.1192e-01,  1.8258e-01,  2.7224e-01,\n",
            "         1.8150e-01,  9.3114e-03,  2.2866e-01]) \n",
            "\n",
            "Video std: tensor([1.0000e+00, 4.5742e+01, 1.6458e-01, 1.7505e-01, 2.2648e-01, 1.3775e-01,\n",
            "        1.7614e-01, 2.2699e-01, 1.3649e-01, 1.7629e-01, 2.4252e-01, 1.4643e-01,\n",
            "        2.3449e+02, 2.3486e+02, 2.3579e+02, 2.3673e+02, 2.3714e+02, 2.3683e+02,\n",
            "        2.3581e+02, 2.3487e+02, 2.3351e+02, 2.3401e+02, 2.3474e+02, 2.3570e+02,\n",
            "        2.3673e+02, 2.3754e+02, 2.3816e+02, 2.3749e+02, 2.3657e+02, 2.3561e+02,\n",
            "        2.3474e+02, 2.3403e+02, 2.3540e+02, 2.3583e+02, 2.3625e+02, 2.3643e+02,\n",
            "        2.3625e+02, 2.3581e+02, 2.3539e+02, 2.3522e+02, 2.4977e+02, 2.5030e+02,\n",
            "        2.5155e+02, 2.5280e+02, 2.5331e+02, 2.5277e+02, 2.5150e+02, 2.5017e+02,\n",
            "        2.4864e+02, 2.4940e+02, 2.5045e+02, 2.5178e+02, 2.5307e+02, 2.5410e+02,\n",
            "        2.5486e+02, 2.5409e+02, 2.5307e+02, 2.5189e+02, 2.5062e+02, 2.4945e+02,\n",
            "        2.5092e+02, 2.5149e+02, 2.5207e+02, 2.5231e+02, 2.5208e+02, 2.5151e+02,\n",
            "        2.5093e+02, 2.5069e+02, 8.0980e+01, 7.9687e+01, 7.9036e+01, 7.9378e+01,\n",
            "        8.0547e+01, 8.1971e+01, 8.2577e+01, 8.2188e+01, 8.1448e+01, 8.0741e+01,\n",
            "        8.0249e+01, 7.9907e+01, 7.9916e+01, 8.0233e+01, 8.0831e+01, 8.1381e+01,\n",
            "        8.1702e+01, 8.1935e+01, 8.1972e+01, 8.1830e+01, 8.1424e+01, 8.1601e+01,\n",
            "        8.1285e+01, 8.0673e+01, 8.0126e+01, 7.9961e+01, 8.0266e+01, 8.0869e+01,\n",
            "        8.0354e+01, 7.9127e+01, 7.8682e+01, 7.9238e+01, 8.0502e+01, 8.1775e+01,\n",
            "        8.2279e+01, 8.1777e+01, 8.0506e+01, 7.9891e+01, 7.9551e+01, 7.9493e+01,\n",
            "        7.9756e+01, 8.0175e+01, 8.0817e+01, 8.1217e+01, 8.1394e+01, 8.1414e+01,\n",
            "        8.1260e+01, 8.1018e+01, 8.1028e+01, 8.1300e+01, 8.1073e+01, 8.0486e+01,\n",
            "        7.9894e+01, 7.9633e+01, 7.9847e+01, 8.0423e+01, 4.6810e+03, 4.6810e+03,\n",
            "        4.6810e+03, 4.6810e+03, 4.6810e+03, 4.6810e+03, 4.6810e+03, 4.6810e+03,\n",
            "        4.6811e+03, 4.6811e+03, 4.6810e+03, 4.6810e+03, 4.6810e+03, 4.6810e+03,\n",
            "        4.6811e+03, 4.6810e+03, 4.6810e+03, 4.6810e+03, 4.6810e+03, 4.6811e+03,\n",
            "        4.6810e+03, 4.6810e+03, 4.6810e+03, 4.6810e+03, 4.6810e+03, 4.6810e+03,\n",
            "        4.6810e+03, 4.6810e+03, 3.2937e+02, 3.2952e+02, 3.2971e+02, 3.2983e+02,\n",
            "        3.2980e+02, 3.2965e+02, 3.2947e+02, 3.2936e+02, 3.2939e+02, 3.2934e+02,\n",
            "        3.2934e+02, 3.2946e+02, 3.2972e+02, 3.3006e+02, 3.3038e+02, 3.3002e+02,\n",
            "        3.2968e+02, 3.2942e+02, 3.2930e+02, 3.2931e+02, 3.2956e+02, 3.2961e+02,\n",
            "        3.2969e+02, 3.2976e+02, 3.2977e+02, 3.2972e+02, 3.2963e+02, 3.2957e+02,\n",
            "        2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03,\n",
            "        2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03,\n",
            "        2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03,\n",
            "        2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03,\n",
            "        2.7767e+03, 2.7767e+03, 2.7767e+03, 2.7767e+03, 1.4305e+02, 1.4303e+02,\n",
            "        1.4304e+02, 1.4308e+02, 1.4313e+02, 1.4315e+02, 1.4313e+02, 1.4311e+02,\n",
            "        1.4304e+02, 1.4298e+02, 1.4294e+02, 1.4296e+02, 1.4304e+02, 1.4317e+02,\n",
            "        1.4331e+02, 1.4319e+02, 1.4307e+02, 1.4300e+02, 1.4298e+02, 1.4301e+02,\n",
            "        1.4313e+02, 1.4315e+02, 1.4316e+02, 1.4314e+02, 1.4312e+02, 1.4309e+02,\n",
            "        1.4309e+02, 1.4311e+02, 3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04,\n",
            "        3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04,\n",
            "        3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04,\n",
            "        3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04,\n",
            "        3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04, 3.9245e+04,\n",
            "        3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03,\n",
            "        3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03,\n",
            "        3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03,\n",
            "        3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03,\n",
            "        3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1680e+03, 3.1910e+06, 1.8198e+06,\n",
            "        4.3861e+06, 2.3527e-01, 2.9754e-01, 1.8454e-01, 2.2917e+02, 2.2881e+02,\n",
            "        2.2895e+02, 2.2955e+02, 2.3058e+02, 2.3249e+02, 2.3506e+02, 2.3861e+02,\n",
            "        2.4324e+02, 2.4828e+02, 2.5302e+02, 2.5734e+02, 2.6084e+02, 2.6310e+02,\n",
            "        2.6424e+02, 2.6488e+02, 2.6522e+02, 2.3115e+02, 2.3278e+02, 2.3491e+02,\n",
            "        2.3727e+02, 2.3956e+02, 2.4726e+02, 2.5046e+02, 2.5356e+02, 2.5661e+02,\n",
            "        2.5909e+02, 2.4319e+02, 2.4304e+02, 2.4293e+02, 2.4281e+02, 2.3936e+02,\n",
            "        2.4105e+02, 2.4287e+02, 2.4486e+02, 2.4670e+02, 2.3343e+02, 2.3496e+02,\n",
            "        2.3685e+02, 2.3855e+02, 2.3673e+02, 2.3489e+02, 2.4850e+02, 2.5064e+02,\n",
            "        2.5312e+02, 2.5521e+02, 2.5321e+02, 2.5080e+02, 2.3653e+02, 2.3865e+02,\n",
            "        2.4108e+02, 2.4280e+02, 2.4477e+02, 2.4770e+02, 2.5053e+02, 2.4781e+02,\n",
            "        2.4495e+02, 2.4283e+02, 2.4094e+02, 2.3857e+02, 2.3751e+02, 2.4104e+02,\n",
            "        2.4281e+02, 2.4479e+02, 2.4938e+02, 2.4478e+02, 2.4277e+02, 2.4098e+02,\n",
            "        8.3479e+01, 8.9521e+01, 9.6290e+01, 1.0346e+02, 1.1047e+02, 1.1687e+02,\n",
            "        1.2214e+02, 1.2624e+02, 1.2737e+02, 1.2613e+02, 1.2208e+02, 1.1678e+02,\n",
            "        1.1045e+02, 1.0321e+02, 9.5696e+01, 8.8567e+01, 8.2334e+01, 7.7319e+01,\n",
            "        7.5362e+01, 7.4621e+01, 7.4761e+01, 7.5397e+01, 7.5154e+01, 7.4310e+01,\n",
            "        7.4118e+01, 7.4647e+01, 7.6249e+01, 7.9606e+01, 8.3317e+01, 8.7378e+01,\n",
            "        9.1893e+01, 9.5266e+01, 9.6251e+01, 9.7058e+01, 9.6136e+01, 9.5121e+01,\n",
            "        8.1565e+01, 8.0281e+01, 8.0075e+01, 8.1042e+01, 8.1832e+01, 8.2077e+01,\n",
            "        8.0728e+01, 7.9648e+01, 7.9795e+01, 8.0846e+01, 8.1464e+01, 8.1370e+01,\n",
            "        1.0617e+02, 1.0364e+02, 1.0258e+02, 1.0323e+02, 1.0251e+02, 1.0350e+02,\n",
            "        1.0556e+02, 1.0965e+02, 1.1139e+02, 1.1179e+02, 1.1152e+02, 1.0993e+02,\n",
            "        1.0623e+02, 1.0527e+02, 1.0544e+02, 1.0510e+02, 1.0582e+02, 1.0741e+02,\n",
            "        1.0780e+02, 1.0754e+02, 2.2236e+02, 2.2223e+02, 2.2236e+02, 2.2239e+02,\n",
            "        2.2172e+02, 2.2055e+02, 2.1876e+02, 2.1680e+02, 2.1659e+02, 2.1808e+02,\n",
            "        2.2081e+02, 2.2318e+02, 2.2461e+02, 2.2520e+02, 2.2528e+02, 2.2542e+02,\n",
            "        2.2587e+02, 2.1657e+02, 2.1571e+02, 2.1497e+02, 2.1423e+02, 2.1373e+02,\n",
            "        2.1452e+02, 2.1560e+02, 2.1685e+02, 2.1806e+02, 2.1921e+02, 2.1382e+02,\n",
            "        2.1266e+02, 2.1147e+02, 2.1035e+02, 2.1265e+02, 2.1232e+02, 2.1215e+02,\n",
            "        2.1265e+02, 2.1326e+02, 2.1580e+02, 2.1532e+02, 2.1531e+02, 2.1536e+02,\n",
            "        2.1514e+02, 2.1515e+02, 2.1638e+02, 2.1666e+02, 2.1714e+02, 2.1791e+02,\n",
            "        2.1700e+02, 2.1652e+02, 2.1520e+02, 2.1320e+02, 2.1246e+02, 2.1247e+02,\n",
            "        2.1281e+02, 2.1421e+02, 2.1648e+02, 2.1443e+02, 2.1305e+02, 2.1265e+02,\n",
            "        2.1263e+02, 2.1342e+02, 2.1490e+02, 2.1276e+02, 2.1275e+02, 2.1312e+02,\n",
            "        2.1595e+02, 2.1323e+02, 2.1284e+02, 2.1288e+02, 1.2210e+02, 1.2275e+02,\n",
            "        1.2349e+02, 1.2419e+02, 1.2447e+02, 1.2428e+02, 1.2353e+02, 1.2241e+02,\n",
            "        1.2196e+02, 1.2232e+02, 1.2315e+02, 1.2359e+02, 1.2342e+02, 1.2280e+02,\n",
            "        1.2197e+02, 1.2121e+02, 1.2065e+02, 1.1921e+02, 1.1861e+02, 1.1811e+02,\n",
            "        1.1768e+02, 1.1734e+02, 1.1718e+02, 1.1732e+02, 1.1755e+02, 1.1783e+02,\n",
            "        1.1817e+02, 1.1749e+02, 1.1730e+02, 1.1708e+02, 1.1686e+02, 1.1810e+02,\n",
            "        1.1791e+02, 1.1776e+02, 1.1778e+02, 1.1785e+02, 1.1912e+02, 1.1876e+02,\n",
            "        1.1855e+02, 1.1839e+02, 1.1854e+02, 1.1876e+02, 1.1810e+02, 1.1812e+02,\n",
            "        1.1818e+02, 1.1834e+02, 1.1816e+02, 1.1810e+02, 1.2026e+02, 1.1898e+02,\n",
            "        1.1839e+02, 1.1830e+02, 1.1828e+02, 1.1876e+02, 1.1974e+02, 1.1922e+02,\n",
            "        1.1888e+02, 1.1886e+02, 1.1899e+02, 1.1946e+02, 1.2003e+02, 1.1868e+02,\n",
            "        1.1855e+02, 1.1857e+02, 1.1958e+02, 1.1872e+02, 1.1870e+02, 1.1883e+02,\n",
            "        4.5347e+02, 4.5331e+02, 4.5311e+02, 4.5299e+02, 4.5318e+02, 4.5342e+02,\n",
            "        4.5365e+02, 4.5378e+02, 4.5393e+02, 4.5400e+02, 4.5407e+02, 4.5408e+02,\n",
            "        4.5426e+02, 4.5450e+02, 4.5472e+02, 4.5482e+02, 4.5481e+02, 4.5340e+02,\n",
            "        4.5335e+02, 4.5345e+02, 4.5352e+02, 4.5364e+02, 4.5389e+02, 4.5389e+02,\n",
            "        4.5407e+02, 4.5437e+02, 4.5465e+02, 4.5380e+02, 4.5389e+02, 4.5399e+02,\n",
            "        4.5411e+02, 4.5380e+02, 4.5387e+02, 4.5395e+02, 4.5400e+02, 4.5402e+02,\n",
            "        4.5341e+02, 4.5344e+02, 4.5348e+02, 4.5358e+02, 4.5348e+02, 4.5344e+02,\n",
            "        4.5395e+02, 4.5399e+02, 4.5412e+02, 4.5422e+02, 4.5414e+02, 4.5403e+02,\n",
            "        4.5371e+02, 4.5388e+02, 4.5396e+02, 4.5404e+02, 4.5411e+02, 4.5415e+02,\n",
            "        4.5413e+02, 4.5414e+02, 4.5408e+02, 4.5407e+02, 4.5402e+02, 4.5391e+02,\n",
            "        4.5379e+02, 4.5395e+02, 4.5401e+02, 4.5409e+02, 4.5413e+02, 4.5405e+02,\n",
            "        4.5399e+02, 4.5394e+02, 5.4231e-01, 1.9112e-01, 2.3744e-01, 1.6087e-01,\n",
            "        2.4325e+02, 9.3702e+01, 1.9862e+01, 1.7116e+01, 9.6002e+00, 1.3005e+01,\n",
            "        9.1706e+00, 8.2138e+00, 7.8160e+00, 7.3517e+00, 7.0737e+00, 5.8543e+00,\n",
            "        5.6557e+00, 3.6732e+00, 3.4367e+00, 3.4314e+00, 3.4688e+00, 3.0298e+00,\n",
            "        2.9997e+00, 2.8139e+00, 2.7437e+00, 2.2286e+00, 1.9444e+00, 1.8458e+00,\n",
            "        1.7822e+00, 1.6451e+00, 1.4076e+00, 1.0462e+00, 7.9869e-01, 4.7027e-01,\n",
            "        2.7516e-01, 3.1820e-01, 2.3856e-01, 2.3916e-01, 1.6296e-01, 1.9472e-01,\n",
            "        5.4489e-01, 3.4167e-01, 6.4274e-01, 2.0140e-01, 4.6478e-01, 7.5394e-01,\n",
            "        1.8383e-01, 6.1933e-01, 5.1408e-01, 5.2879e-01, 3.4846e-01, 5.3403e-01,\n",
            "        2.4035e-01, 3.1693e-01, 5.5030e-01, 5.3172e-01, 4.2386e-01, 3.9273e-01,\n",
            "        4.0457e-01, 4.2970e-01, 4.6596e-01, 3.7995e-01, 4.4313e-01, 2.1775e-01,\n",
            "        4.4366e-01, 3.7400e-01, 4.4226e-01, 3.3405e-01, 3.9167e-01, 2.7114e-01,\n",
            "        3.5070e-01, 3.6047e-01, 3.1482e-01, 8.6444e-02, 3.6269e-01]) \n",
            "\n",
            "Audio mean: tensor([ 1.7323e+02,  6.7178e-01,  7.4609e-02,  2.8545e-01,  5.6938e-01,\n",
            "         3.3358e-01,  1.1886e-01, -3.1350e-01,  1.5326e+00,  5.0598e-01,\n",
            "         2.7302e-01, -7.4503e+00,  2.1175e+00, -4.5268e-02,  3.2577e-01,\n",
            "        -1.6768e-01, -1.0963e-01, -1.1227e-01, -3.3717e-02, -1.3476e-03,\n",
            "         4.1813e-02, -3.4720e-02,  3.1181e-02, -5.1555e-02,  4.0176e-02,\n",
            "        -4.3049e-02,  1.2073e-02, -1.7006e-02,  3.0337e-02, -2.4277e-02,\n",
            "         2.2335e-02, -9.7226e-03,  1.5033e-02, -1.4828e-02,  1.5835e-02,\n",
            "        -1.3404e-02, -1.2921e-04,  3.6037e-04,  4.2836e-04,  7.8571e-04,\n",
            "         5.1980e-04,  6.0838e-04,  1.3466e-03,  2.6785e-03,  8.7485e-03,\n",
            "         2.7719e-02,  8.4391e-02,  1.9479e-01,  3.4923e-01,  4.6635e-01,\n",
            "         5.1773e-01,  5.3307e-01,  5.6334e-01,  5.8892e-01,  6.0585e-01,\n",
            "         6.2406e-01,  6.1672e-01,  6.2502e-01,  6.1352e-01,  4.5734e-01,\n",
            "         3.7870e-01, -3.8707e-01, -1.2675e+00, -1.0304e+00, -9.7422e-01,\n",
            "        -8.2873e-01, -6.9666e-01, -5.9691e-01, -4.7315e-01, -3.8109e-01,\n",
            "        -2.8874e-01, -2.0663e-01, -1.4446e-01, -8.3217e-02]) \n",
            "\n",
            "Audio std: tensor([5.7649e+01, 3.1203e-01, 4.2752e-02, 1.5808e-01, 4.6557e+00, 1.7324e-01,\n",
            "        1.9759e-02, 8.9023e-02, 2.6334e-01, 7.4933e-02, 1.2538e-01, 1.1682e+00,\n",
            "        7.5997e-01, 5.5894e-01, 4.0593e-01, 2.9440e-01, 2.6754e-01, 2.2260e-01,\n",
            "        1.9407e-01, 1.6678e-01, 1.4285e-01, 1.2652e-01, 1.2200e-01, 1.1475e-01,\n",
            "        1.0206e-01, 9.6711e-02, 9.0447e-02, 8.2917e-02, 7.6071e-02, 7.4187e-02,\n",
            "        6.7952e-02, 6.2973e-02, 6.1021e-02, 5.7577e-02, 5.4391e-02, 5.0007e-02,\n",
            "        4.8514e-02, 6.1278e-02, 5.9698e-02, 6.0904e-02, 6.2007e-02, 6.1920e-02,\n",
            "        6.5750e-02, 8.1040e-02, 1.5489e-01, 3.9837e-01, 7.6440e-01, 1.0495e+00,\n",
            "        1.2506e+00, 1.3388e+00, 1.3800e+00, 1.4079e+00, 1.4024e+00, 1.3843e+00,\n",
            "        1.3642e+00, 1.3552e+00, 1.3576e+00, 1.3527e+00, 1.3452e+00, 1.3737e+00,\n",
            "        1.3853e+00, 2.5432e-01, 3.4422e-01, 2.7778e-01, 2.1628e-01, 1.5153e-01,\n",
            "        1.1659e-01, 1.0925e-01, 1.3488e-01, 1.5907e-01, 1.8183e-01, 1.8671e-01,\n",
            "        1.8859e-01, 1.7933e-01]) \n",
            "\n",
            "Text mean: tensor([-2.7277e-02,  1.4076e-01, -1.7856e-01, -4.5181e-02,  9.1255e-02,\n",
            "        -1.3859e-02, -1.3479e-02, -9.8297e-02,  1.8515e-02,  2.2463e+00,\n",
            "        -1.8693e-01,  7.1676e-03,  7.5048e-02, -5.3728e-02, -9.3505e-02,\n",
            "        -7.9782e-02, -7.4434e-02,  1.0107e+00, -2.1226e-01, -3.1709e-02,\n",
            "         2.1994e-02, -4.6905e-02, -4.0183e-02, -3.3894e-02, -1.3456e-02,\n",
            "         3.0154e-02, -5.3274e-02, -7.5907e-02,  3.1476e-02, -8.0673e-02,\n",
            "        -4.3860e-02,  1.1132e-01, -2.1327e-02,  4.7636e-02,  4.0878e-02,\n",
            "        -5.9605e-02,  6.6571e-03,  2.8294e-02, -7.2110e-02, -6.8768e-02,\n",
            "        -1.6225e-02,  9.6370e-02, -2.2624e-02, -7.4763e-02,  6.1348e-02,\n",
            "         6.6704e-02, -1.1853e-01, -4.3948e-02, -1.4062e-03,  1.6929e-02,\n",
            "        -6.5129e-02,  3.1107e-02, -6.3492e-03, -2.2479e-02,  9.0164e-02,\n",
            "         5.3534e-03, -2.8999e-02, -9.8716e-02,  2.5792e-03, -6.7914e-02,\n",
            "        -2.3134e-02, -7.0929e-02, -9.7360e-02,  1.6683e-01,  8.3494e-02,\n",
            "        -9.5869e-02, -3.3630e-02,  9.0674e-02,  6.9141e-02,  7.2721e-02,\n",
            "         8.6920e-02,  5.4973e-02,  1.9810e-01, -4.4801e-02,  9.2552e-02,\n",
            "         2.9755e-02,  9.0440e-02, -6.7314e-02, -4.2648e-02,  1.9838e-01,\n",
            "         2.6199e-02,  7.3067e-02, -1.4724e-01, -1.8070e-02,  6.3422e-02,\n",
            "        -1.6445e-01, -5.9833e-02, -1.4209e-01,  2.3354e-01,  1.0120e-02,\n",
            "        -1.4811e-01,  2.8204e-03, -8.2391e-02,  6.3155e-02,  9.9578e-02,\n",
            "         3.7182e-02,  8.4580e-03, -6.7229e-02, -2.2934e-03, -6.8140e-03,\n",
            "        -2.6021e-02,  1.3427e-02, -5.8804e-02, -5.3342e-02,  1.2957e-01,\n",
            "        -8.6773e-01,  9.6034e-02, -2.4992e-03, -2.8015e-02, -2.5807e-02,\n",
            "         3.4399e-02, -1.5694e-01,  8.1329e-02, -6.1499e-02,  5.1179e-02,\n",
            "        -2.3407e-02,  5.0036e-03,  6.0299e-02, -3.3222e-02,  1.0674e-02,\n",
            "         7.0035e-02, -7.8510e-02, -1.3352e-02, -1.8878e-02,  6.6021e-02,\n",
            "         7.0258e-02, -3.6764e-02, -1.4313e-01,  1.4891e-02, -4.4284e-03,\n",
            "        -1.7143e-02, -1.4558e-02, -7.9719e-02,  5.1058e-02,  1.0195e-01,\n",
            "         5.3924e-03, -2.9111e-02, -1.6416e-02, -6.8813e-03, -4.1634e-02,\n",
            "        -1.2959e+00,  4.9159e-02,  9.4269e-02,  8.6434e-03,  4.7578e-03,\n",
            "        -1.0260e-01, -6.6472e-02,  3.8071e-02,  1.7341e-02, -4.5816e-02,\n",
            "        -2.4536e-02,  2.0037e-02,  5.9020e-02, -2.7001e-02, -5.9008e-02,\n",
            "        -2.4417e-02, -4.5932e-02, -4.3730e-02, -6.2413e-02, -1.0587e-01,\n",
            "        -2.9245e-02,  3.6472e-02, -5.8176e-02, -1.7318e-02, -4.9010e-02,\n",
            "        -1.4402e-01,  8.5509e-02, -3.0621e-02,  1.3801e-01, -1.6895e-02,\n",
            "        -2.9416e-02, -2.8247e-02,  1.2295e-01, -8.7804e-02, -5.9783e-02,\n",
            "         5.5347e-02, -5.8057e-02,  2.3747e-02,  1.6856e-02, -7.0119e-03,\n",
            "         3.7290e-02, -3.9671e-02, -1.0742e-01, -6.6743e-02, -4.0791e-02,\n",
            "         5.2719e-03, -7.2085e-02, -6.5211e-02,  4.1840e-02,  5.1262e-02,\n",
            "         1.2214e-03, -2.0030e-02, -1.3452e-01,  1.9459e-02,  3.9977e-02,\n",
            "         1.2063e-01, -2.3704e-02, -6.6921e-02,  1.4035e-02,  1.4682e-01,\n",
            "        -1.6773e-02, -8.1561e-02, -8.7074e-02, -2.3373e-02,  1.5112e-01,\n",
            "         7.8254e-02,  5.3375e-02,  1.6259e-02,  6.0626e-02,  3.5956e-02,\n",
            "        -8.3810e-02, -4.2310e-02, -4.6122e-02, -1.6022e-01,  2.6829e-02,\n",
            "         1.4369e-01, -4.8175e-02, -2.7616e-03, -1.5672e-01, -1.6639e-02,\n",
            "         2.5582e-02, -1.9751e-02, -5.9867e-02,  7.7729e-03, -6.2505e-03,\n",
            "        -2.3907e-02, -2.1408e-02,  1.2028e-01, -8.6383e-03, -1.2969e-02,\n",
            "        -1.3552e-01,  3.6385e-02,  6.8279e-02,  1.0123e-01, -4.5764e-02,\n",
            "        -7.2249e-02,  2.0102e-02, -1.0071e-01, -1.0645e-01,  1.1498e-01,\n",
            "         7.0320e-02,  3.2529e-02,  2.6989e-02,  1.0831e-01,  1.3137e-01,\n",
            "        -1.6569e-01, -7.7457e-02, -9.0870e-02, -1.2457e-01,  1.1481e-01,\n",
            "         3.7219e-02, -8.3122e-02, -3.8637e-02, -2.1561e-02,  1.7692e-02,\n",
            "         1.8969e-01,  9.3206e-02, -4.7446e-02, -3.8265e-02,  4.5288e-02,\n",
            "         1.3448e-01,  1.4153e-01,  5.3679e-03,  7.5004e-02,  1.2055e-01,\n",
            "        -5.6661e-02, -2.0792e-02,  8.1073e-02,  3.5421e-01,  4.8444e-02,\n",
            "         6.7217e-02, -5.5156e-02, -1.0291e-01, -1.3353e-01, -6.3185e-02,\n",
            "         1.5480e-02,  9.9560e-03,  5.9181e-02,  5.2995e-02,  1.8023e-01,\n",
            "         1.1554e-01,  5.2103e-02, -3.2523e-02, -2.8610e-02, -2.6668e-02,\n",
            "        -8.1234e-02,  1.4016e-01, -6.8671e-02,  8.9981e-02, -5.9044e-02,\n",
            "        -2.0688e-01,  3.9524e-02,  1.2770e-03, -7.3949e-02,  6.3366e-02,\n",
            "        -2.6368e-02, -6.5686e-02, -6.3952e-02,  6.1373e-02,  1.0639e-01]) \n",
            "\n",
            "Text std: tensor([0.2559, 0.2523, 0.2555, 0.2639, 0.2545, 0.2342, 0.2264, 0.3022, 0.2108,\n",
            "        0.8692, 0.3030, 0.2276, 0.2566, 0.2194, 0.2494, 0.2160, 0.2190, 0.6523,\n",
            "        0.2470, 0.2249, 0.2472, 0.2434, 0.2571, 0.2354, 0.2335, 0.2235, 0.2450,\n",
            "        0.2437, 0.2749, 0.2732, 0.2263, 0.2643, 0.2555, 0.2395, 0.2692, 0.2487,\n",
            "        0.2451, 0.2378, 0.2437, 0.2811, 0.2354, 0.2568, 0.2345, 0.2519, 0.2207,\n",
            "        0.2332, 0.2293, 0.2897, 0.2420, 0.2168, 0.2656, 0.2466, 0.2235, 0.2174,\n",
            "        0.2680, 0.2070, 0.2155, 0.2563, 0.2503, 0.2109, 0.2339, 0.2690, 0.2473,\n",
            "        0.2686, 0.2497, 0.2666, 0.2086, 0.2305, 0.2456, 0.2521, 0.2391, 0.2596,\n",
            "        0.2727, 0.2135, 0.2773, 0.2398, 0.2330, 0.2481, 0.2671, 0.2725, 0.2134,\n",
            "        0.2409, 0.2547, 0.2217, 0.2305, 0.2816, 0.5356, 0.4392, 0.2882, 0.2435,\n",
            "        0.2506, 0.2387, 0.2471, 0.2706, 0.2672, 0.2808, 0.2439, 0.2212, 0.2450,\n",
            "        0.2619, 0.2362, 0.2453, 0.2265, 0.2016, 0.2506, 0.4984, 0.2490, 0.2474,\n",
            "        0.2673, 0.2614, 0.2124, 0.2853, 0.2463, 0.2333, 0.2282, 0.2469, 0.2441,\n",
            "        0.2929, 0.2604, 0.2267, 0.2323, 0.2470, 0.2510, 0.2540, 0.2701, 0.2274,\n",
            "        0.2304, 0.2864, 0.2230, 0.2124, 0.2462, 0.2492, 0.2477, 0.2552, 0.2544,\n",
            "        0.2272, 0.2242, 0.2660, 0.2212, 0.2357, 0.8230, 0.2612, 0.2716, 0.2402,\n",
            "        0.2282, 0.2382, 0.2696, 0.2334, 0.2903, 0.2499, 0.2358, 0.2330, 0.2290,\n",
            "        0.2174, 0.2335, 0.2518, 0.2647, 0.2623, 0.2167, 0.2658, 0.2670, 0.2381,\n",
            "        0.2239, 0.2483, 0.3111, 0.2389, 0.2312, 0.2332, 0.2298, 0.2033, 0.2355,\n",
            "        0.2163, 0.2751, 0.2684, 0.2498, 0.2199, 0.2234, 0.2391, 0.2565, 0.2783,\n",
            "        0.2054, 0.2433, 0.2598, 0.2314, 0.2369, 0.2349, 0.2097, 0.2586, 0.2351,\n",
            "        0.2475, 0.2743, 0.2013, 0.2576, 0.2636, 0.2375, 0.2784, 0.2576, 0.2644,\n",
            "        0.2750, 0.2690, 0.2481, 0.2402, 0.2264, 0.2385, 0.2762, 0.2106, 0.2088,\n",
            "        0.2127, 0.2486, 0.2385, 0.2432, 0.2919, 0.2451, 0.2683, 0.2603, 0.2832,\n",
            "        0.2678, 0.2560, 0.3023, 0.2388, 0.2300, 0.2204, 0.2174, 0.2525, 0.2307,\n",
            "        0.2481, 0.2285, 0.2178, 0.2366, 0.2625, 0.2219, 0.2132, 0.2562, 0.2300,\n",
            "        0.2724, 0.2144, 0.2433, 0.2412, 0.2272, 0.2264, 0.2526, 0.2145, 0.2578,\n",
            "        0.2511, 0.2379, 0.2604, 0.2964, 0.2625, 0.2452, 0.3149, 0.2191, 0.2449,\n",
            "        0.2657, 0.2050, 0.2317, 0.3384, 0.2386, 0.2497, 0.2435, 0.2346, 0.2847,\n",
            "        0.2313, 0.2569, 0.2502, 0.2460, 0.3365, 0.2186, 0.2468, 0.3951, 0.3071,\n",
            "        0.3912, 0.2173, 0.2281, 0.2886, 0.2220, 0.2237, 0.2234, 0.2736, 0.2584,\n",
            "        0.2671, 0.2716, 0.2446, 0.2576, 0.2372, 0.2125, 0.2353, 0.2481, 0.2217,\n",
            "        0.2274, 0.2697, 0.2956, 0.2133, 0.2536, 0.2387, 0.2592, 0.2486, 0.2432,\n",
            "        0.2409, 0.2533, 0.2495])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization function\n",
        "def z_score_standardize(data_loader, video_mean, video_std, audio_mean, audio_std, text_mean, text_std):\n",
        "    standardized_data = []\n",
        "    for video, audio, text, label in data_loader:\n",
        "        # Standardize each modality\n",
        "        video = (video - video_mean) / video_std\n",
        "        audio = (audio - audio_mean) / audio_std\n",
        "        text = (text - text_mean) / text_std\n",
        "\n",
        "        # Append standardized data\n",
        "        standardized_data.append([video, audio, text, label])\n",
        "    return standardized_data\n",
        "\n",
        "# Standardize each dataset\n",
        "s_traindata = z_score_standardize(traindata, video_mean, video_std, audio_mean, audio_std, text_mean, text_std)\n",
        "s_validdata = z_score_standardize(validdata, video_mean, video_std, audio_mean, audio_std, text_mean, text_std)\n",
        "s_testdata = z_score_standardize(testdata, video_mean, video_std, audio_mean, audio_std, text_mean, text_std)"
      ],
      "metadata": {
        "id": "P7Obnse8OlKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "NCtHmEHAiwg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_data_path = '/content/drive/MyDrive/data'\n",
        "\n",
        "train_file = os.path.join(save_data_path, 's_traindata.pkl')\n",
        "valid_file = os.path.join(save_data_path, 's_validdata.pkl')\n",
        "test_file = os.path.join(save_data_path, 's_testdata.pkl')"
      ],
      "metadata": {
        "id": "y11qawY7kHdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(dataset, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(dataset, f)\n",
        "\n",
        "# Save the datasets\n",
        "save(s_traindata, train_file)\n",
        "save(s_validdata, valid_file)\n",
        "save(s_testdata, test_file)"
      ],
      "metadata": {
        "id": "cFg1gD5jir9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unimodels"
      ],
      "metadata": {
        "id": "Js3fQrPIeDuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "0ZiVsYaF0SpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# access my drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIdVlfuxeqZs",
        "outputId": "56a3eaad-c628-4abd-dbb6-b57fff009bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save(dataset, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(dataset, f)\n",
        "\n",
        "def load(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "save_data_path = '/content/drive/MyDrive/data'\n",
        "train_file = os.path.join(save_data_path, 's_traindata.pkl')\n",
        "valid_file = os.path.join(save_data_path, 's_validdata.pkl')\n",
        "test_file = os.path.join(save_data_path, 's_testdata.pkl')\n",
        "\n",
        "# load dataloaders\n",
        "traindata = load(train_file)\n",
        "validdata = load(valid_file)\n",
        "testdata = load(test_file)"
      ],
      "metadata": {
        "id": "gU3jY5Qu7MPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UniModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, attention_dim, sentiment_out_dim=1, emotion_out_dim=6, dropout_rate=0.3):\n",
        "        super(UniModel, self).__init__()\n",
        "\n",
        "        # Encoder: non-linear transformation to map to same dimension (256)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "\n",
        "        # Pooling: Scaled Dot-Product Attention\n",
        "        self.query = nn.Linear(hidden_dim, attention_dim)\n",
        "        self.key = nn.Linear(hidden_dim, attention_dim)\n",
        "        self.value = nn.Linear(hidden_dim, attention_dim)\n",
        "        # Dropout for attention output\n",
        "        self.attention_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Decoders\n",
        "        # Sentiment Decoder (Shallow MLP: 2 layers)\n",
        "        self.sentiment_decoder = nn.Sequential(\n",
        "            nn.Linear(attention_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(128, sentiment_out_dim)\n",
        "        )\n",
        "\n",
        "        # Emotion Decoder (Deeper MLP: 3 layers)\n",
        "        self.emotion_decoder = nn.Sequential(\n",
        "            nn.Linear(attention_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(64, emotion_out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, batch):\n",
        "        # Encoder\n",
        "        batch_encoded = self.encoder(batch)\n",
        "\n",
        "        # Scaled Dot-Product Attention\n",
        "        Q = self.query(batch_encoded)  # Query\n",
        "        K = self.key(batch_encoded)   # Key\n",
        "        V = self.value(batch_encoded) # Value\n",
        "\n",
        "        # Compute attention scores between sequence elements using dot product\n",
        "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(Q.shape[-1], dtype=torch.float32))\n",
        "        # Normalize the scores into attention weights using softmax\n",
        "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "        # Compute a weighted sum of value vectors (V) based on the attention weights\n",
        "        attended_features = torch.matmul(attention_weights, V)\n",
        "\n",
        "        # Pool the attended features to create a fixed-size sequence representation\n",
        "        pooled_features = attended_features.mean(dim=1)\n",
        "        # Apply attention dropout\n",
        "        pooled_features = self.attention_dropout(pooled_features)  # Average pooling after attention\n",
        "\n",
        "        # Decoders\n",
        "        sentiment_output = self.sentiment_decoder(pooled_features)\n",
        "        emotion_output = self.emotion_decoder(pooled_features)\n",
        "\n",
        "        return sentiment_output, emotion_output"
      ],
      "metadata": {
        "id": "f6yRRL-feHfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function with uncertainty-based weighting\n",
        "class MultitaskLossWithUncertainty(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultitaskLossWithUncertainty, self).__init__()\n",
        "        # Create learnable parameters (learn log values to ensure numerical stability and avoid negative values of sigma)\n",
        "        self.log_sigma_sentiment = nn.Parameter(torch.tensor(0.0))\n",
        "        self.log_sigma_emotion = nn.Parameter(torch.tensor(0.0))\n",
        "\n",
        "    def forward(self, sentiment_loss, emotion_loss):\n",
        "        # Calculate weight for each task loss\n",
        "        sentiment_weight = torch.exp(-self.log_sigma_sentiment)\n",
        "        emotion_weight = torch.exp(-self.log_sigma_emotion)\n",
        "\n",
        "        # # Clip log_sigma values to prevent instability\n",
        "        # self.log_sigma_sentiment.data = torch.clamp(self.log_sigma_sentiment.data, -5, 5)\n",
        "        # self.log_sigma_emotion.data = torch.clamp(self.log_sigma_emotion.data, -5, 5)\n",
        "\n",
        "        # Calculate total loss, where each task loss is scaled by its corresponding weight\n",
        "        # The log terms act as regularizers, preventing sigma from growing too large and trivializing the task\n",
        "        loss = (\n",
        "            sentiment_weight * sentiment_loss +  # scale sentiment weight\n",
        "            emotion_weight * emotion_loss +\n",
        "            0.1 * (self.log_sigma_sentiment + self.log_sigma_emotion)  # scale down regularization\n",
        "        )\n",
        "        return loss"
      ],
      "metadata": {
        "id": "Vns-fpb-wIeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-compute mean MSE losses for sentiment and emotion task across train dataset. This is for loss normalization\n",
        "def uni_mean_losses(model, train_loader, modality):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Mapping modality to the corresponding index in the dataloader's output\n",
        "    modality_indices = {'video': 0, 'audio': 1, 'text': 2}\n",
        "    modality_index = modality_indices[modality]\n",
        "\n",
        "    total_sentiment_loss = 0.0\n",
        "    total_emotion_loss = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch in tqdm(train_loader, desc=f\"Pre-training ({modality})\", leave=False):\n",
        "            # Extract modality and labels\n",
        "            inputs = batch[modality_index]\n",
        "            labels = batch[3]\n",
        "            sentiment_targets = labels[:, 0]\n",
        "            emotion_targets = labels[:, 1:]\n",
        "\n",
        "            # Move data to the appropriate device\n",
        "            inputs = inputs.to(device)\n",
        "            sentiment_targets = sentiment_targets.to(device)\n",
        "            emotion_targets = emotion_targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            sentiment_preds, emotion_preds = model(inputs)\n",
        "\n",
        "            # Compute losses for the batch\n",
        "            sentiment_loss = F.mse_loss(sentiment_preds.squeeze(), sentiment_targets, reduction='sum')  # Sum across batch\n",
        "            emotion_loss = F.mse_loss(emotion_preds, emotion_targets, reduction='sum')  # Sum across batch\n",
        "\n",
        "            # Accumulate losses\n",
        "            total_sentiment_loss += sentiment_loss.item()\n",
        "            total_emotion_loss += emotion_loss.item()\n",
        "            total_batches += inputs.size(0)  # Count the number of samples in the batch\n",
        "\n",
        "    # Compute mean losses\n",
        "    mean_sentiment_loss = total_sentiment_loss / total_batches\n",
        "    mean_emotion_loss = total_emotion_loss / total_batches\n",
        "\n",
        "    return mean_sentiment_loss, mean_emotion_loss"
      ],
      "metadata": {
        "id": "wYaSUjtbw7CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def uni_avg_mean_losses(traindata, input_dim, hidden_dim, attention_dim, modality):\n",
        "    mean_sentiment_losses = []\n",
        "    mean_emotion_losses = []\n",
        "\n",
        "    for _ in range(5):\n",
        "        model = UniModel(input_dim, hidden_dim, attention_dim)\n",
        "        mean_sentiment_loss, mean_emotion_loss = uni_mean_losses(model, traindata, modality)\n",
        "        mean_sentiment_losses.append(mean_sentiment_loss)\n",
        "        mean_emotion_losses.append(mean_emotion_loss)\n",
        "\n",
        "    final_mean_sentiment_loss = sum(mean_sentiment_losses) / len(mean_sentiment_losses)\n",
        "    final_mean_emotion_loss = sum(mean_emotion_losses) / len(mean_emotion_losses)\n",
        "\n",
        "    return final_mean_sentiment_loss, final_mean_emotion_loss"
      ],
      "metadata": {
        "id": "wz1F_SeAj0Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train function for all uni models\n",
        "# modality: 'text', 'video', 'audio'\n",
        "def uni_train_model(model, train_loader, val_loader, epochs, optimizer, scheduler, loss_fn, save_path, modality, mean_sentiment_loss, mean_emotion_loss):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # Move model and loss function to appropriate device\n",
        "    model.to(device)\n",
        "    loss_fn.to(device)\n",
        "\n",
        "    # Mapping modality to the corresponding index in the dataloader's output\n",
        "    modality_indices = {'video': 0, 'audio': 1, 'text': 2}\n",
        "    modality_index = modality_indices[modality]\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    training_times = []\n",
        "    train_losses, val_losses = [], []\n",
        "    train_sentiment_losses, val_sentiment_losses = [], []\n",
        "    train_emotion_losses, val_emotion_losses = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")  # Start from 1\n",
        "\n",
        "        # Training mode\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        epoch_train_sentiment_loss = 0\n",
        "        epoch_train_emotion_loss = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Training ({modality})\", leave=False):\n",
        "            # Extract modality and labels\n",
        "            inputs = batch[modality_index]\n",
        "            labels = batch[3]\n",
        "            sentiment_targets = labels[:, 0]  # Sentiment is the first column\n",
        "            emotion_targets = labels[:, 1:]  # Emotions are the remaining columns\n",
        "\n",
        "            # Move data to the appropriate device\n",
        "            inputs = inputs.to(device)\n",
        "            sentiment_targets = sentiment_targets.to(device)\n",
        "            emotion_targets = emotion_targets.to(device)\n",
        "\n",
        "            # Forward pass (compute predictions)\n",
        "            sentiment_preds, emotion_preds = model(inputs)\n",
        "            sentiment_loss = F.mse_loss(sentiment_preds.squeeze(), sentiment_targets) / mean_sentiment_loss\n",
        "            emotion_loss = F.mse_loss(emotion_preds, emotion_targets) / mean_emotion_loss\n",
        "            loss = loss_fn(sentiment_loss, emotion_loss)\n",
        "\n",
        "            # clears the gradients of all model parameters before the next backward pass\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Backward pass (update gradient)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss += loss.item()\n",
        "            epoch_train_sentiment_loss += sentiment_loss.item()\n",
        "            epoch_train_emotion_loss += emotion_loss.item()\n",
        "\n",
        "        end_time = time.time()\n",
        "        avg_batch_time = (end_time - start_time) / len(train_loader)\n",
        "        training_times.append(avg_batch_time)\n",
        "\n",
        "        # Validation mode\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0\n",
        "        epoch_val_sentiment_loss = 0\n",
        "        epoch_val_emotion_loss = 0\n",
        "        with torch.no_grad():  # disable gradients in validation mode\n",
        "            for batch in tqdm(val_loader, desc=f\"Validation ({modality})\", leave=False):\n",
        "                # Extract modality and labels\n",
        "                inputs = batch[modality_index]\n",
        "                labels = batch[3]\n",
        "                sentiment_targets = labels[:, 0]\n",
        "                emotion_targets = labels[:, 1:]\n",
        "\n",
        "                # Move data to the appropriate device\n",
        "                inputs = inputs.to(device)\n",
        "                sentiment_targets = sentiment_targets.to(device)\n",
        "                emotion_targets = emotion_targets.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                sentiment_preds, emotion_preds = model(inputs)\n",
        "                sentiment_loss = F.mse_loss(sentiment_preds.squeeze(), sentiment_targets) / mean_sentiment_loss\n",
        "                emotion_loss = F.mse_loss(emotion_preds, emotion_targets) / mean_emotion_loss\n",
        "                loss = loss_fn(sentiment_loss, emotion_loss)\n",
        "\n",
        "                epoch_val_loss += loss.item()\n",
        "                epoch_val_sentiment_loss += sentiment_loss.item()\n",
        "                epoch_val_emotion_loss += emotion_loss.item()\n",
        "\n",
        "        # Scheduler step (reduces the learning rate if val loss doesnt improve for a specified number of epochs)\n",
        "        scheduler.step(epoch_val_loss)\n",
        "\n",
        "        # Log epoch results\n",
        "        train_losses.append(epoch_train_loss / len(train_loader))\n",
        "        val_losses.append(epoch_val_loss / len(val_loader))\n",
        "        train_sentiment_losses.append(epoch_train_sentiment_loss / len(train_loader))\n",
        "        val_sentiment_losses.append(epoch_val_sentiment_loss / len(val_loader))\n",
        "        train_emotion_losses.append(epoch_train_emotion_loss / len(train_loader))\n",
        "        val_emotion_losses.append(epoch_val_emotion_loss / len(val_loader))\n",
        "\n",
        "        # debug uncertainty weight\n",
        "        sentiment_weight = torch.exp(-loss_fn.log_sigma_sentiment).item()\n",
        "        emotion_weight = torch.exp(-loss_fn.log_sigma_emotion).item()\n",
        "        train_weighted_sentiment_loss = sentiment_weight * train_sentiment_losses[-1]\n",
        "        train_weighted_emotion_loss = sentiment_weight * train_emotion_losses[-1]\n",
        "        train_regularization = loss_fn.log_sigma_sentiment.item() + loss_fn.log_sigma_emotion.item()\n",
        "        val_weighted_sentiment_loss = sentiment_weight * val_sentiment_losses[-1]\n",
        "        val_weighted_emotion_loss = sentiment_weight * val_emotion_losses[-1]\n",
        "        val_regularization = loss_fn.log_sigma_sentiment.item() + loss_fn.log_sigma_emotion.item()\n",
        "\n",
        "        print(f\"Train Loss: {train_losses[-1]:.4f} | Val Loss: {val_losses[-1]:.4f}\")\n",
        "        print(f\"Train Sentiment Loss: {train_sentiment_losses[-1]:.4f} | Train Emotion Loss: {train_emotion_losses[-1]:.4f}\")\n",
        "        print(f\"Val Sentiment Loss: {val_sentiment_losses[-1]:.4f} | Val Emotion Loss: {val_emotion_losses[-1]:.4f}\")\n",
        "        print(f\"Sentiment Weight: {sentiment_weight:.4f} | Emotion Weight: {emotion_weight:.4f}\")\n",
        "        print(f\"Train Weighted Sentiment Loss: {train_weighted_sentiment_loss:.4f} | Train Weighted Emotion Loss: {train_weighted_emotion_loss:.4f} | Train Regularization: {train_regularization:.4f}\")\n",
        "        print(f\"Val Weighted Sentiment Loss: {val_weighted_sentiment_loss:.4f} | Val Weighted Emotion Loss: {val_weighted_emotion_loss:.4f} | Val Regularization: {val_regularization:.4f}\")\n",
        "        print()\n",
        "\n",
        "        # Early stopping\n",
        "        if val_losses[-1] < best_val_loss:\n",
        "            best_val_loss = val_losses[-1]\n",
        "            epochs_no_improve = 0\n",
        "            # Save the best model\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= 10:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    return {\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses,\n",
        "        \"train_sentiment_losses\": train_sentiment_losses,\n",
        "        \"val_sentiment_losses\": val_sentiment_losses,\n",
        "        \"train_emotion_losses\": train_emotion_losses,\n",
        "        \"val_emotion_losses\": val_emotion_losses,\n",
        "        \"training_times\": training_times\n",
        "    }"
      ],
      "metadata": {
        "id": "N3WQkE1Z2LIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def uni_test_model(model, test_loader, loss_fn, modality, save_path, mean_sentiment_loss, mean_emotion_loss):\n",
        "    # Load the best model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    model.to(device)\n",
        "    loss_fn.to(device)\n",
        "\n",
        "    # Modality index mapping\n",
        "    modality_indices = {'video': 0, 'audio': 1, 'text': 2}\n",
        "    modality_index = modality_indices[modality]\n",
        "\n",
        "    model.eval()\n",
        "    # Initialize accumulators\n",
        "    total_loss = 0\n",
        "    testing_times = []\n",
        "    all_sentiment_preds, all_sentiment_targets = [], []\n",
        "    all_emotion_preds, all_emotion_targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        for batch in tqdm(test_loader, desc=f\"Testing ({modality})\", leave=False):\n",
        "            # Extract modality and labels\n",
        "            inputs = batch[modality_index]\n",
        "            labels = batch[3]  # Labels are the last item in the list\n",
        "            sentiment_targets = labels[:, 0]  # Sentiment is the first column\n",
        "            emotion_targets = labels[:, 1:]  # Emotions are the remaining columns\n",
        "\n",
        "            # Move data to the appropriate device\n",
        "            inputs = inputs.to(device)\n",
        "            sentiment_targets = sentiment_targets.to(device)\n",
        "            emotion_targets = emotion_targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            sentiment_preds, emotion_preds = model(inputs)\n",
        "\n",
        "            # Accumulate predictions and targets for metrics\n",
        "            # (convert PyTorch tensors into NumPy arrays after moving them to the CPU)\n",
        "            all_sentiment_preds.extend(sentiment_preds.squeeze().cpu().numpy())\n",
        "            all_sentiment_targets.extend(sentiment_targets.cpu().numpy())\n",
        "            all_emotion_preds.extend(emotion_preds.cpu().numpy())\n",
        "            all_emotion_targets.extend(emotion_targets.cpu().numpy())\n",
        "\n",
        "            # Compute loss\n",
        "            sentiment_loss = F.mse_loss(sentiment_preds.squeeze(), sentiment_targets) / mean_sentiment_loss\n",
        "            emotion_loss = F.mse_loss(emotion_preds, emotion_targets) / mean_emotion_loss\n",
        "            loss = loss_fn(sentiment_loss, emotion_loss)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        end_time = time.time()\n",
        "        avg_batch_time = (end_time - start_time) / len(test_loader)\n",
        "        testing_times.append(avg_batch_time)\n",
        "\n",
        "    # Convert lists to numpy arrays for metric calculations\n",
        "    all_sentiment_preds = np.array(all_sentiment_preds)\n",
        "    all_sentiment_targets = np.array(all_sentiment_targets)\n",
        "    all_emotion_preds = np.array(all_emotion_preds)\n",
        "    all_emotion_targets = np.array(all_emotion_targets)\n",
        "\n",
        "    # Compute metrics\n",
        "    sentiment_mae = mean_absolute_error(all_sentiment_targets, all_sentiment_preds)\n",
        "    sentiment_pcc, _ = pearsonr(all_sentiment_targets, all_sentiment_preds)\n",
        "    emotion_mae = mean_absolute_error(all_emotion_targets, all_emotion_preds)\n",
        "    emotion_r2 = r2_score(all_emotion_targets, all_emotion_preds)\n",
        "\n",
        "    metrics = {\n",
        "        \"Total Loss\": total_loss / len(test_loader),\n",
        "        \"Total MAE\": (sentiment_mae + emotion_mae) / 2,\n",
        "        \"Sentiment MAE\": sentiment_mae,\n",
        "        \"Sentiment PCC\": sentiment_pcc,\n",
        "        \"Emotion MAE\": emotion_mae,\n",
        "        \"Emotion R\": emotion_r2\n",
        "    }\n",
        "\n",
        "    print(\"\\nTest Metrics:\")\n",
        "    for key, value in metrics.items():\n",
        "        print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "    metrics['Testing Times'] = testing_times\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "2Od0HWGQ3vHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "tG8T-9d3wY_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_path = \"/content/drive/MyDrive/model\"\n",
        "\n",
        "hidden_dim = 256\n",
        "attention_dim = 256\n",
        "\n",
        "loss_fn = MultitaskLossWithUncertainty()"
      ],
      "metadata": {
        "id": "qPteu0hM9T_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input_dim = 300  # GloVe input dimension for text\n",
        "\n",
        "# Compute mean losses in train dataset for text modality\n",
        "text_mean_sentiment_loss, text_mean_emotion_loss = uni_avg_mean_losses(traindata, text_input_dim, hidden_dim, attention_dim, 'text')\n",
        "\n",
        "print(f\"Text Mean Sentiment Loss: {text_mean_sentiment_loss:.4f}\")\n",
        "print(f\"Text Mean Emotion Loss: {text_mean_emotion_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlOboIIbjSJf",
        "outputId": "c731329c-2af0-44e4-c32f-06fa968a61ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mean Sentiment Loss: 1.2773\n",
            "Text Mean Emotion Loss: 1.1008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_model = UniModel(text_input_dim, hidden_dim, attention_dim)\n",
        "# text_optimizer = AdamW([\n",
        "#     {'params': text_model.parameters(), 'lr': 0.001},\n",
        "#     {'params': [loss_fn.log_sigma_sentiment, loss_fn.log_sigma_emotion], 'lr': 0.0001}  # Smaller LR for log_sigma\n",
        "# ], weight_decay=0.01)\n",
        "text_optimizer = AdamW([\n",
        "    {'params': text_model.parameters()},\n",
        "    {'params': [loss_fn.log_sigma_sentiment, loss_fn.log_sigma_emotion]}\n",
        "], lr=0.001, weight_decay=0.01)\n",
        "text_scheduler = ReduceLROnPlateau(text_optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# Save path for the trained model\n",
        "text_model_path = os.path.join(save_model_path, \"text.pth\")"
      ],
      "metadata": {
        "id": "ctce9lDVlv2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for text modality\n",
        "text_train_res = uni_train_model(\n",
        "    text_model, traindata, validdata, epochs=50, optimizer=text_optimizer,\n",
        "    scheduler=text_scheduler, loss_fn=loss_fn, save_path=text_model_path, modality='text',\n",
        "    mean_sentiment_loss=text_mean_sentiment_loss, mean_emotion_loss=text_mean_emotion_loss\n",
        ")\n",
        "\n",
        "save(text_train_res, '/content/drive/MyDrive/model/text_train_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_zGNzizmoN2",
        "outputId": "c23bc19a-2873-49c0-df78-84894536b4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.7854 | Val Loss: 0.6198\n",
            "Train Sentiment Loss: 0.7574 | Train Emotion Loss: 0.1143\n",
            "Val Sentiment Loss: 0.6762 | Val Emotion Loss: 0.0875\n",
            "Sentiment Weight: 0.7417 | Emotion Weight: 0.9433\n",
            "Train Weighted Sentiment Loss: 0.5618 | Train Weighted Emotion Loss: 0.0848 | Train Regularization: 0.3571\n",
            "Val Weighted Sentiment Loss: 0.5016 | Val Weighted Emotion Loss: 0.0649 | Val Regularization: 0.3571\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5852 | Val Loss: 0.4996\n",
            "Train Sentiment Loss: 0.6680 | Train Emotion Loss: 0.1079\n",
            "Val Sentiment Loss: 0.6273 | Val Emotion Loss: 0.0866\n",
            "Sentiment Weight: 0.5664 | Emotion Weight: 0.9499\n",
            "Train Weighted Sentiment Loss: 0.3784 | Train Weighted Emotion Loss: 0.0611 | Train Regularization: 0.6199\n",
            "Val Weighted Sentiment Loss: 0.3553 | Val Weighted Emotion Loss: 0.0491 | Val Regularization: 0.6199\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4862 | Val Loss: 0.4532\n",
            "Train Sentiment Loss: 0.6150 | Train Emotion Loss: 0.1061\n",
            "Val Sentiment Loss: 0.6326 | Val Emotion Loss: 0.0867\n",
            "Sentiment Weight: 0.4535 | Emotion Weight: 0.9614\n",
            "Train Weighted Sentiment Loss: 0.2789 | Train Weighted Emotion Loss: 0.0481 | Train Regularization: 0.8303\n",
            "Val Weighted Sentiment Loss: 0.2869 | Val Weighted Emotion Loss: 0.0393 | Val Regularization: 0.8303\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4399 | Val Loss: 0.4165\n",
            "Train Sentiment Loss: 0.5975 | Train Emotion Loss: 0.1048\n",
            "Val Sentiment Loss: 0.6190 | Val Emotion Loss: 0.0861\n",
            "Sentiment Weight: 0.3744 | Emotion Weight: 0.9734\n",
            "Train Weighted Sentiment Loss: 0.2237 | Train Weighted Emotion Loss: 0.0392 | Train Regularization: 1.0094\n",
            "Val Weighted Sentiment Loss: 0.2317 | Val Weighted Emotion Loss: 0.0322 | Val Regularization: 1.0094\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4087 | Val Loss: 0.3984\n",
            "Train Sentiment Loss: 0.5760 | Train Emotion Loss: 0.1032\n",
            "Val Sentiment Loss: 0.6222 | Val Emotion Loss: 0.0855\n",
            "Sentiment Weight: 0.3190 | Emotion Weight: 0.9866\n",
            "Train Weighted Sentiment Loss: 0.1837 | Train Weighted Emotion Loss: 0.0329 | Train Regularization: 1.1561\n",
            "Val Weighted Sentiment Loss: 0.1985 | Val Weighted Emotion Loss: 0.0273 | Val Regularization: 1.1561\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3955 | Val Loss: 0.3872\n",
            "Train Sentiment Loss: 0.5773 | Train Emotion Loss: 0.1025\n",
            "Val Sentiment Loss: 0.6247 | Val Emotion Loss: 0.0857\n",
            "Sentiment Weight: 0.2772 | Emotion Weight: 0.9966\n",
            "Train Weighted Sentiment Loss: 0.1600 | Train Weighted Emotion Loss: 0.0284 | Train Regularization: 1.2863\n",
            "Val Weighted Sentiment Loss: 0.1732 | Val Weighted Emotion Loss: 0.0237 | Val Regularization: 1.2863\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3818 | Val Loss: 0.3887\n",
            "Train Sentiment Loss: 0.5569 | Train Emotion Loss: 0.1018\n",
            "Val Sentiment Loss: 0.6560 | Val Emotion Loss: 0.0864\n",
            "Sentiment Weight: 0.2489 | Emotion Weight: 1.0047\n",
            "Train Weighted Sentiment Loss: 0.1386 | Train Weighted Emotion Loss: 0.0253 | Train Regularization: 1.3861\n",
            "Val Weighted Sentiment Loss: 0.1633 | Val Weighted Emotion Loss: 0.0215 | Val Regularization: 1.3861\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3771 | Val Loss: 0.3792\n",
            "Train Sentiment Loss: 0.5558 | Train Emotion Loss: 0.1012\n",
            "Val Sentiment Loss: 0.6373 | Val Emotion Loss: 0.0862\n",
            "Sentiment Weight: 0.2279 | Emotion Weight: 1.0113\n",
            "Train Weighted Sentiment Loss: 0.1267 | Train Weighted Emotion Loss: 0.0231 | Train Regularization: 1.4675\n",
            "Val Weighted Sentiment Loss: 0.1452 | Val Weighted Emotion Loss: 0.0197 | Val Regularization: 1.4675\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3734 | Val Loss: 0.3772\n",
            "Train Sentiment Loss: 0.5511 | Train Emotion Loss: 0.1007\n",
            "Val Sentiment Loss: 0.6397 | Val Emotion Loss: 0.0864\n",
            "Sentiment Weight: 0.2137 | Emotion Weight: 1.0177\n",
            "Train Weighted Sentiment Loss: 0.1178 | Train Weighted Emotion Loss: 0.0215 | Train Regularization: 1.5257\n",
            "Val Weighted Sentiment Loss: 0.1367 | Val Weighted Emotion Loss: 0.0185 | Val Regularization: 1.5257\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3736 | Val Loss: 0.3793\n",
            "Train Sentiment Loss: 0.5557 | Train Emotion Loss: 0.1010\n",
            "Val Sentiment Loss: 0.6572 | Val Emotion Loss: 0.0866\n",
            "Sentiment Weight: 0.2034 | Emotion Weight: 1.0173\n",
            "Train Weighted Sentiment Loss: 0.1130 | Train Weighted Emotion Loss: 0.0205 | Train Regularization: 1.5755\n",
            "Val Weighted Sentiment Loss: 0.1337 | Val Weighted Emotion Loss: 0.0176 | Val Regularization: 1.5755\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3721 | Val Loss: 0.3713\n",
            "Train Sentiment Loss: 0.5554 | Train Emotion Loss: 0.1001\n",
            "Val Sentiment Loss: 0.6258 | Val Emotion Loss: 0.0858\n",
            "Sentiment Weight: 0.1969 | Emotion Weight: 1.0240\n",
            "Train Weighted Sentiment Loss: 0.1093 | Train Weighted Emotion Loss: 0.0197 | Train Regularization: 1.6016\n",
            "Val Weighted Sentiment Loss: 0.1232 | Val Weighted Emotion Loss: 0.0169 | Val Regularization: 1.6016\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3702 | Val Loss: 0.3752\n",
            "Train Sentiment Loss: 0.5465 | Train Emotion Loss: 0.1001\n",
            "Val Sentiment Loss: 0.6425 | Val Emotion Loss: 0.0867\n",
            "Sentiment Weight: 0.1951 | Emotion Weight: 1.0251\n",
            "Train Weighted Sentiment Loss: 0.1066 | Train Weighted Emotion Loss: 0.0195 | Train Regularization: 1.6097\n",
            "Val Weighted Sentiment Loss: 0.1253 | Val Weighted Emotion Loss: 0.0169 | Val Regularization: 1.6097\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3722 | Val Loss: 0.3711\n",
            "Train Sentiment Loss: 0.5537 | Train Emotion Loss: 0.1009\n",
            "Val Sentiment Loss: 0.6259 | Val Emotion Loss: 0.0861\n",
            "Sentiment Weight: 0.1928 | Emotion Weight: 1.0215\n",
            "Train Weighted Sentiment Loss: 0.1068 | Train Weighted Emotion Loss: 0.0194 | Train Regularization: 1.6249\n",
            "Val Weighted Sentiment Loss: 0.1207 | Val Weighted Emotion Loss: 0.0166 | Val Regularization: 1.6249\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3716 | Val Loss: 0.3699\n",
            "Train Sentiment Loss: 0.5536 | Train Emotion Loss: 0.1003\n",
            "Val Sentiment Loss: 0.6159 | Val Emotion Loss: 0.0869\n",
            "Sentiment Weight: 0.1919 | Emotion Weight: 1.0244\n",
            "Train Weighted Sentiment Loss: 0.1062 | Train Weighted Emotion Loss: 0.0192 | Train Regularization: 1.6266\n",
            "Val Weighted Sentiment Loss: 0.1182 | Val Weighted Emotion Loss: 0.0167 | Val Regularization: 1.6266\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3692 | Val Loss: 0.3710\n",
            "Train Sentiment Loss: 0.5440 | Train Emotion Loss: 0.0998\n",
            "Val Sentiment Loss: 0.6213 | Val Emotion Loss: 0.0868\n",
            "Sentiment Weight: 0.1939 | Emotion Weight: 1.0280\n",
            "Train Weighted Sentiment Loss: 0.1055 | Train Weighted Emotion Loss: 0.0194 | Train Regularization: 1.6128\n",
            "Val Weighted Sentiment Loss: 0.1205 | Val Weighted Emotion Loss: 0.0168 | Val Regularization: 1.6128\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3697 | Val Loss: 0.3793\n",
            "Train Sentiment Loss: 0.5492 | Train Emotion Loss: 0.0993\n",
            "Val Sentiment Loss: 0.6582 | Val Emotion Loss: 0.0880\n",
            "Sentiment Weight: 0.1933 | Emotion Weight: 1.0334\n",
            "Train Weighted Sentiment Loss: 0.1062 | Train Weighted Emotion Loss: 0.0192 | Train Regularization: 1.6105\n",
            "Val Weighted Sentiment Loss: 0.1273 | Val Weighted Emotion Loss: 0.0170 | Val Regularization: 1.6105\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3821 | Val Loss: 0.3791\n",
            "Train Sentiment Loss: 0.5963 | Train Emotion Loss: 0.1029\n",
            "Val Sentiment Loss: 0.6695 | Val Emotion Loss: 0.0868\n",
            "Sentiment Weight: 0.1837 | Emotion Weight: 1.0114\n",
            "Train Weighted Sentiment Loss: 0.1095 | Train Weighted Emotion Loss: 0.0189 | Train Regularization: 1.6833\n",
            "Val Weighted Sentiment Loss: 0.1230 | Val Weighted Emotion Loss: 0.0159 | Val Regularization: 1.6833\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3722 | Val Loss: 0.3770\n",
            "Train Sentiment Loss: 0.5577 | Train Emotion Loss: 0.1004\n",
            "Val Sentiment Loss: 0.6555 | Val Emotion Loss: 0.0869\n",
            "Sentiment Weight: 0.1882 | Emotion Weight: 1.0213\n",
            "Train Weighted Sentiment Loss: 0.1049 | Train Weighted Emotion Loss: 0.0189 | Train Regularization: 1.6494\n",
            "Val Weighted Sentiment Loss: 0.1233 | Val Weighted Emotion Loss: 0.0163 | Val Regularization: 1.6494\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3696 | Val Loss: 0.3797\n",
            "Train Sentiment Loss: 0.5468 | Train Emotion Loss: 0.0998\n",
            "Val Sentiment Loss: 0.6657 | Val Emotion Loss: 0.0871\n",
            "Sentiment Weight: 0.1923 | Emotion Weight: 1.0278\n",
            "Train Weighted Sentiment Loss: 0.1052 | Train Weighted Emotion Loss: 0.0192 | Train Regularization: 1.6210\n",
            "Val Weighted Sentiment Loss: 0.1280 | Val Weighted Emotion Loss: 0.0168 | Val Regularization: 1.6210\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3677 | Val Loss: 0.3733\n",
            "Train Sentiment Loss: 0.5416 | Train Emotion Loss: 0.0988\n",
            "Val Sentiment Loss: 0.6323 | Val Emotion Loss: 0.0870\n",
            "Sentiment Weight: 0.1949 | Emotion Weight: 1.0374\n",
            "Train Weighted Sentiment Loss: 0.1055 | Train Weighted Emotion Loss: 0.0192 | Train Regularization: 1.5988\n",
            "Val Weighted Sentiment Loss: 0.1232 | Val Weighted Emotion Loss: 0.0170 | Val Regularization: 1.5988\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3636 | Val Loss: 0.3693\n",
            "Train Sentiment Loss: 0.5256 | Train Emotion Loss: 0.0977\n",
            "Val Sentiment Loss: 0.6135 | Val Emotion Loss: 0.0865\n",
            "Sentiment Weight: 0.1962 | Emotion Weight: 1.0390\n",
            "Train Weighted Sentiment Loss: 0.1032 | Train Weighted Emotion Loss: 0.0192 | Train Regularization: 1.5902\n",
            "Val Weighted Sentiment Loss: 0.1204 | Val Weighted Emotion Loss: 0.0170 | Val Regularization: 1.5902\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3580 | Val Loss: 0.3687\n",
            "Train Sentiment Loss: 0.5029 | Train Emotion Loss: 0.0966\n",
            "Val Sentiment Loss: 0.6095 | Val Emotion Loss: 0.0863\n",
            "Sentiment Weight: 0.2004 | Emotion Weight: 1.0444\n",
            "Train Weighted Sentiment Loss: 0.1008 | Train Weighted Emotion Loss: 0.0194 | Train Regularization: 1.5640\n",
            "Val Weighted Sentiment Loss: 0.1221 | Val Weighted Emotion Loss: 0.0173 | Val Regularization: 1.5640\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3579 | Val Loss: 0.3707\n",
            "Train Sentiment Loss: 0.5040 | Train Emotion Loss: 0.0962\n",
            "Val Sentiment Loss: 0.6154 | Val Emotion Loss: 0.0869\n",
            "Sentiment Weight: 0.2026 | Emotion Weight: 1.0492\n",
            "Train Weighted Sentiment Loss: 0.1021 | Train Weighted Emotion Loss: 0.0195 | Train Regularization: 1.5484\n",
            "Val Weighted Sentiment Loss: 0.1247 | Val Weighted Emotion Loss: 0.0176 | Val Regularization: 1.5484\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3563 | Val Loss: 0.3699\n",
            "Train Sentiment Loss: 0.4994 | Train Emotion Loss: 0.0955\n",
            "Val Sentiment Loss: 0.6076 | Val Emotion Loss: 0.0874\n",
            "Sentiment Weight: 0.2047 | Emotion Weight: 1.0552\n",
            "Train Weighted Sentiment Loss: 0.1023 | Train Weighted Emotion Loss: 0.0196 | Train Regularization: 1.5322\n",
            "Val Weighted Sentiment Loss: 0.1244 | Val Weighted Emotion Loss: 0.0179 | Val Regularization: 1.5322\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3533 | Val Loss: 0.3724\n",
            "Train Sentiment Loss: 0.4895 | Train Emotion Loss: 0.0947\n",
            "Val Sentiment Loss: 0.6186 | Val Emotion Loss: 0.0874\n",
            "Sentiment Weight: 0.2078 | Emotion Weight: 1.0626\n",
            "Train Weighted Sentiment Loss: 0.1017 | Train Weighted Emotion Loss: 0.0197 | Train Regularization: 1.5105\n",
            "Val Weighted Sentiment Loss: 0.1285 | Val Weighted Emotion Loss: 0.0182 | Val Regularization: 1.5105\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3530 | Val Loss: 0.3682\n",
            "Train Sentiment Loss: 0.4871 | Train Emotion Loss: 0.0948\n",
            "Val Sentiment Loss: 0.6007 | Val Emotion Loss: 0.0867\n",
            "Sentiment Weight: 0.2099 | Emotion Weight: 1.0664\n",
            "Train Weighted Sentiment Loss: 0.1022 | Train Weighted Emotion Loss: 0.0199 | Train Regularization: 1.4968\n",
            "Val Weighted Sentiment Loss: 0.1261 | Val Weighted Emotion Loss: 0.0182 | Val Regularization: 1.4968\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3535 | Val Loss: 0.3679\n",
            "Train Sentiment Loss: 0.4879 | Train Emotion Loss: 0.0951\n",
            "Val Sentiment Loss: 0.5987 | Val Emotion Loss: 0.0867\n",
            "Sentiment Weight: 0.2108 | Emotion Weight: 1.0672\n",
            "Train Weighted Sentiment Loss: 0.1029 | Train Weighted Emotion Loss: 0.0200 | Train Regularization: 1.4918\n",
            "Val Weighted Sentiment Loss: 0.1262 | Val Weighted Emotion Loss: 0.0183 | Val Regularization: 1.4918\n",
            "\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3499 | Val Loss: 0.3689\n",
            "Train Sentiment Loss: 0.4754 | Train Emotion Loss: 0.0942\n",
            "Val Sentiment Loss: 0.6049 | Val Emotion Loss: 0.0860\n",
            "Sentiment Weight: 0.2139 | Emotion Weight: 1.0721\n",
            "Train Weighted Sentiment Loss: 0.1017 | Train Weighted Emotion Loss: 0.0202 | Train Regularization: 1.4726\n",
            "Val Weighted Sentiment Loss: 0.1294 | Val Weighted Emotion Loss: 0.0184 | Val Regularization: 1.4726\n",
            "\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3473 | Val Loss: 0.3720\n",
            "Train Sentiment Loss: 0.4673 | Train Emotion Loss: 0.0933\n",
            "Val Sentiment Loss: 0.6105 | Val Emotion Loss: 0.0874\n",
            "Sentiment Weight: 0.2173 | Emotion Weight: 1.0790\n",
            "Train Weighted Sentiment Loss: 0.1016 | Train Weighted Emotion Loss: 0.0203 | Train Regularization: 1.4503\n",
            "Val Weighted Sentiment Loss: 0.1327 | Val Weighted Emotion Loss: 0.0190 | Val Regularization: 1.4503\n",
            "\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3484 | Val Loss: 0.3701\n",
            "Train Sentiment Loss: 0.4707 | Train Emotion Loss: 0.0937\n",
            "Val Sentiment Loss: 0.6060 | Val Emotion Loss: 0.0864\n",
            "Sentiment Weight: 0.2185 | Emotion Weight: 1.0812\n",
            "Train Weighted Sentiment Loss: 0.1029 | Train Weighted Emotion Loss: 0.0205 | Train Regularization: 1.4427\n",
            "Val Weighted Sentiment Loss: 0.1324 | Val Weighted Emotion Loss: 0.0189 | Val Regularization: 1.4427\n",
            "\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3474 | Val Loss: 0.3696\n",
            "Train Sentiment Loss: 0.4677 | Train Emotion Loss: 0.0933\n",
            "Val Sentiment Loss: 0.6035 | Val Emotion Loss: 0.0863\n",
            "Sentiment Weight: 0.2196 | Emotion Weight: 1.0851\n",
            "Train Weighted Sentiment Loss: 0.1027 | Train Weighted Emotion Loss: 0.0205 | Train Regularization: 1.4341\n",
            "Val Weighted Sentiment Loss: 0.1325 | Val Weighted Emotion Loss: 0.0189 | Val Regularization: 1.4341\n",
            "\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3464 | Val Loss: 0.3683\n",
            "Train Sentiment Loss: 0.4645 | Train Emotion Loss: 0.0931\n",
            "Val Sentiment Loss: 0.5963 | Val Emotion Loss: 0.0864\n",
            "Sentiment Weight: 0.2208 | Emotion Weight: 1.0885\n",
            "Train Weighted Sentiment Loss: 0.1025 | Train Weighted Emotion Loss: 0.0206 | Train Regularization: 1.4258\n",
            "Val Weighted Sentiment Loss: 0.1316 | Val Weighted Emotion Loss: 0.0191 | Val Regularization: 1.4258\n",
            "\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3461 | Val Loss: 0.3676\n",
            "Train Sentiment Loss: 0.4636 | Train Emotion Loss: 0.0930\n",
            "Val Sentiment Loss: 0.5934 | Val Emotion Loss: 0.0862\n",
            "Sentiment Weight: 0.2217 | Emotion Weight: 1.0902\n",
            "Train Weighted Sentiment Loss: 0.1028 | Train Weighted Emotion Loss: 0.0206 | Train Regularization: 1.4199\n",
            "Val Weighted Sentiment Loss: 0.1316 | Val Weighted Emotion Loss: 0.0191 | Val Regularization: 1.4199\n",
            "\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3429 | Val Loss: 0.3687\n",
            "Train Sentiment Loss: 0.4537 | Train Emotion Loss: 0.0920\n",
            "Val Sentiment Loss: 0.5969 | Val Emotion Loss: 0.0862\n",
            "Sentiment Weight: 0.2245 | Emotion Weight: 1.0965\n",
            "Train Weighted Sentiment Loss: 0.1018 | Train Weighted Emotion Loss: 0.0206 | Train Regularization: 1.4019\n",
            "Val Weighted Sentiment Loss: 0.1340 | Val Weighted Emotion Loss: 0.0194 | Val Regularization: 1.4019\n",
            "\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3406 | Val Loss: 0.3681\n",
            "Train Sentiment Loss: 0.4480 | Train Emotion Loss: 0.0911\n",
            "Val Sentiment Loss: 0.5930 | Val Emotion Loss: 0.0861\n",
            "Sentiment Weight: 0.2271 | Emotion Weight: 1.1046\n",
            "Train Weighted Sentiment Loss: 0.1017 | Train Weighted Emotion Loss: 0.0207 | Train Regularization: 1.3829\n",
            "Val Weighted Sentiment Loss: 0.1347 | Val Weighted Emotion Loss: 0.0196 | Val Regularization: 1.3829\n",
            "\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3424 | Val Loss: 0.3662\n",
            "Train Sentiment Loss: 0.4518 | Train Emotion Loss: 0.0919\n",
            "Val Sentiment Loss: 0.5877 | Val Emotion Loss: 0.0854\n",
            "Sentiment Weight: 0.2278 | Emotion Weight: 1.1062\n",
            "Train Weighted Sentiment Loss: 0.1029 | Train Weighted Emotion Loss: 0.0209 | Train Regularization: 1.3784\n",
            "Val Weighted Sentiment Loss: 0.1339 | Val Weighted Emotion Loss: 0.0195 | Val Regularization: 1.3784\n",
            "\n",
            "Epoch 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3406 | Val Loss: 0.3645\n",
            "Train Sentiment Loss: 0.4469 | Train Emotion Loss: 0.0913\n",
            "Val Sentiment Loss: 0.5755 | Val Emotion Loss: 0.0862\n",
            "Sentiment Weight: 0.2293 | Emotion Weight: 1.1096\n",
            "Train Weighted Sentiment Loss: 0.1025 | Train Weighted Emotion Loss: 0.0209 | Train Regularization: 1.3686\n",
            "Val Weighted Sentiment Loss: 0.1320 | Val Weighted Emotion Loss: 0.0198 | Val Regularization: 1.3686\n",
            "\n",
            "Epoch 38/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3384 | Val Loss: 0.3698\n",
            "Train Sentiment Loss: 0.4402 | Train Emotion Loss: 0.0906\n",
            "Val Sentiment Loss: 0.5947 | Val Emotion Loss: 0.0867\n",
            "Sentiment Weight: 0.2317 | Emotion Weight: 1.1147\n",
            "Train Weighted Sentiment Loss: 0.1020 | Train Weighted Emotion Loss: 0.0210 | Train Regularization: 1.3537\n",
            "Val Weighted Sentiment Loss: 0.1378 | Val Weighted Emotion Loss: 0.0201 | Val Regularization: 1.3537\n",
            "\n",
            "Epoch 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3395 | Val Loss: 0.3674\n",
            "Train Sentiment Loss: 0.4409 | Train Emotion Loss: 0.0914\n",
            "Val Sentiment Loss: 0.5869 | Val Emotion Loss: 0.0860\n",
            "Sentiment Weight: 0.2325 | Emotion Weight: 1.1136\n",
            "Train Weighted Sentiment Loss: 0.1025 | Train Weighted Emotion Loss: 0.0213 | Train Regularization: 1.3511\n",
            "Val Weighted Sentiment Loss: 0.1365 | Val Weighted Emotion Loss: 0.0200 | Val Regularization: 1.3511\n",
            "\n",
            "Epoch 40/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3399 | Val Loss: 0.3676\n",
            "Train Sentiment Loss: 0.4430 | Train Emotion Loss: 0.0914\n",
            "Val Sentiment Loss: 0.5839 | Val Emotion Loss: 0.0868\n",
            "Sentiment Weight: 0.2328 | Emotion Weight: 1.1132\n",
            "Train Weighted Sentiment Loss: 0.1031 | Train Weighted Emotion Loss: 0.0213 | Train Regularization: 1.3505\n",
            "Val Weighted Sentiment Loss: 0.1359 | Val Weighted Emotion Loss: 0.0202 | Val Regularization: 1.3505\n",
            "\n",
            "Epoch 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3375 | Val Loss: 0.3662\n",
            "Train Sentiment Loss: 0.4359 | Train Emotion Loss: 0.0907\n",
            "Val Sentiment Loss: 0.5755 | Val Emotion Loss: 0.0871\n",
            "Sentiment Weight: 0.2344 | Emotion Weight: 1.1173\n",
            "Train Weighted Sentiment Loss: 0.1022 | Train Weighted Emotion Loss: 0.0213 | Train Regularization: 1.3398\n",
            "Val Weighted Sentiment Loss: 0.1349 | Val Weighted Emotion Loss: 0.0204 | Val Regularization: 1.3398\n",
            "\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3370 | Val Loss: 0.3663\n",
            "Train Sentiment Loss: 0.4340 | Train Emotion Loss: 0.0907\n",
            "Val Sentiment Loss: 0.5820 | Val Emotion Loss: 0.0856\n",
            "Sentiment Weight: 0.2360 | Emotion Weight: 1.1195\n",
            "Train Weighted Sentiment Loss: 0.1024 | Train Weighted Emotion Loss: 0.0214 | Train Regularization: 1.3311\n",
            "Val Weighted Sentiment Loss: 0.1373 | Val Weighted Emotion Loss: 0.0202 | Val Regularization: 1.3311\n",
            "\n",
            "Epoch 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3375 | Val Loss: 0.3659\n",
            "Train Sentiment Loss: 0.4387 | Train Emotion Loss: 0.0901\n",
            "Val Sentiment Loss: 0.5795 | Val Emotion Loss: 0.0858\n",
            "Sentiment Weight: 0.2359 | Emotion Weight: 1.1238\n",
            "Train Weighted Sentiment Loss: 0.1035 | Train Weighted Emotion Loss: 0.0213 | Train Regularization: 1.3277\n",
            "Val Weighted Sentiment Loss: 0.1367 | Val Weighted Emotion Loss: 0.0202 | Val Regularization: 1.3277\n",
            "\n",
            "Epoch 44/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3349 | Val Loss: 0.3640\n",
            "Train Sentiment Loss: 0.4295 | Train Emotion Loss: 0.0897\n",
            "Val Sentiment Loss: 0.5710 | Val Emotion Loss: 0.0858\n",
            "Sentiment Weight: 0.2363 | Emotion Weight: 1.1241\n",
            "Train Weighted Sentiment Loss: 0.1015 | Train Weighted Emotion Loss: 0.0212 | Train Regularization: 1.3256\n",
            "Val Weighted Sentiment Loss: 0.1349 | Val Weighted Emotion Loss: 0.0203 | Val Regularization: 1.3256\n",
            "\n",
            "Epoch 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3306 | Val Loss: 0.3662\n",
            "Train Sentiment Loss: 0.4171 | Train Emotion Loss: 0.0885\n",
            "Val Sentiment Loss: 0.5775 | Val Emotion Loss: 0.0861\n",
            "Sentiment Weight: 0.2385 | Emotion Weight: 1.1282\n",
            "Train Weighted Sentiment Loss: 0.0995 | Train Weighted Emotion Loss: 0.0211 | Train Regularization: 1.3127\n",
            "Val Weighted Sentiment Loss: 0.1378 | Val Weighted Emotion Loss: 0.0205 | Val Regularization: 1.3127\n",
            "\n",
            "Epoch 46/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3287 | Val Loss: 0.3668\n",
            "Train Sentiment Loss: 0.4121 | Train Emotion Loss: 0.0879\n",
            "Val Sentiment Loss: 0.5784 | Val Emotion Loss: 0.0861\n",
            "Sentiment Weight: 0.2408 | Emotion Weight: 1.1331\n",
            "Train Weighted Sentiment Loss: 0.0992 | Train Weighted Emotion Loss: 0.0212 | Train Regularization: 1.2990\n",
            "Val Weighted Sentiment Loss: 0.1392 | Val Weighted Emotion Loss: 0.0207 | Val Regularization: 1.2990\n",
            "\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3292 | Val Loss: 0.3650\n",
            "Train Sentiment Loss: 0.4116 | Train Emotion Loss: 0.0884\n",
            "Val Sentiment Loss: 0.5698 | Val Emotion Loss: 0.0862\n",
            "Sentiment Weight: 0.2427 | Emotion Weight: 1.1351\n",
            "Train Weighted Sentiment Loss: 0.0999 | Train Weighted Emotion Loss: 0.0215 | Train Regularization: 1.2894\n",
            "Val Weighted Sentiment Loss: 0.1383 | Val Weighted Emotion Loss: 0.0209 | Val Regularization: 1.2894\n",
            "\n",
            "Epoch 48/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3281 | Val Loss: 0.3651\n",
            "Train Sentiment Loss: 0.4091 | Train Emotion Loss: 0.0880\n",
            "Val Sentiment Loss: 0.5704 | Val Emotion Loss: 0.0858\n",
            "Sentiment Weight: 0.2444 | Emotion Weight: 1.1382\n",
            "Train Weighted Sentiment Loss: 0.1000 | Train Weighted Emotion Loss: 0.0215 | Train Regularization: 1.2797\n",
            "Val Weighted Sentiment Loss: 0.1394 | Val Weighted Emotion Loss: 0.0210 | Val Regularization: 1.2797\n",
            "\n",
            "Epoch 49/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3264 | Val Loss: 0.3646\n",
            "Train Sentiment Loss: 0.4042 | Train Emotion Loss: 0.0876\n",
            "Val Sentiment Loss: 0.5663 | Val Emotion Loss: 0.0861\n",
            "Sentiment Weight: 0.2464 | Emotion Weight: 1.1415\n",
            "Train Weighted Sentiment Loss: 0.0996 | Train Weighted Emotion Loss: 0.0216 | Train Regularization: 1.2686\n",
            "Val Weighted Sentiment Loss: 0.1395 | Val Weighted Emotion Loss: 0.0212 | Val Regularization: 1.2686\n",
            "\n",
            "Epoch 50/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3264 | Val Loss: 0.3656\n",
            "Train Sentiment Loss: 0.4059 | Train Emotion Loss: 0.0872\n",
            "Val Sentiment Loss: 0.5687 | Val Emotion Loss: 0.0862\n",
            "Sentiment Weight: 0.2477 | Emotion Weight: 1.1459\n",
            "Train Weighted Sentiment Loss: 0.1005 | Train Weighted Emotion Loss: 0.0216 | Train Regularization: 1.2592\n",
            "Val Weighted Sentiment Loss: 0.1409 | Val Weighted Emotion Loss: 0.0214 | Val Regularization: 1.2592\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_train_res = load('/content/drive/MyDrive/model/text_train_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Text training time per batch (ms): {sum(text_train_res['training_times']) / len(text_train_res['training_times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwua_IbJMAn7",
        "outputId": "6eb04db5-a1c1-4975-ba4d-7f33c87c815e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text training time per batch (ms): 5.002913381722109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_test_res = uni_test_model(text_model, testdata, loss_fn, modality='text', save_path=text_model_path, mean_sentiment_loss=text_mean_sentiment_loss, mean_emotion_loss=text_mean_emotion_loss)\n",
        "\n",
        "save(text_test_res, '/content/drive/MyDrive/model/text_test_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PtQYDyxwe2f",
        "outputId": "ba33c81f-4c6d-4564-d47e-366619126d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e0ca022d749b>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(save_path))\n",
            "                                                                  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Metrics:\n",
            "Total Loss: 0.3936\n",
            "Total MAE: 0.4420\n",
            "Sentiment MAE: 0.6904\n",
            "Sentiment PCC: 0.5944\n",
            "Emotion MAE: 0.1937\n",
            "Emotion R: 0.0554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_test_res = load('/content/drive/MyDrive/model/text_test_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Text testing time per batch (ms): {sum(text_test_res['Testing Times']) / len(text_test_res['Testing Times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_zGcWEjWqPm",
        "outputId": "5c1ac41b-62b7-4fcd-91f7-107cacc75dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text testing time per batch (ms): 1.4734888729983813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_input_dim = 74\n",
        "\n",
        "# Compute mean losses in train dataset for audio modality\n",
        "audio_mean_sentiment_loss, audio_mean_emotion_loss = uni_avg_mean_losses(traindata, audio_input_dim, hidden_dim, attention_dim, 'audio')\n",
        "\n",
        "print(f\"Audio Mean Sentiment Loss: {audio_mean_sentiment_loss:.4f}\")\n",
        "print(f\"Audio Mean Emotion Loss: {audio_mean_emotion_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rji9eH_BpreL",
        "outputId": "1379042c-13ec-4f88-88ae-c2acdebfc3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio Mean Sentiment Loss: 1.3031\n",
            "Audio Mean Emotion Loss: 1.1349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_model = UniModel(audio_input_dim, hidden_dim, attention_dim)\n",
        "audio_optimizer = AdamW([\n",
        "    {'params': audio_model.parameters()},\n",
        "    {'params': [loss_fn.log_sigma_sentiment, loss_fn.log_sigma_emotion]}\n",
        "], lr=0.001, weight_decay=0.01)\n",
        "audio_scheduler = ReduceLROnPlateau(audio_optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# Save path for the trained model\n",
        "audio_model_path = os.path.join(save_model_path, \"audio.pth\")"
      ],
      "metadata": {
        "id": "E5kt1QAwBDCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for audio modality\n",
        "audio_train_res = uni_train_model(\n",
        "    audio_model, traindata, validdata, epochs=50, optimizer=audio_optimizer,\n",
        "    scheduler=audio_scheduler, loss_fn=loss_fn, save_path=audio_model_path, modality='audio',\n",
        "    mean_sentiment_loss=audio_mean_sentiment_loss, mean_emotion_loss=audio_mean_emotion_loss\n",
        ")\n",
        "\n",
        "save(audio_train_res, '/content/drive/MyDrive/model/audio_train_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QIDxGgeBmZA",
        "outputId": "8c5dddd7-b7b0-4a1e-f8b0-0b94f18e1692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4537 | Val Loss: 0.4136\n",
            "Train Sentiment Loss: 0.8699 | Train Emotion Loss: 0.1095\n",
            "Val Sentiment Loss: 0.8325 | Val Emotion Loss: 0.0871\n",
            "Sentiment Weight: 0.1980 | Emotion Weight: 1.0240\n",
            "Train Weighted Sentiment Loss: 0.1723 | Train Weighted Emotion Loss: 0.0217 | Train Regularization: 1.5957\n",
            "Val Weighted Sentiment Loss: 0.1648 | Val Weighted Emotion Loss: 0.0173 | Val Regularization: 1.5957\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4340 | Val Loss: 0.4040\n",
            "Train Sentiment Loss: 0.8669 | Train Emotion Loss: 0.1062\n",
            "Val Sentiment Loss: 0.8284 | Val Emotion Loss: 0.0869\n",
            "Sentiment Weight: 0.1655 | Emotion Weight: 0.9917\n",
            "Train Weighted Sentiment Loss: 0.1435 | Train Weighted Emotion Loss: 0.0176 | Train Regularization: 1.8072\n",
            "Val Weighted Sentiment Loss: 0.1371 | Val Weighted Emotion Loss: 0.0144 | Val Regularization: 1.8072\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4281 | Val Loss: 0.4011\n",
            "Train Sentiment Loss: 0.8786 | Train Emotion Loss: 0.1056\n",
            "Val Sentiment Loss: 0.8319 | Val Emotion Loss: 0.0870\n",
            "Sentiment Weight: 0.1459 | Emotion Weight: 0.9823\n",
            "Train Weighted Sentiment Loss: 0.1282 | Train Weighted Emotion Loss: 0.0154 | Train Regularization: 1.9430\n",
            "Val Weighted Sentiment Loss: 0.1213 | Val Weighted Emotion Loss: 0.0127 | Val Regularization: 1.9430\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4248 | Val Loss: 0.4055\n",
            "Train Sentiment Loss: 0.8704 | Train Emotion Loss: 0.1065\n",
            "Val Sentiment Loss: 0.8657 | Val Emotion Loss: 0.0880\n",
            "Sentiment Weight: 0.1353 | Emotion Weight: 0.9717\n",
            "Train Weighted Sentiment Loss: 0.1177 | Train Weighted Emotion Loss: 0.0144 | Train Regularization: 2.0292\n",
            "Val Weighted Sentiment Loss: 0.1171 | Val Weighted Emotion Loss: 0.0119 | Val Regularization: 2.0292\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4223 | Val Loss: 0.4009\n",
            "Train Sentiment Loss: 0.8656 | Train Emotion Loss: 0.1057\n",
            "Val Sentiment Loss: 0.8420 | Val Emotion Loss: 0.0871\n",
            "Sentiment Weight: 0.1300 | Emotion Weight: 0.9735\n",
            "Train Weighted Sentiment Loss: 0.1125 | Train Weighted Emotion Loss: 0.0137 | Train Regularization: 2.0673\n",
            "Val Weighted Sentiment Loss: 0.1094 | Val Weighted Emotion Loss: 0.0113 | Val Regularization: 2.0673\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4218 | Val Loss: 0.4024\n",
            "Train Sentiment Loss: 0.8677 | Train Emotion Loss: 0.1053\n",
            "Val Sentiment Loss: 0.8497 | Val Emotion Loss: 0.0878\n",
            "Sentiment Weight: 0.1271 | Emotion Weight: 0.9760\n",
            "Train Weighted Sentiment Loss: 0.1103 | Train Weighted Emotion Loss: 0.0134 | Train Regularization: 2.0872\n",
            "Val Weighted Sentiment Loss: 0.1080 | Val Weighted Emotion Loss: 0.0112 | Val Regularization: 2.0872\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4200 | Val Loss: 0.4004\n",
            "Train Sentiment Loss: 0.8582 | Train Emotion Loss: 0.1050\n",
            "Val Sentiment Loss: 0.8404 | Val Emotion Loss: 0.0871\n",
            "Sentiment Weight: 0.1265 | Emotion Weight: 0.9792\n",
            "Train Weighted Sentiment Loss: 0.1085 | Train Weighted Emotion Loss: 0.0133 | Train Regularization: 2.0886\n",
            "Val Weighted Sentiment Loss: 0.1063 | Val Weighted Emotion Loss: 0.0110 | Val Regularization: 2.0886\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4188 | Val Loss: 0.3994\n",
            "Train Sentiment Loss: 0.8568 | Train Emotion Loss: 0.1039\n",
            "Val Sentiment Loss: 0.8340 | Val Emotion Loss: 0.0869\n",
            "Sentiment Weight: 0.1264 | Emotion Weight: 0.9865\n",
            "Train Weighted Sentiment Loss: 0.1083 | Train Weighted Emotion Loss: 0.0131 | Train Regularization: 2.0817\n",
            "Val Weighted Sentiment Loss: 0.1054 | Val Weighted Emotion Loss: 0.0110 | Val Regularization: 2.0817\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4168 | Val Loss: 0.4005\n",
            "Train Sentiment Loss: 0.8439 | Train Emotion Loss: 0.1034\n",
            "Val Sentiment Loss: 0.8405 | Val Emotion Loss: 0.0873\n",
            "Sentiment Weight: 0.1274 | Emotion Weight: 0.9926\n",
            "Train Weighted Sentiment Loss: 0.1075 | Train Weighted Emotion Loss: 0.0132 | Train Regularization: 2.0675\n",
            "Val Weighted Sentiment Loss: 0.1071 | Val Weighted Emotion Loss: 0.0111 | Val Regularization: 2.0675\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4160 | Val Loss: 0.3996\n",
            "Train Sentiment Loss: 0.8379 | Train Emotion Loss: 0.1034\n",
            "Val Sentiment Loss: 0.8389 | Val Emotion Loss: 0.0866\n",
            "Sentiment Weight: 0.1284 | Emotion Weight: 0.9956\n",
            "Train Weighted Sentiment Loss: 0.1076 | Train Weighted Emotion Loss: 0.0133 | Train Regularization: 2.0567\n",
            "Val Weighted Sentiment Loss: 0.1078 | Val Weighted Emotion Loss: 0.0111 | Val Regularization: 2.0567\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4139 | Val Loss: 0.3997\n",
            "Train Sentiment Loss: 0.8285 | Train Emotion Loss: 0.1024\n",
            "Val Sentiment Loss: 0.8406 | Val Emotion Loss: 0.0865\n",
            "Sentiment Weight: 0.1297 | Emotion Weight: 1.0030\n",
            "Train Weighted Sentiment Loss: 0.1075 | Train Weighted Emotion Loss: 0.0133 | Train Regularization: 2.0392\n",
            "Val Weighted Sentiment Loss: 0.1091 | Val Weighted Emotion Loss: 0.0112 | Val Regularization: 2.0392\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4109 | Val Loss: 0.3995\n",
            "Train Sentiment Loss: 0.8166 | Train Emotion Loss: 0.1009\n",
            "Val Sentiment Loss: 0.8393 | Val Emotion Loss: 0.0865\n",
            "Sentiment Weight: 0.1314 | Emotion Weight: 1.0143\n",
            "Train Weighted Sentiment Loss: 0.1073 | Train Weighted Emotion Loss: 0.0133 | Train Regularization: 2.0151\n",
            "Val Weighted Sentiment Loss: 0.1103 | Val Weighted Emotion Loss: 0.0114 | Val Regularization: 2.0151\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4084 | Val Loss: 0.3998\n",
            "Train Sentiment Loss: 0.8026 | Train Emotion Loss: 0.1002\n",
            "Val Sentiment Loss: 0.8365 | Val Emotion Loss: 0.0871\n",
            "Sentiment Weight: 0.1334 | Emotion Weight: 1.0233\n",
            "Train Weighted Sentiment Loss: 0.1070 | Train Weighted Emotion Loss: 0.0134 | Train Regularization: 1.9917\n",
            "Val Weighted Sentiment Loss: 0.1116 | Val Weighted Emotion Loss: 0.0116 | Val Regularization: 1.9917\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4067 | Val Loss: 0.4007\n",
            "Train Sentiment Loss: 0.7951 | Train Emotion Loss: 0.0994\n",
            "Val Sentiment Loss: 0.8484 | Val Emotion Loss: 0.0863\n",
            "Sentiment Weight: 0.1349 | Emotion Weight: 1.0316\n",
            "Train Weighted Sentiment Loss: 0.1073 | Train Weighted Emotion Loss: 0.0134 | Train Regularization: 1.9720\n",
            "Val Weighted Sentiment Loss: 0.1145 | Val Weighted Emotion Loss: 0.0116 | Val Regularization: 1.9720\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4028 | Val Loss: 0.3994\n",
            "Train Sentiment Loss: 0.7739 | Train Emotion Loss: 0.0981\n",
            "Val Sentiment Loss: 0.8363 | Val Emotion Loss: 0.0866\n",
            "Sentiment Weight: 0.1350 | Emotion Weight: 1.0329\n",
            "Train Weighted Sentiment Loss: 0.1045 | Train Weighted Emotion Loss: 0.0132 | Train Regularization: 1.9699\n",
            "Val Weighted Sentiment Loss: 0.1129 | Val Weighted Emotion Loss: 0.0117 | Val Regularization: 1.9699\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3990 | Val Loss: 0.4014\n",
            "Train Sentiment Loss: 0.7580 | Train Emotion Loss: 0.0964\n",
            "Val Sentiment Loss: 0.8477 | Val Emotion Loss: 0.0871\n",
            "Sentiment Weight: 0.1361 | Emotion Weight: 1.0406\n",
            "Train Weighted Sentiment Loss: 0.1032 | Train Weighted Emotion Loss: 0.0131 | Train Regularization: 1.9545\n",
            "Val Weighted Sentiment Loss: 0.1154 | Val Weighted Emotion Loss: 0.0119 | Val Regularization: 1.9545\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3963 | Val Loss: 0.3991\n",
            "Train Sentiment Loss: 0.7452 | Train Emotion Loss: 0.0955\n",
            "Val Sentiment Loss: 0.8354 | Val Emotion Loss: 0.0864\n",
            "Sentiment Weight: 0.1377 | Emotion Weight: 1.0494\n",
            "Train Weighted Sentiment Loss: 0.1026 | Train Weighted Emotion Loss: 0.0131 | Train Regularization: 1.9346\n",
            "Val Weighted Sentiment Loss: 0.1150 | Val Weighted Emotion Loss: 0.0119 | Val Regularization: 1.9346\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3939 | Val Loss: 0.4001\n",
            "Train Sentiment Loss: 0.7343 | Train Emotion Loss: 0.0947\n",
            "Val Sentiment Loss: 0.8405 | Val Emotion Loss: 0.0865\n",
            "Sentiment Weight: 0.1394 | Emotion Weight: 1.0580\n",
            "Train Weighted Sentiment Loss: 0.1024 | Train Weighted Emotion Loss: 0.0132 | Train Regularization: 1.9141\n",
            "Val Weighted Sentiment Loss: 0.1172 | Val Weighted Emotion Loss: 0.0121 | Val Regularization: 1.9141\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3930 | Val Loss: 0.4020\n",
            "Train Sentiment Loss: 0.7333 | Train Emotion Loss: 0.0939\n",
            "Val Sentiment Loss: 0.8529 | Val Emotion Loss: 0.0866\n",
            "Sentiment Weight: 0.1405 | Emotion Weight: 1.0672\n",
            "Train Weighted Sentiment Loss: 0.1030 | Train Weighted Emotion Loss: 0.0132 | Train Regularization: 1.8974\n",
            "Val Weighted Sentiment Loss: 0.1198 | Val Weighted Emotion Loss: 0.0122 | Val Regularization: 1.8974\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3896 | Val Loss: 0.4026\n",
            "Train Sentiment Loss: 0.7155 | Train Emotion Loss: 0.0931\n",
            "Val Sentiment Loss: 0.8513 | Val Emotion Loss: 0.0871\n",
            "Sentiment Weight: 0.1426 | Emotion Weight: 1.0759\n",
            "Train Weighted Sentiment Loss: 0.1020 | Train Weighted Emotion Loss: 0.0133 | Train Regularization: 1.8747\n",
            "Val Weighted Sentiment Loss: 0.1214 | Val Weighted Emotion Loss: 0.0124 | Val Regularization: 1.8747\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3883 | Val Loss: 0.4042\n",
            "Train Sentiment Loss: 0.7087 | Train Emotion Loss: 0.0928\n",
            "Val Sentiment Loss: 0.8556 | Val Emotion Loss: 0.0879\n",
            "Sentiment Weight: 0.1443 | Emotion Weight: 1.0829\n",
            "Train Weighted Sentiment Loss: 0.1023 | Train Weighted Emotion Loss: 0.0134 | Train Regularization: 1.8559\n",
            "Val Weighted Sentiment Loss: 0.1235 | Val Weighted Emotion Loss: 0.0127 | Val Regularization: 1.8559\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3868 | Val Loss: 0.4054\n",
            "Train Sentiment Loss: 0.7027 | Train Emotion Loss: 0.0921\n",
            "Val Sentiment Loss: 0.8631 | Val Emotion Loss: 0.0878\n",
            "Sentiment Weight: 0.1459 | Emotion Weight: 1.0895\n",
            "Train Weighted Sentiment Loss: 0.1025 | Train Weighted Emotion Loss: 0.0134 | Train Regularization: 1.8394\n",
            "Val Weighted Sentiment Loss: 0.1259 | Val Weighted Emotion Loss: 0.0128 | Val Regularization: 1.8394\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3847 | Val Loss: 0.4054\n",
            "Train Sentiment Loss: 0.6928 | Train Emotion Loss: 0.0915\n",
            "Val Sentiment Loss: 0.8621 | Val Emotion Loss: 0.0876\n",
            "Sentiment Weight: 0.1476 | Emotion Weight: 1.0967\n",
            "Train Weighted Sentiment Loss: 0.1023 | Train Weighted Emotion Loss: 0.0135 | Train Regularization: 1.8208\n",
            "Val Weighted Sentiment Loss: 0.1273 | Val Weighted Emotion Loss: 0.0129 | Val Regularization: 1.8208\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3833 | Val Loss: 0.4067\n",
            "Train Sentiment Loss: 0.6864 | Train Emotion Loss: 0.0911\n",
            "Val Sentiment Loss: 0.8681 | Val Emotion Loss: 0.0879\n",
            "Sentiment Weight: 0.1480 | Emotion Weight: 1.0986\n",
            "Train Weighted Sentiment Loss: 0.1016 | Train Weighted Emotion Loss: 0.0135 | Train Regularization: 1.8163\n",
            "Val Weighted Sentiment Loss: 0.1285 | Val Weighted Emotion Loss: 0.0130 | Val Regularization: 1.8163\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3810 | Val Loss: 0.4079\n",
            "Train Sentiment Loss: 0.6769 | Train Emotion Loss: 0.0902\n",
            "Val Sentiment Loss: 0.8719 | Val Emotion Loss: 0.0883\n",
            "Sentiment Weight: 0.1488 | Emotion Weight: 1.1027\n",
            "Train Weighted Sentiment Loss: 0.1007 | Train Weighted Emotion Loss: 0.0134 | Train Regularization: 1.8073\n",
            "Val Weighted Sentiment Loss: 0.1297 | Val Weighted Emotion Loss: 0.0131 | Val Regularization: 1.8073\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3785 | Val Loss: 0.4086\n",
            "Train Sentiment Loss: 0.6652 | Train Emotion Loss: 0.0896\n",
            "Val Sentiment Loss: 0.8719 | Val Emotion Loss: 0.0888\n",
            "Sentiment Weight: 0.1500 | Emotion Weight: 1.1076\n",
            "Train Weighted Sentiment Loss: 0.0998 | Train Weighted Emotion Loss: 0.0134 | Train Regularization: 1.7948\n",
            "Val Weighted Sentiment Loss: 0.1308 | Val Weighted Emotion Loss: 0.0133 | Val Regularization: 1.7948\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3776 | Val Loss: 0.4104\n",
            "Train Sentiment Loss: 0.6630 | Train Emotion Loss: 0.0890\n",
            "Val Sentiment Loss: 0.8784 | Val Emotion Loss: 0.0893\n",
            "Sentiment Weight: 0.1510 | Emotion Weight: 1.1131\n",
            "Train Weighted Sentiment Loss: 0.1001 | Train Weighted Emotion Loss: 0.0134 | Train Regularization: 1.7831\n",
            "Val Weighted Sentiment Loss: 0.1327 | Val Weighted Emotion Loss: 0.0135 | Val Regularization: 1.7831\n",
            "\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_train_res = load('/content/drive/MyDrive/model/audio_train_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Audio training time per batch (ms): {sum(audio_train_res['training_times']) / len(audio_train_res['training_times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpETFuflOTFF",
        "outputId": "7037a019-a10f-4eb1-bf32-c7908ea3d544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio training time per batch (ms): 4.665709495751798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_test_res = uni_test_model(audio_model, testdata, loss_fn, modality='audio', save_path=audio_model_path, mean_sentiment_loss=audio_mean_sentiment_loss, mean_emotion_loss=audio_mean_emotion_loss)\n",
        "\n",
        "save(audio_test_res, '/content/drive/MyDrive/model/audio_test_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgeZWd_JwrQG",
        "outputId": "1a3b7940-8c8f-4027-aec0-142c011b416c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Metrics:\n",
            "Total Loss: 0.4300\n",
            "Total MAE: 0.5212\n",
            "Sentiment MAE: 0.8420\n",
            "Sentiment PCC: 0.1381\n",
            "Emotion MAE: 0.2003\n",
            "Emotion R: 0.0373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_test_res = load('/content/drive/MyDrive/model/audio_test_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Audio testing time per batch (ms): {sum(audio_test_res['Testing Times']) / len(audio_test_res['Testing Times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W4xXhenWgsE",
        "outputId": "b3bee606-3641-4640-9ff5-43103a464f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio testing time per batch (ms): 1.5786967865408283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_input_dim = 713\n",
        "\n",
        "# Compute mean losses in train dataset for video modality\n",
        "video_mean_sentiment_loss, video_mean_emotion_loss = uni_avg_mean_losses(traindata, video_input_dim, hidden_dim, attention_dim, 'video')\n",
        "\n",
        "print(f\"Video Mean Sentiment Loss: {video_mean_sentiment_loss:.4f}\")\n",
        "print(f\"Video Mean Emotion Loss: {video_mean_emotion_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRmq7isXxFuW",
        "outputId": "9a5304dc-9277-42d7-be7c-1365eca1454a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Mean Sentiment Loss: 1.2787\n",
            "Video Mean Emotion Loss: 1.2053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_model = UniModel(video_input_dim, hidden_dim, attention_dim)\n",
        "video_optimizer = AdamW([\n",
        "    {'params': video_model.parameters()},\n",
        "    {'params': [loss_fn.log_sigma_sentiment, loss_fn.log_sigma_emotion]}\n",
        "], lr=0.001, weight_decay=0.01)\n",
        "video_scheduler = ReduceLROnPlateau(video_optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# Save path for the trained model\n",
        "video_model_path = os.path.join(save_model_path, \"video.pth\")"
      ],
      "metadata": {
        "id": "GCiHGyw9xcvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for video modality\n",
        "video_train_res = uni_train_model(\n",
        "    video_model, traindata, validdata, epochs=50, optimizer=video_optimizer,\n",
        "    scheduler=video_scheduler, loss_fn=loss_fn, save_path=video_model_path, modality='video',\n",
        "    mean_sentiment_loss=video_mean_sentiment_loss, mean_emotion_loss=video_mean_emotion_loss\n",
        ")\n",
        "\n",
        "save(video_train_res, '/content/drive/MyDrive/model/video_train_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8r7HIXUxfbq",
        "outputId": "2de7efe5-1e2f-4985-ebdd-6be9c284ee46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4417 | Val Loss: 0.4050\n",
            "Train Sentiment Loss: 0.8964 | Train Emotion Loss: 0.1171\n",
            "Val Sentiment Loss: 0.8826 | Val Emotion Loss: 0.0854\n",
            "Sentiment Weight: 0.1399 | Emotion Weight: 1.0485\n",
            "Train Weighted Sentiment Loss: 0.1254 | Train Weighted Emotion Loss: 0.0164 | Train Regularization: 1.9196\n",
            "Val Weighted Sentiment Loss: 0.1235 | Val Weighted Emotion Loss: 0.0119 | Val Regularization: 1.9196\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4219 | Val Loss: 0.3987\n",
            "Train Sentiment Loss: 0.8654 | Train Emotion Loss: 0.1046\n",
            "Val Sentiment Loss: 0.8555 | Val Emotion Loss: 0.0836\n",
            "Sentiment Weight: 0.1322 | Emotion Weight: 1.0229\n",
            "Train Weighted Sentiment Loss: 0.1144 | Train Weighted Emotion Loss: 0.0138 | Train Regularization: 2.0005\n",
            "Val Weighted Sentiment Loss: 0.1131 | Val Weighted Emotion Loss: 0.0111 | Val Regularization: 2.0005\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4333 | Val Loss: 0.8536\n",
            "Train Sentiment Loss: 0.9595 | Train Emotion Loss: 0.1050\n",
            "Val Sentiment Loss: 3.2532 | Val Emotion Loss: 0.2430\n",
            "Sentiment Weight: 0.1234 | Emotion Weight: 0.9998\n",
            "Train Weighted Sentiment Loss: 0.1184 | Train Weighted Emotion Loss: 0.0130 | Train Regularization: 2.0928\n",
            "Val Weighted Sentiment Loss: 0.4013 | Val Weighted Emotion Loss: 0.0300 | Val Regularization: 2.0928\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4193 | Val Loss: 1.0880\n",
            "Train Sentiment Loss: 0.8742 | Train Emotion Loss: 0.1023\n",
            "Val Sentiment Loss: 5.2056 | Val Emotion Loss: 0.2356\n",
            "Sentiment Weight: 0.1234 | Emotion Weight: 1.0049\n",
            "Train Weighted Sentiment Loss: 0.1079 | Train Weighted Emotion Loss: 0.0126 | Train Regularization: 2.0872\n",
            "Val Weighted Sentiment Loss: 0.6425 | Val Weighted Emotion Loss: 0.0291 | Val Regularization: 2.0872\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4181 | Val Loss: 0.4006\n",
            "Train Sentiment Loss: 0.8730 | Train Emotion Loss: 0.1012\n",
            "Val Sentiment Loss: 0.8748 | Val Emotion Loss: 0.0836\n",
            "Sentiment Weight: 0.1233 | Emotion Weight: 1.0149\n",
            "Train Weighted Sentiment Loss: 0.1076 | Train Weighted Emotion Loss: 0.0125 | Train Regularization: 2.0786\n",
            "Val Weighted Sentiment Loss: 0.1078 | Val Weighted Emotion Loss: 0.0103 | Val Regularization: 2.0786\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4166 | Val Loss: 0.3934\n",
            "Train Sentiment Loss: 0.8666 | Train Emotion Loss: 0.1006\n",
            "Val Sentiment Loss: 0.8306 | Val Emotion Loss: 0.0821\n",
            "Sentiment Weight: 0.1236 | Emotion Weight: 1.0254\n",
            "Train Weighted Sentiment Loss: 0.1071 | Train Weighted Emotion Loss: 0.0124 | Train Regularization: 2.0656\n",
            "Val Weighted Sentiment Loss: 0.1027 | Val Weighted Emotion Loss: 0.0101 | Val Regularization: 2.0656\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4140 | Val Loss: 0.4817\n",
            "Train Sentiment Loss: 0.8592 | Train Emotion Loss: 0.0988\n",
            "Val Sentiment Loss: 1.2445 | Val Emotion Loss: 0.1177\n",
            "Sentiment Weight: 0.1243 | Emotion Weight: 1.0400\n",
            "Train Weighted Sentiment Loss: 0.1068 | Train Weighted Emotion Loss: 0.0123 | Train Regularization: 2.0455\n",
            "Val Weighted Sentiment Loss: 0.1547 | Val Weighted Emotion Loss: 0.0146 | Val Regularization: 2.0455\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4155 | Val Loss: 0.3901\n",
            "Train Sentiment Loss: 0.8619 | Train Emotion Loss: 0.0999\n",
            "Val Sentiment Loss: 0.8020 | Val Emotion Loss: 0.0825\n",
            "Sentiment Weight: 0.1248 | Emotion Weight: 1.0388\n",
            "Train Weighted Sentiment Loss: 0.1076 | Train Weighted Emotion Loss: 0.0125 | Train Regularization: 2.0430\n",
            "Val Weighted Sentiment Loss: 0.1001 | Val Weighted Emotion Loss: 0.0103 | Val Regularization: 2.0430\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4161 | Val Loss: 0.3957\n",
            "Train Sentiment Loss: 0.8678 | Train Emotion Loss: 0.0998\n",
            "Val Sentiment Loss: 0.8435 | Val Emotion Loss: 0.0830\n",
            "Sentiment Weight: 0.1247 | Emotion Weight: 1.0396\n",
            "Train Weighted Sentiment Loss: 0.1082 | Train Weighted Emotion Loss: 0.0124 | Train Regularization: 2.0432\n",
            "Val Weighted Sentiment Loss: 0.1052 | Val Weighted Emotion Loss: 0.0103 | Val Regularization: 2.0432\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4151 | Val Loss: 0.3894\n",
            "Train Sentiment Loss: 0.8687 | Train Emotion Loss: 0.0988\n",
            "Val Sentiment Loss: 0.7941 | Val Emotion Loss: 0.0829\n",
            "Sentiment Weight: 0.1247 | Emotion Weight: 1.0472\n",
            "Train Weighted Sentiment Loss: 0.1083 | Train Weighted Emotion Loss: 0.0123 | Train Regularization: 2.0358\n",
            "Val Weighted Sentiment Loss: 0.0990 | Val Weighted Emotion Loss: 0.0103 | Val Regularization: 2.0358\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4164 | Val Loss: 0.3947\n",
            "Train Sentiment Loss: 0.8771 | Train Emotion Loss: 0.0990\n",
            "Val Sentiment Loss: 0.8204 | Val Emotion Loss: 0.0848\n",
            "Sentiment Weight: 0.1241 | Emotion Weight: 1.0486\n",
            "Train Weighted Sentiment Loss: 0.1089 | Train Weighted Emotion Loss: 0.0123 | Train Regularization: 2.0389\n",
            "Val Weighted Sentiment Loss: 0.1018 | Val Weighted Emotion Loss: 0.0105 | Val Regularization: 2.0389\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4152 | Val Loss: 0.3899\n",
            "Train Sentiment Loss: 0.8674 | Train Emotion Loss: 0.0990\n",
            "Val Sentiment Loss: 0.8029 | Val Emotion Loss: 0.0823\n",
            "Sentiment Weight: 0.1244 | Emotion Weight: 1.0456\n",
            "Train Weighted Sentiment Loss: 0.1079 | Train Weighted Emotion Loss: 0.0123 | Train Regularization: 2.0393\n",
            "Val Weighted Sentiment Loss: 0.0999 | Val Weighted Emotion Loss: 0.0102 | Val Regularization: 2.0393\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4155 | Val Loss: 0.3907\n",
            "Train Sentiment Loss: 0.8699 | Train Emotion Loss: 0.0990\n",
            "Val Sentiment Loss: 0.8027 | Val Emotion Loss: 0.0831\n",
            "Sentiment Weight: 0.1246 | Emotion Weight: 1.0472\n",
            "Train Weighted Sentiment Loss: 0.1084 | Train Weighted Emotion Loss: 0.0123 | Train Regularization: 2.0368\n",
            "Val Weighted Sentiment Loss: 0.1000 | Val Weighted Emotion Loss: 0.0103 | Val Regularization: 2.0368\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4154 | Val Loss: 0.3914\n",
            "Train Sentiment Loss: 0.8682 | Train Emotion Loss: 0.0991\n",
            "Val Sentiment Loss: 0.8067 | Val Emotion Loss: 0.0833\n",
            "Sentiment Weight: 0.1248 | Emotion Weight: 1.0468\n",
            "Train Weighted Sentiment Loss: 0.1084 | Train Weighted Emotion Loss: 0.0124 | Train Regularization: 2.0350\n",
            "Val Weighted Sentiment Loss: 0.1007 | Val Weighted Emotion Loss: 0.0104 | Val Regularization: 2.0350\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4177 | Val Loss: 0.3937\n",
            "Train Sentiment Loss: 0.8731 | Train Emotion Loss: 0.1007\n",
            "Val Sentiment Loss: 0.8267 | Val Emotion Loss: 0.0830\n",
            "Sentiment Weight: 0.1245 | Emotion Weight: 1.0385\n",
            "Train Weighted Sentiment Loss: 0.1087 | Train Weighted Emotion Loss: 0.0125 | Train Regularization: 2.0456\n",
            "Val Weighted Sentiment Loss: 0.1029 | Val Weighted Emotion Loss: 0.0103 | Val Regularization: 2.0456\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4226 | Val Loss: 0.3940\n",
            "Train Sentiment Loss: 0.8820 | Train Emotion Loss: 0.1045\n",
            "Val Sentiment Loss: 0.8316 | Val Emotion Loss: 0.0822\n",
            "Sentiment Weight: 0.1236 | Emotion Weight: 1.0045\n",
            "Train Weighted Sentiment Loss: 0.1091 | Train Weighted Emotion Loss: 0.0129 | Train Regularization: 2.0858\n",
            "Val Weighted Sentiment Loss: 0.1028 | Val Weighted Emotion Loss: 0.0102 | Val Regularization: 2.0858\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4565 | Val Loss: 0.3947\n",
            "Train Sentiment Loss: 1.0765 | Train Emotion Loss: 0.1148\n",
            "Val Sentiment Loss: 0.8344 | Val Emotion Loss: 0.0824\n",
            "Sentiment Weight: 0.1194 | Emotion Weight: 0.9932\n",
            "Train Weighted Sentiment Loss: 0.1286 | Train Weighted Emotion Loss: 0.0137 | Train Regularization: 2.1319\n",
            "Val Weighted Sentiment Loss: 0.0996 | Val Weighted Emotion Loss: 0.0098 | Val Regularization: 2.1319\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4125 | Val Loss: 0.3906\n",
            "Train Sentiment Loss: 0.8652 | Train Emotion Loss: 0.0967\n",
            "Val Sentiment Loss: 0.8069 | Val Emotion Loss: 0.0817\n",
            "Sentiment Weight: 0.1199 | Emotion Weight: 0.9980\n",
            "Train Weighted Sentiment Loss: 0.1038 | Train Weighted Emotion Loss: 0.0116 | Train Regularization: 2.1228\n",
            "Val Weighted Sentiment Loss: 0.0968 | Val Weighted Emotion Loss: 0.0098 | Val Regularization: 2.1228\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4090 | Val Loss: 0.3896\n",
            "Train Sentiment Loss: 0.8476 | Train Emotion Loss: 0.0953\n",
            "Val Sentiment Loss: 0.7984 | Val Emotion Loss: 0.0819\n",
            "Sentiment Weight: 0.1207 | Emotion Weight: 1.0056\n",
            "Train Weighted Sentiment Loss: 0.1023 | Train Weighted Emotion Loss: 0.0115 | Train Regularization: 2.1092\n",
            "Val Weighted Sentiment Loss: 0.0963 | Val Weighted Emotion Loss: 0.0099 | Val Regularization: 2.1092\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4087 | Val Loss: 0.3891\n",
            "Train Sentiment Loss: 0.8488 | Train Emotion Loss: 0.0949\n",
            "Val Sentiment Loss: 0.8009 | Val Emotion Loss: 0.0813\n",
            "Sentiment Weight: 0.1213 | Emotion Weight: 1.0148\n",
            "Train Weighted Sentiment Loss: 0.1030 | Train Weighted Emotion Loss: 0.0115 | Train Regularization: 2.0946\n",
            "Val Weighted Sentiment Loss: 0.0972 | Val Weighted Emotion Loss: 0.0099 | Val Regularization: 2.0946\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4072 | Val Loss: 0.3914\n",
            "Train Sentiment Loss: 0.8340 | Train Emotion Loss: 0.0952\n",
            "Val Sentiment Loss: 0.8054 | Val Emotion Loss: 0.0831\n",
            "Sentiment Weight: 0.1222 | Emotion Weight: 1.0241\n",
            "Train Weighted Sentiment Loss: 0.1019 | Train Weighted Emotion Loss: 0.0116 | Train Regularization: 2.0782\n",
            "Val Weighted Sentiment Loss: 0.0984 | Val Weighted Emotion Loss: 0.0102 | Val Regularization: 2.0782\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4065 | Val Loss: 0.3879\n",
            "Train Sentiment Loss: 0.8348 | Train Emotion Loss: 0.0945\n",
            "Val Sentiment Loss: 0.8005 | Val Emotion Loss: 0.0805\n",
            "Sentiment Weight: 0.1230 | Emotion Weight: 1.0354\n",
            "Train Weighted Sentiment Loss: 0.1027 | Train Weighted Emotion Loss: 0.0116 | Train Regularization: 2.0606\n",
            "Val Weighted Sentiment Loss: 0.0985 | Val Weighted Emotion Loss: 0.0099 | Val Regularization: 2.0606\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4054 | Val Loss: 0.3879\n",
            "Train Sentiment Loss: 0.8280 | Train Emotion Loss: 0.0942\n",
            "Val Sentiment Loss: 0.7951 | Val Emotion Loss: 0.0814\n",
            "Sentiment Weight: 0.1239 | Emotion Weight: 1.0467\n",
            "Train Weighted Sentiment Loss: 0.1026 | Train Weighted Emotion Loss: 0.0117 | Train Regularization: 2.0424\n",
            "Val Weighted Sentiment Loss: 0.0985 | Val Weighted Emotion Loss: 0.0101 | Val Regularization: 2.0424\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4052 | Val Loss: 0.3888\n",
            "Train Sentiment Loss: 0.8239 | Train Emotion Loss: 0.0945\n",
            "Val Sentiment Loss: 0.7988 | Val Emotion Loss: 0.0819\n",
            "Sentiment Weight: 0.1248 | Emotion Weight: 1.0556\n",
            "Train Weighted Sentiment Loss: 0.1029 | Train Weighted Emotion Loss: 0.0118 | Train Regularization: 2.0267\n",
            "Val Weighted Sentiment Loss: 0.0997 | Val Weighted Emotion Loss: 0.0102 | Val Regularization: 2.0267\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4035 | Val Loss: 0.3873\n",
            "Train Sentiment Loss: 0.8186 | Train Emotion Loss: 0.0934\n",
            "Val Sentiment Loss: 0.7953 | Val Emotion Loss: 0.0810\n",
            "Sentiment Weight: 0.1258 | Emotion Weight: 1.0665\n",
            "Train Weighted Sentiment Loss: 0.1030 | Train Weighted Emotion Loss: 0.0118 | Train Regularization: 2.0085\n",
            "Val Weighted Sentiment Loss: 0.1001 | Val Weighted Emotion Loss: 0.0102 | Val Regularization: 2.0085\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4036 | Val Loss: 0.3870\n",
            "Train Sentiment Loss: 0.8179 | Train Emotion Loss: 0.0936\n",
            "Val Sentiment Loss: 0.7914 | Val Emotion Loss: 0.0813\n",
            "Sentiment Weight: 0.1266 | Emotion Weight: 1.0737\n",
            "Train Weighted Sentiment Loss: 0.1035 | Train Weighted Emotion Loss: 0.0119 | Train Regularization: 1.9958\n",
            "Val Weighted Sentiment Loss: 0.1002 | Val Weighted Emotion Loss: 0.0103 | Val Regularization: 1.9958\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4050 | Val Loss: 0.3893\n",
            "Train Sentiment Loss: 0.8223 | Train Emotion Loss: 0.0944\n",
            "Val Sentiment Loss: 0.7984 | Val Emotion Loss: 0.0826\n",
            "Sentiment Weight: 0.1269 | Emotion Weight: 1.0760\n",
            "Train Weighted Sentiment Loss: 0.1044 | Train Weighted Emotion Loss: 0.0120 | Train Regularization: 1.9910\n",
            "Val Weighted Sentiment Loss: 0.1013 | Val Weighted Emotion Loss: 0.0105 | Val Regularization: 1.9910\n",
            "\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4059 | Val Loss: 0.3865\n",
            "Train Sentiment Loss: 0.8292 | Train Emotion Loss: 0.0944\n",
            "Val Sentiment Loss: 0.7894 | Val Emotion Loss: 0.0811\n",
            "Sentiment Weight: 0.1268 | Emotion Weight: 1.0773\n",
            "Train Weighted Sentiment Loss: 0.1051 | Train Weighted Emotion Loss: 0.0120 | Train Regularization: 1.9908\n",
            "Val Weighted Sentiment Loss: 0.1001 | Val Weighted Emotion Loss: 0.0103 | Val Regularization: 1.9908\n",
            "\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4035 | Val Loss: 0.3884\n",
            "Train Sentiment Loss: 0.8158 | Train Emotion Loss: 0.0937\n",
            "Val Sentiment Loss: 0.7988 | Val Emotion Loss: 0.0818\n",
            "Sentiment Weight: 0.1274 | Emotion Weight: 1.0808\n",
            "Train Weighted Sentiment Loss: 0.1039 | Train Weighted Emotion Loss: 0.0119 | Train Regularization: 1.9830\n",
            "Val Weighted Sentiment Loss: 0.1017 | Val Weighted Emotion Loss: 0.0104 | Val Regularization: 1.9830\n",
            "\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4026 | Val Loss: 0.3886\n",
            "Train Sentiment Loss: 0.8133 | Train Emotion Loss: 0.0932\n",
            "Val Sentiment Loss: 0.7983 | Val Emotion Loss: 0.0821\n",
            "Sentiment Weight: 0.1279 | Emotion Weight: 1.0857\n",
            "Train Weighted Sentiment Loss: 0.1040 | Train Weighted Emotion Loss: 0.0119 | Train Regularization: 1.9744\n",
            "Val Weighted Sentiment Loss: 0.1021 | Val Weighted Emotion Loss: 0.0105 | Val Regularization: 1.9744\n",
            "\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4033 | Val Loss: 0.3868\n",
            "Train Sentiment Loss: 0.8193 | Train Emotion Loss: 0.0931\n",
            "Val Sentiment Loss: 0.7932 | Val Emotion Loss: 0.0810\n",
            "Sentiment Weight: 0.1278 | Emotion Weight: 1.0892\n",
            "Train Weighted Sentiment Loss: 0.1047 | Train Weighted Emotion Loss: 0.0119 | Train Regularization: 1.9715\n",
            "Val Weighted Sentiment Loss: 0.1014 | Val Weighted Emotion Loss: 0.0104 | Val Regularization: 1.9715\n",
            "\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4028 | Val Loss: 0.3877\n",
            "Train Sentiment Loss: 0.8159 | Train Emotion Loss: 0.0930\n",
            "Val Sentiment Loss: 0.7935 | Val Emotion Loss: 0.0819\n",
            "Sentiment Weight: 0.1280 | Emotion Weight: 1.0914\n",
            "Train Weighted Sentiment Loss: 0.1044 | Train Weighted Emotion Loss: 0.0119 | Train Regularization: 1.9684\n",
            "Val Weighted Sentiment Loss: 0.1015 | Val Weighted Emotion Loss: 0.0105 | Val Regularization: 1.9684\n",
            "\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4021 | Val Loss: 0.3871\n",
            "Train Sentiment Loss: 0.8113 | Train Emotion Loss: 0.0929\n",
            "Val Sentiment Loss: 0.7903 | Val Emotion Loss: 0.0817\n",
            "Sentiment Weight: 0.1284 | Emotion Weight: 1.0933\n",
            "Train Weighted Sentiment Loss: 0.1041 | Train Weighted Emotion Loss: 0.0119 | Train Regularization: 1.9637\n",
            "Val Weighted Sentiment Loss: 0.1014 | Val Weighted Emotion Loss: 0.0105 | Val Regularization: 1.9637\n",
            "\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4024 | Val Loss: 0.3857\n",
            "Train Sentiment Loss: 0.8115 | Train Emotion Loss: 0.0931\n",
            "Val Sentiment Loss: 0.7841 | Val Emotion Loss: 0.0811\n",
            "Sentiment Weight: 0.1286 | Emotion Weight: 1.0935\n",
            "Train Weighted Sentiment Loss: 0.1044 | Train Weighted Emotion Loss: 0.0120 | Train Regularization: 1.9615\n",
            "Val Weighted Sentiment Loss: 0.1008 | Val Weighted Emotion Loss: 0.0104 | Val Regularization: 1.9615\n",
            "\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4012 | Val Loss: 0.3883\n",
            "Train Sentiment Loss: 0.8073 | Train Emotion Loss: 0.0925\n",
            "Val Sentiment Loss: 0.7956 | Val Emotion Loss: 0.0822\n",
            "Sentiment Weight: 0.1289 | Emotion Weight: 1.0962\n",
            "Train Weighted Sentiment Loss: 0.1041 | Train Weighted Emotion Loss: 0.0119 | Train Regularization: 1.9568\n",
            "Val Weighted Sentiment Loss: 0.1026 | Val Weighted Emotion Loss: 0.0106 | Val Regularization: 1.9568\n",
            "\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4021 | Val Loss: 0.3869\n",
            "Train Sentiment Loss: 0.8098 | Train Emotion Loss: 0.0931\n",
            "Val Sentiment Loss: 0.7865 | Val Emotion Loss: 0.0820\n",
            "Sentiment Weight: 0.1291 | Emotion Weight: 1.0957\n",
            "Train Weighted Sentiment Loss: 0.1045 | Train Weighted Emotion Loss: 0.0120 | Train Regularization: 1.9557\n",
            "Val Weighted Sentiment Loss: 0.1015 | Val Weighted Emotion Loss: 0.0106 | Val Regularization: 1.9557\n",
            "\n",
            "Epoch 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4003 | Val Loss: 0.3843\n",
            "Train Sentiment Loss: 0.8029 | Train Emotion Loss: 0.0923\n",
            "Val Sentiment Loss: 0.7864 | Val Emotion Loss: 0.0796\n",
            "Sentiment Weight: 0.1295 | Emotion Weight: 1.0988\n",
            "Train Weighted Sentiment Loss: 0.1040 | Train Weighted Emotion Loss: 0.0120 | Train Regularization: 1.9498\n",
            "Val Weighted Sentiment Loss: 0.1018 | Val Weighted Emotion Loss: 0.0103 | Val Regularization: 1.9498\n",
            "\n",
            "Epoch 38/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4010 | Val Loss: 0.3872\n",
            "Train Sentiment Loss: 0.8039 | Train Emotion Loss: 0.0927\n",
            "Val Sentiment Loss: 0.7967 | Val Emotion Loss: 0.0810\n",
            "Sentiment Weight: 0.1298 | Emotion Weight: 1.0986\n",
            "Train Weighted Sentiment Loss: 0.1043 | Train Weighted Emotion Loss: 0.0120 | Train Regularization: 1.9480\n",
            "Val Weighted Sentiment Loss: 0.1034 | Val Weighted Emotion Loss: 0.0105 | Val Regularization: 1.9480\n",
            "\n",
            "Epoch 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3984 | Val Loss: 0.3861\n",
            "Train Sentiment Loss: 0.7942 | Train Emotion Loss: 0.0915\n",
            "Val Sentiment Loss: 0.7909 | Val Emotion Loss: 0.0808\n",
            "Sentiment Weight: 0.1305 | Emotion Weight: 1.1044\n",
            "Train Weighted Sentiment Loss: 0.1036 | Train Weighted Emotion Loss: 0.0119 | Train Regularization: 1.9373\n",
            "Val Weighted Sentiment Loss: 0.1032 | Val Weighted Emotion Loss: 0.0105 | Val Regularization: 1.9373\n",
            "\n",
            "Epoch 40/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3998 | Val Loss: 0.3898\n",
            "Train Sentiment Loss: 0.8022 | Train Emotion Loss: 0.0918\n",
            "Val Sentiment Loss: 0.7985 | Val Emotion Loss: 0.0832\n",
            "Sentiment Weight: 0.1304 | Emotion Weight: 1.1063\n",
            "Train Weighted Sentiment Loss: 0.1046 | Train Weighted Emotion Loss: 0.0120 | Train Regularization: 1.9359\n",
            "Val Weighted Sentiment Loss: 0.1041 | Val Weighted Emotion Loss: 0.0109 | Val Regularization: 1.9359\n",
            "\n",
            "Epoch 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4008 | Val Loss: 0.3897\n",
            "Train Sentiment Loss: 0.8051 | Train Emotion Loss: 0.0924\n",
            "Val Sentiment Loss: 0.7962 | Val Emotion Loss: 0.0834\n",
            "Sentiment Weight: 0.1303 | Emotion Weight: 1.1045\n",
            "Train Weighted Sentiment Loss: 0.1049 | Train Weighted Emotion Loss: 0.0120 | Train Regularization: 1.9386\n",
            "Val Weighted Sentiment Loss: 0.1037 | Val Weighted Emotion Loss: 0.0109 | Val Regularization: 1.9386\n",
            "\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4000 | Val Loss: 0.3868\n",
            "Train Sentiment Loss: 0.7964 | Train Emotion Loss: 0.0927\n",
            "Val Sentiment Loss: 0.7965 | Val Emotion Loss: 0.0807\n",
            "Sentiment Weight: 0.1307 | Emotion Weight: 1.1022\n",
            "Train Weighted Sentiment Loss: 0.1041 | Train Weighted Emotion Loss: 0.0121 | Train Regularization: 1.9377\n",
            "Val Weighted Sentiment Loss: 0.1041 | Val Weighted Emotion Loss: 0.0105 | Val Regularization: 1.9377\n",
            "\n",
            "Epoch 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3992 | Val Loss: 0.3862\n",
            "Train Sentiment Loss: 0.7958 | Train Emotion Loss: 0.0920\n",
            "Val Sentiment Loss: 0.7905 | Val Emotion Loss: 0.0809\n",
            "Sentiment Weight: 0.1310 | Emotion Weight: 1.1042\n",
            "Train Weighted Sentiment Loss: 0.1042 | Train Weighted Emotion Loss: 0.0121 | Train Regularization: 1.9336\n",
            "Val Weighted Sentiment Loss: 0.1035 | Val Weighted Emotion Loss: 0.0106 | Val Regularization: 1.9336\n",
            "\n",
            "Epoch 44/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3981 | Val Loss: 0.3871\n",
            "Train Sentiment Loss: 0.7969 | Train Emotion Loss: 0.0909\n",
            "Val Sentiment Loss: 0.7840 | Val Emotion Loss: 0.0825\n",
            "Sentiment Weight: 0.1306 | Emotion Weight: 1.1058\n",
            "Train Weighted Sentiment Loss: 0.1041 | Train Weighted Emotion Loss: 0.0119 | Train Regularization: 1.9348\n",
            "Val Weighted Sentiment Loss: 0.1024 | Val Weighted Emotion Loss: 0.0108 | Val Regularization: 1.9348\n",
            "\n",
            "Epoch 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3963 | Val Loss: 0.3887\n",
            "Train Sentiment Loss: 0.7855 | Train Emotion Loss: 0.0906\n",
            "Val Sentiment Loss: 0.7821 | Val Emotion Loss: 0.0842\n",
            "Sentiment Weight: 0.1308 | Emotion Weight: 1.1081\n",
            "Train Weighted Sentiment Loss: 0.1027 | Train Weighted Emotion Loss: 0.0118 | Train Regularization: 1.9318\n",
            "Val Weighted Sentiment Loss: 0.1023 | Val Weighted Emotion Loss: 0.0110 | Val Regularization: 1.9318\n",
            "\n",
            "Epoch 46/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3946 | Val Loss: 0.3856\n",
            "Train Sentiment Loss: 0.7777 | Train Emotion Loss: 0.0900\n",
            "Val Sentiment Loss: 0.7850 | Val Emotion Loss: 0.0811\n",
            "Sentiment Weight: 0.1311 | Emotion Weight: 1.1114\n",
            "Train Weighted Sentiment Loss: 0.1019 | Train Weighted Emotion Loss: 0.0118 | Train Regularization: 1.9262\n",
            "Val Weighted Sentiment Loss: 0.1029 | Val Weighted Emotion Loss: 0.0106 | Val Regularization: 1.9262\n",
            "\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3934 | Val Loss: 0.3864\n",
            "Train Sentiment Loss: 0.7700 | Train Emotion Loss: 0.0898\n",
            "Val Sentiment Loss: 0.7849 | Val Emotion Loss: 0.0818\n",
            "Sentiment Weight: 0.1316 | Emotion Weight: 1.1143\n",
            "Train Weighted Sentiment Loss: 0.1013 | Train Weighted Emotion Loss: 0.0118 | Train Regularization: 1.9197\n",
            "Val Weighted Sentiment Loss: 0.1033 | Val Weighted Emotion Loss: 0.0108 | Val Regularization: 1.9197\n",
            "\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_train_res = load('/content/drive/MyDrive/model/video_train_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Video training time per batch (ms): {sum(video_train_res['training_times']) / len(video_train_res['training_times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPAROOQvOgnE",
        "outputId": "7c601c3d-adcb-4b65-ada2-38bc2ee21793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video training time per batch (ms): 5.530866361723587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_test_res = uni_test_model(video_model, testdata, loss_fn, modality='video', save_path=video_model_path, mean_sentiment_loss=video_mean_sentiment_loss, mean_emotion_loss=video_mean_emotion_loss)\n",
        "\n",
        "save(video_test_res, '/content/drive/MyDrive/model/video_test_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjAMtCx8y8k-",
        "outputId": "ca1811b2-eed8-4015-a998-e6e84b1241d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e0ca022d749b>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(save_path))\n",
            "                                                                   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Metrics:\n",
            "Total Loss: 0.4125\n",
            "Total MAE: 0.5056\n",
            "Sentiment MAE: 0.8142\n",
            "Sentiment PCC: 0.2739\n",
            "Emotion MAE: 0.1970\n",
            "Emotion R: 0.0455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_test_res = load('/content/drive/MyDrive/model/video_test_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Video testing time per batch (ms): {sum(video_test_res['Testing Times']) / len(video_test_res['Testing Times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jtcQMsxWV5b",
        "outputId": "9520cc7c-ee16-4b46-8ab7-b00329b12fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video testing time per batch (ms): 2.4455508140668476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal"
      ],
      "metadata": {
        "id": "27bL79CFjHk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_dims (dict): Dictionary with input dimensions for each modality, e.g., {'text': 300, 'audio': 74, 'video': 713}.\n",
        "class MultiModel(nn.Module):\n",
        "    def __init__(self, input_dims, hidden_dim, attention_dim, sentiment_out_dim=1, emotion_out_dim=6, dropout_rate=0.3):\n",
        "        super(MultiModel, self).__init__()\n",
        "        self.modalities = list(input_dims.keys())\n",
        "\n",
        "        # Modality-specific encoders\n",
        "        self.encoders = nn.ModuleDict({\n",
        "            modality: nn.Sequential(\n",
        "                nn.Linear(input_dims[modality], hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            )\n",
        "            for modality in self.modalities\n",
        "        })\n",
        "\n",
        "        # Cross-attention fusion: Query, Key, Value layers for each modality (each modality can attend seperately to all 3 modalities, including itself)\n",
        "        # With dropout\n",
        "        self.query_layers = nn.ModuleDict({\n",
        "            modality: nn.Linear(hidden_dim, attention_dim) for modality in self.modalities\n",
        "        })\n",
        "        self.key_layers = nn.ModuleDict({\n",
        "            modality: nn.Linear(hidden_dim, attention_dim) for modality in self.modalities\n",
        "        })\n",
        "        self.value_layers = nn.ModuleDict({\n",
        "            modality: nn.Linear(hidden_dim, attention_dim) for modality in self.modalities\n",
        "        })\n",
        "        self.fusion_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Scaled-dot attention pooling (with dropout)\n",
        "        self.pool_query = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.pool_key = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.pool_value = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.pool_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Task-specific decoders\n",
        "        self.sentiment_decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(128, sentiment_out_dim)\n",
        "        )\n",
        "        self.emotion_decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(64, emotion_out_dim)\n",
        "        )\n",
        "\n",
        "    # batch (dict): Dictionary containing modality-specific tensors\n",
        "    def forward(self, batch):\n",
        "        device = next(self.parameters()).device  # Ensure computations are on the same device\n",
        "\n",
        "        # Encode inputs for each active modality\n",
        "        encoded_features = {\n",
        "            modality: self.encoders[modality](batch[modality].to(device))\n",
        "            for modality in self.modalities\n",
        "        }\n",
        "\n",
        "        # Prepare query, key, value for cross-attention\n",
        "        Q = {modality: self.query_layers[modality](encoded_features[modality]) for modality in self.modalities}\n",
        "        K = {modality: self.key_layers[modality](encoded_features[modality]) for modality in self.modalities}\n",
        "        V = {modality: self.value_layers[modality](encoded_features[modality]) for modality in self.modalities}\n",
        "\n",
        "        # Cross-attention fusion\n",
        "        fused_features = []\n",
        "        fuse_attention_scores = {}\n",
        "        for query_modality in self.modalities:\n",
        "            query = Q[query_modality]\n",
        "            scores = []\n",
        "            values = []\n",
        "            for key_modality in self.modalities:\n",
        "                attention_score = torch.matmul(query, K[key_modality].transpose(-2, -1)) / torch.sqrt(torch.tensor(query.size(-1), dtype=torch.float32))\n",
        "                attention_weight = F.softmax(attention_score, dim=-1)\n",
        "                attention_value = torch.matmul(attention_weight, V[key_modality])\n",
        "                scores.append(attention_weight)\n",
        "                values.append(attention_value)\n",
        "            # Aggregate values and scores for the query modality\n",
        "            fused_features.append(sum(values))\n",
        "            fuse_attention_scores[query_modality] = scores  # Store all scores for interpretability\n",
        "\n",
        "        # Combine fused features across all modalities\n",
        "        fused_features = torch.stack(fused_features, dim=0).mean(dim=0)\n",
        "        fused_features = self.fusion_dropout(fused_features)\n",
        "\n",
        "        # Scaled-dot attention pooling\n",
        "        pool_query = self.pool_query(fused_features)\n",
        "        pool_key = self.pool_key(fused_features)\n",
        "        pool_value = self.pool_value(fused_features)\n",
        "        pool_attention_score = torch.matmul(pool_query, pool_key.transpose(-2, -1)) / torch.sqrt(torch.tensor(pool_query.size(-1), dtype=torch.float32))\n",
        "        pool_attention_weight = F.softmax(pool_attention_score, dim=-1)\n",
        "        pooled_features = torch.matmul(pool_attention_weight, pool_value).mean(dim=1)\n",
        "        pooled_features = self.pool_dropout(pooled_features)\n",
        "\n",
        "        # Task-specific decoders\n",
        "        sentiment_output = self.sentiment_decoder(pooled_features)\n",
        "        emotion_output = self.emotion_decoder(pooled_features)\n",
        "\n",
        "        return sentiment_output, emotion_output, fuse_attention_scores"
      ],
      "metadata": {
        "id": "EtppG4rujGpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-compute mean MSE losses for sentiment and emotion tasks across train dataset (multimodal version)\n",
        "# modalities: List of active modalities, e.g., ['text', 'audio'].\n",
        "def multi_mean_losses(model, train_loader, modalities):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Mapping modality to the corresponding index in the dataloader's output\n",
        "    modality_indices = {'video': 0, 'audio': 1, 'text': 2}\n",
        "\n",
        "    total_sentiment_loss = 0.0\n",
        "    total_emotion_loss = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch in tqdm(train_loader, desc=f\"Pre-training (Multimodal: {modalities})\", leave=False):\n",
        "            # Extract modalities and labels\n",
        "            inputs = {\n",
        "                modality: batch[modality_indices[modality]].to(device) for modality in modalities\n",
        "            }\n",
        "            labels = batch[3].to(device)  # Assuming labels are always at index 3\n",
        "            sentiment_targets = labels[:, 0].to(device)  # Sentiment is the first column\n",
        "            emotion_targets = labels[:, 1:].to(device)  # Emotions are the remaining columns\n",
        "\n",
        "            # Forward pass\n",
        "            sentiment_preds, emotion_preds, _ = model(inputs)\n",
        "\n",
        "            # Compute losses for the batch\n",
        "            sentiment_loss = F.mse_loss(sentiment_preds.squeeze(), sentiment_targets, reduction='sum')  # Sum across batch\n",
        "            emotion_loss = F.mse_loss(emotion_preds, emotion_targets, reduction='sum')  # Sum across batch\n",
        "\n",
        "            # Accumulate losses\n",
        "            total_sentiment_loss += sentiment_loss.item()\n",
        "            total_emotion_loss += emotion_loss.item()\n",
        "            total_batches += labels.size(0)  # Count the number of samples in the batch\n",
        "\n",
        "    # Compute mean losses\n",
        "    mean_sentiment_loss = total_sentiment_loss / total_batches\n",
        "    mean_emotion_loss = total_emotion_loss / total_batches\n",
        "\n",
        "    return mean_sentiment_loss, mean_emotion_loss"
      ],
      "metadata": {
        "id": "a4LhFa_o57qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_dims (dict): Dictionary with input dimensions for each modality, e.g., {'text': 300, 'audio': 74, 'video': 713}.\n",
        "def multi_avg_mean_losses(traindata, input_dims, hidden_dim, attention_dim):\n",
        "    modalities = list(input_dims.keys())\n",
        "\n",
        "    mean_sentiment_losses = []\n",
        "    mean_emotion_losses = []\n",
        "\n",
        "    for _ in range(5):  # Repeat computation 5 times\n",
        "        model = MultiModel(input_dims, hidden_dim, attention_dim)  # Instantiate multimodal model\n",
        "        mean_sentiment_loss, mean_emotion_loss = multi_mean_losses(model, traindata, modalities)\n",
        "        mean_sentiment_losses.append(mean_sentiment_loss)\n",
        "        mean_emotion_losses.append(mean_emotion_loss)\n",
        "\n",
        "    # Compute averaged mean losses\n",
        "    final_mean_sentiment_loss = sum(mean_sentiment_losses) / len(mean_sentiment_losses)\n",
        "    final_mean_emotion_loss = sum(mean_emotion_losses) / len(mean_emotion_losses)\n",
        "\n",
        "    return final_mean_sentiment_loss, final_mean_emotion_loss"
      ],
      "metadata": {
        "id": "cpitNJTc65DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modalities: List of active modalities, e.g., ['text', 'audio'].\n",
        "def multi_train_model(model, train_loader, val_loader, epochs, optimizer, scheduler, loss_fn, save_path, modalities, mean_sentiment_loss, mean_emotion_loss):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # Move model and loss function to appropriate device\n",
        "    model.to(device)\n",
        "    loss_fn.to(device)\n",
        "\n",
        "    # Mapping modality to the corresponding index in the dataloader's output\n",
        "    modality_indices = {'video': 0, 'audio': 1, 'text': 2}\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    training_times = []\n",
        "    train_losses, val_losses = [], []\n",
        "    train_sentiment_losses, val_sentiment_losses = [], []\n",
        "    train_emotion_losses, val_emotion_losses = [], []\n",
        "    # List to store averaged attention scores for each epoch\n",
        "    epoch_attention_scores = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")  # Start from 1\n",
        "\n",
        "        # Training mode\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        epoch_train_sentiment_loss = 0\n",
        "        epoch_train_emotion_loss = 0\n",
        "\n",
        "        batch_attention_sums = {modality: [None] * len(modalities) for modality in modalities}\n",
        "        total_elements = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Training (Modalities: {modalities})\", leave=False):\n",
        "            # Extract modalities and labels\n",
        "            inputs = {modality: batch[modality_indices[modality]].to(device) for modality in modalities}\n",
        "            labels = batch[3].to(device)  # Labels assumed to be at index 3\n",
        "            sentiment_targets = labels[:, 0].to(device)  # Sentiment is the first column\n",
        "            emotion_targets = labels[:, 1:].to(device)  # Emotions are the remaining columns\n",
        "\n",
        "            # Forward pass (compute predictions and attention scores)\n",
        "            sentiment_preds, emotion_preds, attention_scores = model(inputs)\n",
        "            sentiment_loss = F.mse_loss(sentiment_preds.squeeze(), sentiment_targets) / mean_sentiment_loss\n",
        "            emotion_loss = F.mse_loss(emotion_preds, emotion_targets) / mean_emotion_loss\n",
        "            loss = loss_fn(sentiment_loss, emotion_loss)\n",
        "\n",
        "            # clears the gradients of all model parameters before the next backward pass\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Backward pass (update gradient)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss += loss.item()\n",
        "            epoch_train_sentiment_loss += sentiment_loss.item()\n",
        "            epoch_train_emotion_loss += emotion_loss.item()\n",
        "\n",
        "            # Accumulate attention scores\n",
        "            for modality, score_list in attention_scores.items():\n",
        "                for i, attention_matrix in enumerate(score_list):\n",
        "                    if batch_attention_sums[modality][i] is None:\n",
        "                        batch_attention_sums[modality][i] = attention_matrix.sum(dim=0)  # sum along batch size\n",
        "                    else:\n",
        "                        batch_attention_sums[modality][i] += attention_matrix.sum(dim=0)\n",
        "            total_elements += batch[0].size(0)\n",
        "\n",
        "        end_time = time.time()\n",
        "        avg_batch_time = (end_time - start_time) / len(train_loader)\n",
        "        training_times.append(avg_batch_time)\n",
        "\n",
        "        # Calculate average attention scores for the epoch\n",
        "        averaged_attention_scores = {modality: [None] * len(modalities) for modality in modalities}\n",
        "        for modality in batch_attention_sums:\n",
        "            for i in range(len(modalities)):\n",
        "                averaged_attention_scores[modality][i] = batch_attention_sums[modality][i] / total_elements\n",
        "\n",
        "        # Store the averaged matrices for the epoch\n",
        "        epoch_attention_scores.append(averaged_attention_scores)\n",
        "\n",
        "        # Validation mode\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0\n",
        "        epoch_val_sentiment_loss = 0\n",
        "        epoch_val_emotion_loss = 0\n",
        "        with torch.no_grad():  # Disable gradients in validation mode\n",
        "            for batch in tqdm(val_loader, desc=f\"Validation (Modalities: {modalities})\", leave=False):\n",
        "                # Extract modalities and labels\n",
        "                inputs = {modality: batch[modality_indices[modality]].to(device) for modality in modalities}\n",
        "                labels = batch[3].to(device)\n",
        "                sentiment_targets = labels[:, 0].to(device)\n",
        "                emotion_targets = labels[:, 1:].to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                sentiment_preds, emotion_preds, _ = model(inputs)\n",
        "                sentiment_loss = F.mse_loss(sentiment_preds.squeeze(), sentiment_targets) / mean_sentiment_loss\n",
        "                emotion_loss = F.mse_loss(emotion_preds, emotion_targets) / mean_emotion_loss\n",
        "                loss = loss_fn(sentiment_loss, emotion_loss)\n",
        "\n",
        "                epoch_val_loss += loss.item()\n",
        "                epoch_val_sentiment_loss += sentiment_loss.item()\n",
        "                epoch_val_emotion_loss += emotion_loss.item()\n",
        "\n",
        "        # Scheduler step\n",
        "        scheduler.step(epoch_val_loss)\n",
        "\n",
        "        # Log epoch results\n",
        "        train_losses.append(epoch_train_loss / len(train_loader))\n",
        "        val_losses.append(epoch_val_loss / len(val_loader))\n",
        "        train_sentiment_losses.append(epoch_train_sentiment_loss / len(train_loader))\n",
        "        val_sentiment_losses.append(epoch_val_sentiment_loss / len(val_loader))\n",
        "        train_emotion_losses.append(epoch_train_emotion_loss / len(train_loader))\n",
        "        val_emotion_losses.append(epoch_val_emotion_loss / len(val_loader))\n",
        "\n",
        "        print(f\"Train Loss: {train_losses[-1]:.4f} | Val Loss: {val_losses[-1]:.4f}\")\n",
        "        print(f\"Train Sentiment Loss: {train_sentiment_losses[-1]:.4f} | Train Emotion Loss: {train_emotion_losses[-1]:.4f}\")\n",
        "        print(f\"Val Sentiment Loss: {val_sentiment_losses[-1]:.4f} | Val Emotion Loss: {val_emotion_losses[-1]:.4f}\")\n",
        "        print()\n",
        "\n",
        "        # Early stopping\n",
        "        if val_losses[-1] < best_val_loss:\n",
        "            best_val_loss = val_losses[-1]\n",
        "            epochs_no_improve = 0\n",
        "            # Save the best model\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= 10:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    return {\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses,\n",
        "        \"train_sentiment_losses\": train_sentiment_losses,\n",
        "        \"val_sentiment_losses\": val_sentiment_losses,\n",
        "        \"train_emotion_losses\": train_emotion_losses,\n",
        "        \"val_emotion_losses\": val_emotion_losses,\n",
        "        \"training_times\": training_times,\n",
        "        \"epoch_attention_scores\": epoch_attention_scores\n",
        "    }"
      ],
      "metadata": {
        "id": "5LscuYFKCEG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_test_model(model, test_loader, loss_fn, modalities, save_path, mean_sentiment_loss, mean_emotion_loss):\n",
        "    # Load the best model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    model.to(device)\n",
        "    loss_fn.to(device)\n",
        "\n",
        "    # Modality index mapping\n",
        "    modality_indices = {'video': 0, 'audio': 1, 'text': 2}\n",
        "\n",
        "    model.eval()\n",
        "    # Initialize accumulators\n",
        "    total_loss = 0\n",
        "    testing_times = []\n",
        "    all_sentiment_preds, all_sentiment_targets = [], []\n",
        "    all_emotion_preds, all_emotion_targets = [], []\n",
        "\n",
        "    # List to store average attention scores for each batch\n",
        "    batch_attention_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        for batch in tqdm(test_loader, desc=f\"Testing (Modalities: {modalities})\", leave=False):\n",
        "            # Extract modalities and labels\n",
        "            inputs = {modality: batch[modality_indices[modality]].to(device) for modality in modalities}\n",
        "            labels = batch[3].to(device)  # Labels assumed to be at index 3\n",
        "            sentiment_targets = labels[:, 0].to(device)  # Sentiment is the first column\n",
        "            emotion_targets = labels[:, 1:].to(device)  # Emotions are the remaining columns\n",
        "\n",
        "            # Forward pass (with attention scores)\n",
        "            sentiment_preds, emotion_preds, attention_scores = model(inputs)\n",
        "\n",
        "            # Accumulate predictions and targets for metrics\n",
        "            all_sentiment_preds.extend(sentiment_preds.squeeze().cpu().numpy())\n",
        "            all_sentiment_targets.extend(sentiment_targets.cpu().numpy())\n",
        "            all_emotion_preds.extend(emotion_preds.cpu().numpy())\n",
        "            all_emotion_targets.extend(emotion_targets.cpu().numpy())\n",
        "\n",
        "            # Compute loss\n",
        "            sentiment_loss = F.mse_loss(sentiment_preds.squeeze(), sentiment_targets) / mean_sentiment_loss\n",
        "            emotion_loss = F.mse_loss(emotion_preds, emotion_targets) / mean_emotion_loss\n",
        "            loss = loss_fn(sentiment_loss, emotion_loss)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Log batch attention scores\n",
        "            batch_avg_attention = {}\n",
        "            for query_modality, score_list in attention_scores.items():\n",
        "                batch_avg_attention[query_modality] = [\n",
        "                    attention_matrix.mean(dim=0).cpu().numpy() for attention_matrix in score_list\n",
        "                ]\n",
        "            batch_attention_scores.append(batch_avg_attention)\n",
        "\n",
        "        end_time = time.time()\n",
        "        avg_batch_time = (end_time - start_time) / len(test_loader)\n",
        "        testing_times.append(avg_batch_time)\n",
        "\n",
        "    # Convert lists to numpy arrays for metric calculations\n",
        "    all_sentiment_preds = np.array(all_sentiment_preds)\n",
        "    all_sentiment_targets = np.array(all_sentiment_targets)\n",
        "    all_emotion_preds = np.array(all_emotion_preds)\n",
        "    all_emotion_targets = np.array(all_emotion_targets)\n",
        "\n",
        "    # Compute metrics\n",
        "    sentiment_mae = mean_absolute_error(all_sentiment_targets, all_sentiment_preds)\n",
        "    sentiment_pcc, _ = pearsonr(all_sentiment_targets, all_sentiment_preds)\n",
        "    emotion_mae = mean_absolute_error(all_emotion_targets, all_emotion_preds)\n",
        "    emotion_r2 = r2_score(all_emotion_targets, all_emotion_preds)\n",
        "\n",
        "    metrics = {\n",
        "        \"Total Loss\": total_loss / len(test_loader),\n",
        "        \"Total MAE\": (sentiment_mae + emotion_mae) / 2,\n",
        "        \"Sentiment MAE\": sentiment_mae,\n",
        "        \"Sentiment PCC\": sentiment_pcc,\n",
        "        \"Emotion MAE\": emotion_mae,\n",
        "        \"Emotion R\": emotion_r2\n",
        "    }\n",
        "\n",
        "    print(\"\\nTest Metrics:\")\n",
        "    for key, value in metrics.items():\n",
        "        print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "    metrics['Testing Times'] = testing_times\n",
        "    metrics['Batch Attention Scores'] = batch_attention_scores\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "eCsahixYFdxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "W7XQ9eI8K6rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_path = \"/content/drive/MyDrive/model\"\n",
        "\n",
        "hidden_dim = 256\n",
        "attention_dim = 256\n",
        "\n",
        "loss_fn = MultitaskLossWithUncertainty()"
      ],
      "metadata": {
        "id": "VHxJ_op1Fj9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_audio_input_dims = {'text': 300, 'audio': 74}\n",
        "\n",
        "# Compute mean losses in train dataset\n",
        "text_audio_mean_sentiment_loss, text_audio_mean_emotion_loss = multi_avg_mean_losses(traindata, text_audio_input_dims, hidden_dim, attention_dim)\n",
        "\n",
        "print(f\"Text + Audio Mean Sentiment Loss: {text_audio_mean_sentiment_loss:.4f}\")\n",
        "print(f\"Text + Audio Mean Emotion Loss: {text_audio_mean_emotion_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JfmjyR8J_Wo",
        "outputId": "3a2e3d91-4b51-4443-9ee4-3c9cfbcb2b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                                "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text + Audio Mean Sentiment Loss: 1.2907\n",
            "Text + Audio Mean Emotion Loss: 1.1204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_audio_model = MultiModel(text_audio_input_dims, hidden_dim, attention_dim)\n",
        "text_audio_optimizer = AdamW([\n",
        "    {'params': text_audio_model.parameters()},\n",
        "    {'params': [loss_fn.log_sigma_sentiment, loss_fn.log_sigma_emotion]}\n",
        "], lr=0.001, weight_decay=0.01)\n",
        "text_audio_scheduler = ReduceLROnPlateau(text_audio_optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# Save path for the trained model\n",
        "text_audio_model_path = os.path.join(save_model_path, \"text_audio.pth\")"
      ],
      "metadata": {
        "id": "gitpWm2LXw6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_audio_train_res = multi_train_model(\n",
        "    text_audio_model, traindata, validdata, epochs=50, optimizer=text_audio_optimizer,\n",
        "    scheduler=text_audio_scheduler, loss_fn=loss_fn, save_path=text_audio_model_path, modalities=['text', 'audio'],\n",
        "    mean_sentiment_loss=text_audio_mean_sentiment_loss, mean_emotion_loss=text_audio_mean_emotion_loss\n",
        ")\n",
        "\n",
        "save(text_audio_train_res, '/content/drive/MyDrive/model/text_audio_train_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fCmJ7UqYbW1",
        "outputId": "a93abeaa-da20-4e6b-ec91-f781375f327d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.8425 | Val Loss: 0.7227\n",
            "Train Sentiment Loss: 0.8237 | Train Emotion Loss: 0.1191\n",
            "Val Sentiment Loss: 0.8156 | Val Emotion Loss: 0.0944\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6265 | Val Loss: 0.5295\n",
            "Train Sentiment Loss: 0.7326 | Train Emotion Loss: 0.1150\n",
            "Val Sentiment Loss: 0.6819 | Val Emotion Loss: 0.0919\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5142 | Val Loss: 0.4823\n",
            "Train Sentiment Loss: 0.6725 | Train Emotion Loss: 0.1115\n",
            "Val Sentiment Loss: 0.6994 | Val Emotion Loss: 0.0909\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4567 | Val Loss: 0.4341\n",
            "Train Sentiment Loss: 0.6397 | Train Emotion Loss: 0.1089\n",
            "Val Sentiment Loss: 0.6647 | Val Emotion Loss: 0.0902\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4379 | Val Loss: 0.4195\n",
            "Train Sentiment Loss: 0.6591 | Train Emotion Loss: 0.1086\n",
            "Val Sentiment Loss: 0.6877 | Val Emotion Loss: 0.0906\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4156 | Val Loss: 0.4033\n",
            "Train Sentiment Loss: 0.6389 | Train Emotion Loss: 0.1088\n",
            "Val Sentiment Loss: 0.6769 | Val Emotion Loss: 0.0911\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4055 | Val Loss: 0.4011\n",
            "Train Sentiment Loss: 0.6390 | Train Emotion Loss: 0.1080\n",
            "Val Sentiment Loss: 0.7032 | Val Emotion Loss: 0.0913\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3993 | Val Loss: 0.3948\n",
            "Train Sentiment Loss: 0.6373 | Train Emotion Loss: 0.1079\n",
            "Val Sentiment Loss: 0.6991 | Val Emotion Loss: 0.0915\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3981 | Val Loss: 0.3881\n",
            "Train Sentiment Loss: 0.6446 | Train Emotion Loss: 0.1084\n",
            "Val Sentiment Loss: 0.6834 | Val Emotion Loss: 0.0913\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3950 | Val Loss: 0.3923\n",
            "Train Sentiment Loss: 0.6392 | Train Emotion Loss: 0.1081\n",
            "Val Sentiment Loss: 0.7104 | Val Emotion Loss: 0.0922\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4013 | Val Loss: 0.3903\n",
            "Train Sentiment Loss: 0.6729 | Train Emotion Loss: 0.1095\n",
            "Val Sentiment Loss: 0.7069 | Val Emotion Loss: 0.0922\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4007 | Val Loss: 0.3897\n",
            "Train Sentiment Loss: 0.6719 | Train Emotion Loss: 0.1099\n",
            "Val Sentiment Loss: 0.7033 | Val Emotion Loss: 0.0929\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4079 | Val Loss: 0.3947\n",
            "Train Sentiment Loss: 0.7068 | Train Emotion Loss: 0.1121\n",
            "Val Sentiment Loss: 0.7346 | Val Emotion Loss: 0.0934\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4072 | Val Loss: 0.3954\n",
            "Train Sentiment Loss: 0.7089 | Train Emotion Loss: 0.1116\n",
            "Val Sentiment Loss: 0.7421 | Val Emotion Loss: 0.0932\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4068 | Val Loss: 0.3932\n",
            "Train Sentiment Loss: 0.7083 | Train Emotion Loss: 0.1114\n",
            "Val Sentiment Loss: 0.7335 | Val Emotion Loss: 0.0924\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4029 | Val Loss: 0.3882\n",
            "Train Sentiment Loss: 0.6923 | Train Emotion Loss: 0.1098\n",
            "Val Sentiment Loss: 0.7031 | Val Emotion Loss: 0.0920\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4004 | Val Loss: 0.3867\n",
            "Train Sentiment Loss: 0.6826 | Train Emotion Loss: 0.1086\n",
            "Val Sentiment Loss: 0.6953 | Val Emotion Loss: 0.0918\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4017 | Val Loss: 0.3915\n",
            "Train Sentiment Loss: 0.6935 | Train Emotion Loss: 0.1082\n",
            "Val Sentiment Loss: 0.7272 | Val Emotion Loss: 0.0918\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4040 | Val Loss: 0.3903\n",
            "Train Sentiment Loss: 0.7081 | Train Emotion Loss: 0.1084\n",
            "Val Sentiment Loss: 0.7173 | Val Emotion Loss: 0.0923\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4021 | Val Loss: 0.3865\n",
            "Train Sentiment Loss: 0.6954 | Train Emotion Loss: 0.1084\n",
            "Val Sentiment Loss: 0.6976 | Val Emotion Loss: 0.0913\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4001 | Val Loss: 0.3868\n",
            "Train Sentiment Loss: 0.6834 | Train Emotion Loss: 0.1082\n",
            "Val Sentiment Loss: 0.7030 | Val Emotion Loss: 0.0908\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3995 | Val Loss: 0.3950\n",
            "Train Sentiment Loss: 0.6815 | Train Emotion Loss: 0.1078\n",
            "Val Sentiment Loss: 0.7503 | Val Emotion Loss: 0.0919\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3981 | Val Loss: 0.3836\n",
            "Train Sentiment Loss: 0.6697 | Train Emotion Loss: 0.1082\n",
            "Val Sentiment Loss: 0.6804 | Val Emotion Loss: 0.0910\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3961 | Val Loss: 0.3849\n",
            "Train Sentiment Loss: 0.6625 | Train Emotion Loss: 0.1073\n",
            "Val Sentiment Loss: 0.6895 | Val Emotion Loss: 0.0909\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3977 | Val Loss: 0.3869\n",
            "Train Sentiment Loss: 0.6700 | Train Emotion Loss: 0.1077\n",
            "Val Sentiment Loss: 0.6996 | Val Emotion Loss: 0.0913\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3961 | Val Loss: 0.3864\n",
            "Train Sentiment Loss: 0.6590 | Train Emotion Loss: 0.1078\n",
            "Val Sentiment Loss: 0.6945 | Val Emotion Loss: 0.0915\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3984 | Val Loss: 0.3907\n",
            "Train Sentiment Loss: 0.6755 | Train Emotion Loss: 0.1075\n",
            "Val Sentiment Loss: 0.7214 | Val Emotion Loss: 0.0918\n",
            "\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3978 | Val Loss: 0.3952\n",
            "Train Sentiment Loss: 0.6679 | Train Emotion Loss: 0.1081\n",
            "Val Sentiment Loss: 0.7465 | Val Emotion Loss: 0.0924\n",
            "\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3977 | Val Loss: 0.3916\n",
            "Train Sentiment Loss: 0.6682 | Train Emotion Loss: 0.1079\n",
            "Val Sentiment Loss: 0.7250 | Val Emotion Loss: 0.0921\n",
            "\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3983 | Val Loss: 0.3888\n",
            "Train Sentiment Loss: 0.6784 | Train Emotion Loss: 0.1069\n",
            "Val Sentiment Loss: 0.7125 | Val Emotion Loss: 0.0913\n",
            "\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3970 | Val Loss: 0.3867\n",
            "Train Sentiment Loss: 0.6725 | Train Emotion Loss: 0.1065\n",
            "Val Sentiment Loss: 0.6983 | Val Emotion Loss: 0.0914\n",
            "\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3951 | Val Loss: 0.3851\n",
            "Train Sentiment Loss: 0.6607 | Train Emotion Loss: 0.1064\n",
            "Val Sentiment Loss: 0.6905 | Val Emotion Loss: 0.0909\n",
            "\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3929 | Val Loss: 0.3834\n",
            "Train Sentiment Loss: 0.6501 | Train Emotion Loss: 0.1058\n",
            "Val Sentiment Loss: 0.6794 | Val Emotion Loss: 0.0910\n",
            "\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3909 | Val Loss: 0.3822\n",
            "Train Sentiment Loss: 0.6398 | Train Emotion Loss: 0.1055\n",
            "Val Sentiment Loss: 0.6732 | Val Emotion Loss: 0.0908\n",
            "\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3913 | Val Loss: 0.3834\n",
            "Train Sentiment Loss: 0.6427 | Train Emotion Loss: 0.1053\n",
            "Val Sentiment Loss: 0.6808 | Val Emotion Loss: 0.0907\n",
            "\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3907 | Val Loss: 0.3873\n",
            "Train Sentiment Loss: 0.6403 | Train Emotion Loss: 0.1051\n",
            "Val Sentiment Loss: 0.7042 | Val Emotion Loss: 0.0909\n",
            "\n",
            "Epoch 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3896 | Val Loss: 0.3842\n",
            "Train Sentiment Loss: 0.6365 | Train Emotion Loss: 0.1047\n",
            "Val Sentiment Loss: 0.6854 | Val Emotion Loss: 0.0908\n",
            "\n",
            "Epoch 38/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3903 | Val Loss: 0.3835\n",
            "Train Sentiment Loss: 0.6392 | Train Emotion Loss: 0.1049\n",
            "Val Sentiment Loss: 0.6824 | Val Emotion Loss: 0.0906\n",
            "\n",
            "Epoch 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3887 | Val Loss: 0.3855\n",
            "Train Sentiment Loss: 0.6325 | Train Emotion Loss: 0.1043\n",
            "Val Sentiment Loss: 0.6924 | Val Emotion Loss: 0.0910\n",
            "\n",
            "Epoch 40/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3879 | Val Loss: 0.3834\n",
            "Train Sentiment Loss: 0.6303 | Train Emotion Loss: 0.1039\n",
            "Val Sentiment Loss: 0.6814 | Val Emotion Loss: 0.0907\n",
            "\n",
            "Epoch 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3902 | Val Loss: 0.3803\n",
            "Train Sentiment Loss: 0.6393 | Train Emotion Loss: 0.1047\n",
            "Val Sentiment Loss: 0.6665 | Val Emotion Loss: 0.0899\n",
            "\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3879 | Val Loss: 0.3826\n",
            "Train Sentiment Loss: 0.6278 | Train Emotion Loss: 0.1043\n",
            "Val Sentiment Loss: 0.6788 | Val Emotion Loss: 0.0903\n",
            "\n",
            "Epoch 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3884 | Val Loss: 0.3815\n",
            "Train Sentiment Loss: 0.6320 | Train Emotion Loss: 0.1041\n",
            "Val Sentiment Loss: 0.6737 | Val Emotion Loss: 0.0899\n",
            "\n",
            "Epoch 44/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3866 | Val Loss: 0.3817\n",
            "Train Sentiment Loss: 0.6207 | Train Emotion Loss: 0.1041\n",
            "Val Sentiment Loss: 0.6729 | Val Emotion Loss: 0.0903\n",
            "\n",
            "Epoch 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3873 | Val Loss: 0.3832\n",
            "Train Sentiment Loss: 0.6244 | Train Emotion Loss: 0.1042\n",
            "Val Sentiment Loss: 0.6805 | Val Emotion Loss: 0.0906\n",
            "\n",
            "Epoch 46/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3869 | Val Loss: 0.3830\n",
            "Train Sentiment Loss: 0.6243 | Train Emotion Loss: 0.1038\n",
            "Val Sentiment Loss: 0.6812 | Val Emotion Loss: 0.0902\n",
            "\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3863 | Val Loss: 0.3828\n",
            "Train Sentiment Loss: 0.6217 | Train Emotion Loss: 0.1036\n",
            "Val Sentiment Loss: 0.6792 | Val Emotion Loss: 0.0903\n",
            "\n",
            "Epoch 48/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3883 | Val Loss: 0.3803\n",
            "Train Sentiment Loss: 0.6294 | Train Emotion Loss: 0.1044\n",
            "Val Sentiment Loss: 0.6684 | Val Emotion Loss: 0.0895\n",
            "\n",
            "Epoch 49/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3873 | Val Loss: 0.3796\n",
            "Train Sentiment Loss: 0.6262 | Train Emotion Loss: 0.1040\n",
            "Val Sentiment Loss: 0.6644 | Val Emotion Loss: 0.0895\n",
            "\n",
            "Epoch 50/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3871 | Val Loss: 0.3798\n",
            "Train Sentiment Loss: 0.6272 | Train Emotion Loss: 0.1035\n",
            "Val Sentiment Loss: 0.6666 | Val Emotion Loss: 0.0894\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_audio_train_res = load('/content/drive/MyDrive/model/text_audio_train_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Text + Audio training time per batch (ms): {sum(text_audio_train_res['training_times']) / len(text_audio_train_res['training_times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlhIwjz7PFa0",
        "outputId": "37364eb7-6122-4c50-e234-2f98f988595a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text + Audio training time per batch (ms): 9.292967697412301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_audio_test_res = multi_test_model(text_audio_model, testdata, loss_fn, modalities=['text', 'audio'], save_path=text_audio_model_path, mean_sentiment_loss=text_audio_mean_sentiment_loss, mean_emotion_loss=text_audio_mean_emotion_loss)\n",
        "\n",
        "save(text_audio_test_res, '/content/drive/MyDrive/model/text_audio_test_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1PGE5MbBmkt",
        "outputId": "63548012-14ee-4f37-d2e9-a7be79488c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Metrics:\n",
            "Total Loss: 0.3812\n",
            "Total MAE: 0.4291\n",
            "Sentiment MAE: 0.6847\n",
            "Sentiment PCC: 0.6043\n",
            "Emotion MAE: 0.1734\n",
            "Emotion R: 0.0727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_audio_test_res = load('/content/drive/MyDrive/model/text_audio_test_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Text + Audio testing time per batch (ms): {sum(text_audio_test_res['Testing Times']) / len(text_audio_test_res['Testing Times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdzdN3ifVnNI",
        "outputId": "c3c6287a-a206-4fe6-ccb8-26247163e567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text + Audio testing time per batch (ms): 5.820481744531082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_video_input_dims = {'text': 300, 'video': 713}\n",
        "\n",
        "# Compute mean losses in train dataset\n",
        "text_video_mean_sentiment_loss, text_video_mean_emotion_loss = multi_avg_mean_losses(traindata, text_video_input_dims, hidden_dim, attention_dim)\n",
        "\n",
        "print(f\"Text + Video Mean Sentiment Loss: {text_video_mean_sentiment_loss:.4f}\")\n",
        "print(f\"Text + Video Mean Emotion Loss: {text_video_mean_emotion_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I0zsvVYaLNH",
        "outputId": "4f7598d9-1106-4db2-c5f2-0fe5148c411e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                                "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text + Video Mean Sentiment Loss: 1.2992\n",
            "Text + Video Mean Emotion Loss: 1.0988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_video_model = MultiModel(text_video_input_dims, hidden_dim, attention_dim)\n",
        "text_video_optimizer = AdamW([\n",
        "    {'params': text_video_model.parameters()},\n",
        "    {'params': [loss_fn.log_sigma_sentiment, loss_fn.log_sigma_emotion]}\n",
        "], lr=0.001, weight_decay=0.01)\n",
        "text_video_scheduler = ReduceLROnPlateau(text_video_optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# Save path for the trained model\n",
        "text_video_model_path = os.path.join(save_model_path, \"text_video.pth\")"
      ],
      "metadata": {
        "id": "YOlsHZSVf0kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_video_train_res = multi_train_model(\n",
        "    text_video_model, traindata, validdata, epochs=50, optimizer=text_video_optimizer,\n",
        "    scheduler=text_video_scheduler, loss_fn=loss_fn, save_path=text_video_model_path, modalities=['text', 'video'],\n",
        "    mean_sentiment_loss=text_video_mean_sentiment_loss, mean_emotion_loss=text_video_mean_emotion_loss\n",
        ")\n",
        "\n",
        "save(text_video_train_res, '/content/drive/MyDrive/model/text_video_train_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfwf1cHhf27S",
        "outputId": "68074f92-d508-40db-995b-5def558e6775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4356 | Val Loss: 0.4148\n",
            "Train Sentiment Loss: 0.8192 | Train Emotion Loss: 0.1279\n",
            "Val Sentiment Loss: 0.8082 | Val Emotion Loss: 0.1050\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4123 | Val Loss: 0.3816\n",
            "Train Sentiment Loss: 0.6851 | Train Emotion Loss: 0.1218\n",
            "Val Sentiment Loss: 0.6617 | Val Emotion Loss: 0.0901\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4188 | Val Loss: 0.3865\n",
            "Train Sentiment Loss: 0.7711 | Train Emotion Loss: 0.1140\n",
            "Val Sentiment Loss: 0.6793 | Val Emotion Loss: 0.0930\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4004 | Val Loss: 0.3902\n",
            "Train Sentiment Loss: 0.6803 | Train Emotion Loss: 0.1089\n",
            "Val Sentiment Loss: 0.7105 | Val Emotion Loss: 0.0925\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4221 | Val Loss: 0.4169\n",
            "Train Sentiment Loss: 0.7996 | Train Emotion Loss: 0.1134\n",
            "Val Sentiment Loss: 0.8789 | Val Emotion Loss: 0.0949\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4432 | Val Loss: 0.4010\n",
            "Train Sentiment Loss: 0.9115 | Train Emotion Loss: 0.1202\n",
            "Val Sentiment Loss: 0.7703 | Val Emotion Loss: 0.0951\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4430 | Val Loss: 0.3994\n",
            "Train Sentiment Loss: 0.9321 | Train Emotion Loss: 0.1188\n",
            "Val Sentiment Loss: 0.7549 | Val Emotion Loss: 0.0958\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4357 | Val Loss: 0.3978\n",
            "Train Sentiment Loss: 0.8887 | Train Emotion Loss: 0.1179\n",
            "Val Sentiment Loss: 0.7595 | Val Emotion Loss: 0.0932\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6331 | Val Loss: 0.3990\n",
            "Train Sentiment Loss: 2.4860 | Train Emotion Loss: 0.1150\n",
            "Val Sentiment Loss: 0.7650 | Val Emotion Loss: 0.0938\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4333 | Val Loss: 0.3965\n",
            "Train Sentiment Loss: 0.8844 | Train Emotion Loss: 0.1161\n",
            "Val Sentiment Loss: 0.7492 | Val Emotion Loss: 0.0932\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4319 | Val Loss: 0.3943\n",
            "Train Sentiment Loss: 0.8862 | Train Emotion Loss: 0.1143\n",
            "Val Sentiment Loss: 0.7458 | Val Emotion Loss: 0.0914\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4297 | Val Loss: 0.3945\n",
            "Train Sentiment Loss: 0.8862 | Train Emotion Loss: 0.1117\n",
            "Val Sentiment Loss: 0.7406 | Val Emotion Loss: 0.0926\n",
            "\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_video_train_res = load('/content/drive/MyDrive/model/text_video_train_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Text + Video training time per batch (ms): {sum(text_video_train_res['training_times']) / len(text_video_train_res['training_times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLm7C_3YSiTQ",
        "outputId": "673eaf28-a381-4f0b-a4a3-922767455b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text + Video training time per batch (ms): 10.179630619827938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_video_test_res = multi_test_model(text_video_model, testdata, loss_fn, modalities=['text', 'video'], save_path=text_video_model_path, mean_sentiment_loss=text_video_mean_sentiment_loss, mean_emotion_loss=text_video_mean_emotion_loss)\n",
        "\n",
        "save(text_video_test_res, '/content/drive/MyDrive/model/text_video_test_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy3k_RaxEEaX",
        "outputId": "46a1e0ad-ddc2-4936-a891-32c52a40988e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Metrics:\n",
            "Total Loss: 0.3735\n",
            "Total MAE: 0.4235\n",
            "Sentiment MAE: 0.6798\n",
            "Sentiment PCC: 0.6156\n",
            "Emotion MAE: 0.1671\n",
            "Emotion R: 0.0826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_video_test_res = load('/content/drive/MyDrive/model/text_video_test_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Text + Video testing time per batch (ms): {sum(text_video_test_res['Testing Times']) / len(text_video_test_res['Testing Times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMdnf9JfVX23",
        "outputId": "9937a8b3-b630-4d7a-809c-9031873150f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text + Video testing time per batch (ms): 6.175682969289284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_video_input_dims = {'audio': 74, 'video': 713}\n",
        "\n",
        "# Compute mean losses in train dataset\n",
        "audio_video_mean_sentiment_loss, audio_video_mean_emotion_loss = multi_avg_mean_losses(traindata, audio_video_input_dims, hidden_dim, attention_dim)\n",
        "\n",
        "print(f\"Audio + Video Mean Sentiment Loss: {audio_video_mean_sentiment_loss:.4f}\")\n",
        "print(f\"Audio + Video Mean Emotion Loss: {audio_video_mean_emotion_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekM63a29sYb-",
        "outputId": "9adc8b6d-287d-4829-8576-2aab99f7edd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                                 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio + Video Mean Sentiment Loss: 1.2846\n",
            "Audio + Video Mean Emotion Loss: 1.1544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_video_model = MultiModel(audio_video_input_dims, hidden_dim, attention_dim)\n",
        "audio_video_optimizer = AdamW([\n",
        "    {'params': audio_video_model.parameters()},\n",
        "    {'params': [loss_fn.log_sigma_sentiment, loss_fn.log_sigma_emotion]}\n",
        "], lr=0.001, weight_decay=0.01)\n",
        "audio_video_scheduler = ReduceLROnPlateau(audio_video_optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# Save path for the trained model\n",
        "audio_video_model_path = os.path.join(save_model_path, \"audio_video.pth\")"
      ],
      "metadata": {
        "id": "5-T3QjE-i-V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_video_train_res = multi_train_model(\n",
        "    audio_video_model, traindata, validdata, epochs=50, optimizer=audio_video_optimizer,\n",
        "    scheduler=audio_video_scheduler, loss_fn=loss_fn, save_path=audio_video_model_path, modalities=['audio', 'video'],\n",
        "    mean_sentiment_loss=audio_video_mean_sentiment_loss, mean_emotion_loss=audio_video_mean_emotion_loss\n",
        ")\n",
        "\n",
        "save(audio_video_train_res, '/content/drive/MyDrive/model/audio_video_train_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2K_YAscsh0V",
        "outputId": "edc44305-aecc-4a69-fda8-ae1b15cde2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4372 | Val Loss: 0.4128\n",
            "Train Sentiment Loss: 0.8869 | Train Emotion Loss: 0.1209\n",
            "Val Sentiment Loss: 0.8915 | Val Emotion Loss: 0.0923\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4317 | Val Loss: 0.4432\n",
            "Train Sentiment Loss: 0.8961 | Train Emotion Loss: 0.1131\n",
            "Val Sentiment Loss: 0.9985 | Val Emotion Loss: 0.1121\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4427 | Val Loss: 0.4119\n",
            "Train Sentiment Loss: 0.9635 | Train Emotion Loss: 0.1167\n",
            "Val Sentiment Loss: 0.8344 | Val Emotion Loss: 0.0988\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4417 | Val Loss: 0.4073\n",
            "Train Sentiment Loss: 0.9619 | Train Emotion Loss: 0.1162\n",
            "Val Sentiment Loss: 0.8365 | Val Emotion Loss: 0.0933\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0837 | Val Loss: 0.4092\n",
            "Train Sentiment Loss: 1.0496 | Train Emotion Loss: 0.8453\n",
            "Val Sentiment Loss: 0.8344 | Val Emotion Loss: 0.0941\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4420 | Val Loss: 0.4095\n",
            "Train Sentiment Loss: 0.9602 | Train Emotion Loss: 0.1171\n",
            "Val Sentiment Loss: 0.8352 | Val Emotion Loss: 0.0946\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4451 | Val Loss: 0.4097\n",
            "Train Sentiment Loss: 0.9863 | Train Emotion Loss: 0.1174\n",
            "Val Sentiment Loss: 0.8350 | Val Emotion Loss: 0.0949\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4451 | Val Loss: 0.4208\n",
            "Train Sentiment Loss: 0.9867 | Train Emotion Loss: 0.1174\n",
            "Val Sentiment Loss: 0.9365 | Val Emotion Loss: 0.0950\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4446 | Val Loss: 0.4098\n",
            "Train Sentiment Loss: 0.9866 | Train Emotion Loss: 0.1168\n",
            "Val Sentiment Loss: 0.8348 | Val Emotion Loss: 0.0951\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4449 | Val Loss: 0.4096\n",
            "Train Sentiment Loss: 0.9845 | Train Emotion Loss: 0.1174\n",
            "Val Sentiment Loss: 0.8347 | Val Emotion Loss: 0.0950\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4446 | Val Loss: 0.4082\n",
            "Train Sentiment Loss: 0.9870 | Train Emotion Loss: 0.1166\n",
            "Val Sentiment Loss: 0.8345 | Val Emotion Loss: 0.0933\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4390 | Val Loss: 0.4041\n",
            "Train Sentiment Loss: 0.9702 | Train Emotion Loss: 0.1122\n",
            "Val Sentiment Loss: 0.8136 | Val Emotion Loss: 0.0911\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4391 | Val Loss: 0.4044\n",
            "Train Sentiment Loss: 0.9611 | Train Emotion Loss: 0.1135\n",
            "Val Sentiment Loss: 0.8125 | Val Emotion Loss: 0.0916\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4342 | Val Loss: 0.4019\n",
            "Train Sentiment Loss: 0.9547 | Train Emotion Loss: 0.1086\n",
            "Val Sentiment Loss: 0.8102 | Val Emotion Loss: 0.0892\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4337 | Val Loss: 0.4100\n",
            "Train Sentiment Loss: 0.9663 | Train Emotion Loss: 0.1064\n",
            "Val Sentiment Loss: 0.8805 | Val Emotion Loss: 0.0896\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4305 | Val Loss: 0.4063\n",
            "Train Sentiment Loss: 0.9419 | Train Emotion Loss: 0.1059\n",
            "Val Sentiment Loss: 0.8524 | Val Emotion Loss: 0.0892\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4308 | Val Loss: 0.4035\n",
            "Train Sentiment Loss: 0.9401 | Train Emotion Loss: 0.1065\n",
            "Val Sentiment Loss: 0.8413 | Val Emotion Loss: 0.0875\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4336 | Val Loss: 0.4000\n",
            "Train Sentiment Loss: 0.9754 | Train Emotion Loss: 0.1052\n",
            "Val Sentiment Loss: 0.8034 | Val Emotion Loss: 0.0884\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4295 | Val Loss: 0.4009\n",
            "Train Sentiment Loss: 0.9327 | Train Emotion Loss: 0.1061\n",
            "Val Sentiment Loss: 0.8108 | Val Emotion Loss: 0.0888\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4271 | Val Loss: 0.4024\n",
            "Train Sentiment Loss: 0.8978 | Train Emotion Loss: 0.1077\n",
            "Val Sentiment Loss: 0.8197 | Val Emotion Loss: 0.0896\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4616 | Val Loss: 0.4058\n",
            "Train Sentiment Loss: 0.9541 | Train Emotion Loss: 0.1396\n",
            "Val Sentiment Loss: 0.8335 | Val Emotion Loss: 0.0916\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5866 | Val Loss: 0.4097\n",
            "Train Sentiment Loss: 1.2523 | Train Emotion Loss: 0.2447\n",
            "Val Sentiment Loss: 0.8400 | Val Emotion Loss: 0.0948\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4352 | Val Loss: 0.4041\n",
            "Train Sentiment Loss: 0.9483 | Train Emotion Loss: 0.1107\n",
            "Val Sentiment Loss: 0.8108 | Val Emotion Loss: 0.0921\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4309 | Val Loss: 0.4012\n",
            "Train Sentiment Loss: 0.9232 | Train Emotion Loss: 0.1088\n",
            "Val Sentiment Loss: 0.8115 | Val Emotion Loss: 0.0888\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4299 | Val Loss: 0.3988\n",
            "Train Sentiment Loss: 0.9107 | Train Emotion Loss: 0.1093\n",
            "Val Sentiment Loss: 0.8004 | Val Emotion Loss: 0.0875\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4302 | Val Loss: 0.3986\n",
            "Train Sentiment Loss: 0.9136 | Train Emotion Loss: 0.1092\n",
            "Val Sentiment Loss: 0.7993 | Val Emotion Loss: 0.0875\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4332 | Val Loss: 0.4024\n",
            "Train Sentiment Loss: 0.9303 | Train Emotion Loss: 0.1105\n",
            "Val Sentiment Loss: 0.8051 | Val Emotion Loss: 0.0912\n",
            "\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4371 | Val Loss: 0.4063\n",
            "Train Sentiment Loss: 0.9284 | Train Emotion Loss: 0.1153\n",
            "Val Sentiment Loss: 0.8324 | Val Emotion Loss: 0.0922\n",
            "\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4382 | Val Loss: 0.4054\n",
            "Train Sentiment Loss: 0.9430 | Train Emotion Loss: 0.1147\n",
            "Val Sentiment Loss: 0.8256 | Val Emotion Loss: 0.0920\n",
            "\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4351 | Val Loss: 0.4039\n",
            "Train Sentiment Loss: 0.9167 | Train Emotion Loss: 0.1145\n",
            "Val Sentiment Loss: 0.8144 | Val Emotion Loss: 0.0918\n",
            "\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4344 | Val Loss: 0.4060\n",
            "Train Sentiment Loss: 0.9058 | Train Emotion Loss: 0.1150\n",
            "Val Sentiment Loss: 0.8269 | Val Emotion Loss: 0.0926\n",
            "\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4342 | Val Loss: 0.4049\n",
            "Train Sentiment Loss: 0.9029 | Train Emotion Loss: 0.1152\n",
            "Val Sentiment Loss: 0.8179 | Val Emotion Loss: 0.0926\n",
            "\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4363 | Val Loss: 0.4047\n",
            "Train Sentiment Loss: 0.9216 | Train Emotion Loss: 0.1151\n",
            "Val Sentiment Loss: 0.8214 | Val Emotion Loss: 0.0919\n",
            "\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4346 | Val Loss: 0.4045\n",
            "Train Sentiment Loss: 0.9080 | Train Emotion Loss: 0.1149\n",
            "Val Sentiment Loss: 0.8204 | Val Emotion Loss: 0.0918\n",
            "\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4343 | Val Loss: 0.4041\n",
            "Train Sentiment Loss: 0.9067 | Train Emotion Loss: 0.1148\n",
            "Val Sentiment Loss: 0.8194 | Val Emotion Loss: 0.0915\n",
            "\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4349 | Val Loss: 0.4039\n",
            "Train Sentiment Loss: 0.9145 | Train Emotion Loss: 0.1145\n",
            "Val Sentiment Loss: 0.8185 | Val Emotion Loss: 0.0914\n",
            "\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_video_train_res = load('/content/drive/MyDrive/model/audio_video_train_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Audio + Video training time per batch (ms): {sum(audio_video_train_res['training_times']) / len(audio_video_train_res['training_times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxTe2UboUVon",
        "outputId": "0e2ad695-907e-4564-a247-50e4d3bdc0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio + Video training time per batch (ms): 9.77151284764243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_video_test_res = multi_test_model(audio_video_model, testdata, loss_fn, modalities=['audio', 'video'], save_path=audio_video_model_path, mean_sentiment_loss=audio_video_mean_sentiment_loss, mean_emotion_loss=audio_video_mean_emotion_loss)\n",
        "\n",
        "save(audio_video_test_res, '/content/drive/MyDrive/model/audio_video_test_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYWxtnNTE0aE",
        "outputId": "afa49909-ef1d-4ce0-da02-a96cf39cb2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Metrics:\n",
            "Total Loss: 0.4055\n",
            "Total MAE: 0.4908\n",
            "Sentiment MAE: 0.8075\n",
            "Sentiment PCC: 0.2831\n",
            "Emotion MAE: 0.1740\n",
            "Emotion R: 0.0653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_video_test_res = load('/content/drive/MyDrive/model/audio_video_test_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Audio + Video testing time per batch (ms): {sum(audio_video_test_res['Testing Times']) / len(audio_video_test_res['Testing Times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCqvslqVVKGK",
        "outputId": "d56a1acd-ed92-491e-c9ba-23bcefbfd9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio + Video testing time per batch (ms): 5.233323737366559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tri_input_dims = {'text': 300, 'audio': 74, 'video': 713}\n",
        "\n",
        "# Compute mean losses in train dataset\n",
        "tri_mean_sentiment_loss, tri_mean_emotion_loss = multi_avg_mean_losses(traindata, tri_input_dims, hidden_dim, attention_dim)\n",
        "\n",
        "print(f\"Trimodal Mean Sentiment Loss: {tri_mean_sentiment_loss:.4f}\")\n",
        "print(f\"Trimodal Mean Emotion Loss: {tri_mean_emotion_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjLyNa6GwAeu",
        "outputId": "f7b6f4fb-7038-4c55-fadb-37289ee92a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trimodal Mean Sentiment Loss: 1.2928\n",
            "Trimodal Mean Emotion Loss: 1.2170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tri_model = MultiModel(tri_input_dims, hidden_dim, attention_dim)\n",
        "tri_optimizer = AdamW([\n",
        "    {'params': tri_model.parameters()},\n",
        "    {'params': [loss_fn.log_sigma_sentiment, loss_fn.log_sigma_emotion]}\n",
        "], lr=0.001, weight_decay=0.01)\n",
        "tri_scheduler = ReduceLROnPlateau(tri_optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# Save path for the trained model\n",
        "tri_model_path = os.path.join(save_model_path, \"tri.pth\")"
      ],
      "metadata": {
        "id": "z3-jF8aVwIVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tri_train_res = multi_train_model(\n",
        "    tri_model, traindata, validdata, epochs=50, optimizer=tri_optimizer,\n",
        "    scheduler=tri_scheduler, loss_fn=loss_fn, save_path=tri_model_path, modalities=['text', 'audio', 'video'],\n",
        "    mean_sentiment_loss=tri_mean_sentiment_loss, mean_emotion_loss=tri_mean_emotion_loss\n",
        ")\n",
        "\n",
        "save(tri_train_res, '/content/drive/MyDrive/model/tri_train_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CftUm-kvwLA2",
        "outputId": "846a1970-3cdd-4b2c-9575-a1c479c88d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4237 | Val Loss: 0.3886\n",
            "Train Sentiment Loss: 0.7970 | Train Emotion Loss: 0.1177\n",
            "Val Sentiment Loss: 0.7612 | Val Emotion Loss: 0.0832\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4053 | Val Loss: 0.3914\n",
            "Train Sentiment Loss: 0.7343 | Train Emotion Loss: 0.1061\n",
            "Val Sentiment Loss: 0.7645 | Val Emotion Loss: 0.0862\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4067 | Val Loss: 0.3839\n",
            "Train Sentiment Loss: 0.7593 | Train Emotion Loss: 0.1039\n",
            "Val Sentiment Loss: 0.7331 | Val Emotion Loss: 0.0836\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3989 | Val Loss: 0.3902\n",
            "Train Sentiment Loss: 0.7260 | Train Emotion Loss: 0.1007\n",
            "Val Sentiment Loss: 0.7463 | Val Emotion Loss: 0.0887\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4149 | Val Loss: 0.3957\n",
            "Train Sentiment Loss: 0.7981 | Train Emotion Loss: 0.1067\n",
            "Val Sentiment Loss: 0.7865 | Val Emotion Loss: 0.0888\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4165 | Val Loss: 0.3844\n",
            "Train Sentiment Loss: 0.8145 | Train Emotion Loss: 0.1066\n",
            "Val Sentiment Loss: 0.7178 | Val Emotion Loss: 0.0867\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4209 | Val Loss: 0.3894\n",
            "Train Sentiment Loss: 0.8460 | Train Emotion Loss: 0.1071\n",
            "Val Sentiment Loss: 0.7591 | Val Emotion Loss: 0.0861\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4183 | Val Loss: 0.3984\n",
            "Train Sentiment Loss: 0.8371 | Train Emotion Loss: 0.1058\n",
            "Val Sentiment Loss: 0.8185 | Val Emotion Loss: 0.0876\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4295 | Val Loss: 0.4006\n",
            "Train Sentiment Loss: 0.9327 | Train Emotion Loss: 0.1052\n",
            "Val Sentiment Loss: 0.8256 | Val Emotion Loss: 0.0893\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4258 | Val Loss: 0.3933\n",
            "Train Sentiment Loss: 0.8859 | Train Emotion Loss: 0.1076\n",
            "Val Sentiment Loss: 0.7818 | Val Emotion Loss: 0.0870\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4157 | Val Loss: 0.3880\n",
            "Train Sentiment Loss: 0.8261 | Train Emotion Loss: 0.1046\n",
            "Val Sentiment Loss: 0.7482 | Val Emotion Loss: 0.0858\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4096 | Val Loss: 0.3858\n",
            "Train Sentiment Loss: 0.7937 | Train Emotion Loss: 0.1025\n",
            "Val Sentiment Loss: 0.7410 | Val Emotion Loss: 0.0849\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4089 | Val Loss: 0.3895\n",
            "Train Sentiment Loss: 0.7953 | Train Emotion Loss: 0.1016\n",
            "Val Sentiment Loss: 0.7670 | Val Emotion Loss: 0.0855\n",
            "\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tri_train_res = load('/content/drive/MyDrive/model/tri_train_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Trimodal training time per batch (ms): {sum(tri_train_res['training_times']) / len(tri_train_res['training_times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H5D5EzHUjIk",
        "outputId": "6a0f0c45-f0f0-4f53-f299-2b050b255a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trimodal training time per batch (ms): 13.736942419890232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tri_test_res = multi_test_model(tri_model, testdata, loss_fn, modalities=['text', 'audio', 'video'], save_path=tri_model_path, mean_sentiment_loss=tri_mean_sentiment_loss, mean_emotion_loss=tri_mean_emotion_loss)\n",
        "\n",
        "save(tri_test_res, '/content/drive/MyDrive/model/tri_test_res.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PlnMHSjJn2V",
        "outputId": "f0162575-c332-46f7-8f1d-3a4c2fc9b0f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Metrics:\n",
            "Total Loss: 0.3611\n",
            "Total MAE: 0.4140\n",
            "Sentiment MAE: 0.6735\n",
            "Sentiment PCC: 0.6207\n",
            "Emotion MAE: 0.1544\n",
            "Emotion R: 0.0972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tri_test_res = load('/content/drive/MyDrive/model/tri_test_res.pkl')\n",
        "# avg training time per batch, then avg among epoch\n",
        "print(f\"Trimodal testing time per batch (ms): {sum(tri_test_res['Testing Times']) / len(tri_test_res['Testing Times']) * 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYoCRtDcUy5x",
        "outputId": "8adef5fa-b7c4-4e51-c1e0-ee598d81e568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trimodal testing time per batch (ms): 5.802930217899688\n"
          ]
        }
      ]
    }
  ]
}
